[{"content":"$$ U_i = U_1 + U_0 $$\n中文测试\n","permalink":"https://zehua716.github.io/posts/machinelearning/test/","summary":"summary","title":"tst title"},{"content":"这是关乎概率论的测试\n","permalink":"https://zehua716.github.io/posts/probability/test/","summary":"summary","title":"tst title"},{"content":"$$ U_i = U_1 + U_0 $$\n中文测试\n","permalink":"https://zehua716.github.io/posts/signal/test/","summary":"summary","title":"tst title"},{"content":"1. Image Projection Model and 3D Reconstruction Theory 1.1. Concept of SLAM SLAM (Simultaneous Localization and Mapping).\nBy estimating each camera’s position and the scene’s 3D points, achieve scene reconstruction.\n1.2. Reverse 2D Image Extract 3D scene information from a 2D image, i.e., perform $3D$ reconstruction.\nInverse Projection\nThe image is a 2D representation of the 3D scene after projection. To recover 3D information, it is necessary to reverse this projection process.\nEstablish a mathematical model describing how the 3D scene is projected onto the 2D image, then attempt to solve it inversely.\n1.3 Pinhole Camera Model 1.3.1 Model Overview Definition: The pinhole camera model assumes that all light rays pass through a common point, the optical center.\nAdvantages: Simple model, easy to compute inversely, widely used in 3D reconstruction. 1.3.2 Coordinate Systems and Notation Conventions Camera Coordinate System: Origin $O_C$: Optical center, coordinates $(0, 0, 0)$.\nAxis Directions: Establish a right-handed coordinate system, $X_C$ to the right, $Y_C$ downward, $Z_C$ pointing backward (scene depth direction).\nAdvantage: The $Z$ axis points backward, object depth is positive, which is intuitive.\n1.3.3 Projection of 3D Points to Normalized Focal Plane 3D Point Representation:\nPoint $U$: Coordinates $(U_X, U_Y, U_Z)$, representing a 3D point in space.\nNormalized Focal Plane:\nA plane at a distance of $1$ from the optical center $O_C$ ($Z_C = 1$), called the normalized focal plane.\nProject distant 3D points onto this plane.\n1.3.4 Homogeneous Coordinates and Inhomogeneous Coordinates Homogeneous Coordinates:\nDefinition: Adding an extra dimension (usually $1$) to the original coordinates to facilitate projection and transformation.\nRepresentation: For a 2D point $m = (m_X, m_Y)^T$, its homogeneous coordinates are $\\bar{m} = (m_X, m_Y, 1)^T$.\nPurpose: Homogeneous coordinates facilitate matrix operations, especially during projection and transformation processes.\nInhomogeneous Coordinates:\nStandard Cartesian coordinate representation, without extra dimensions.\n1.4 Linear Calibration of the Camera 1.4.1 From Normalized Focal Plane to Image Plane Image Plane:\nCoordinate System: Pixel coordinate system, typically with the image’s top-left corner as the origin, $X$ axis to the right (column index), $Y$ axis downward.\nPurpose: Map points on the normalized focal plane to actual image pixel coordinates.\nLinear Transformation:\nTransformation Formula:\n$$\\begin{cases} P_U = f \\cdot m_X + U_0 \\\\ P_V = f \\cdot m_Y + V_0 \\end{cases}$$ Focal Length $f$\n$m_X$, $m_Y$ are points on the normalized focal plane\nOptical Center Coordinates on the Image Plane $(U_0, V_0)$\n1.4.2 Camera Intrinsic Matrix Represent the above linear transformation in matrix form. $$K = \\begin{pmatrix} f \u0026 0 \u0026 U_0 \\\\ 0 \u0026 f \u0026 V_0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix}$$ Matrix Mapping Relationship: $$\\underline{P} = K \\cdot \\underline{m}$$ Where, $\\underline{P}$ is the homogeneous coordinates of points on the image plane.\n1.4.3 Inverse Process From Image Plane to Normalized Focal Plane: $$\\underline{M} = K^{-1} \\cdot \\underline{P}$$ 1.4.4 Viewing Frustum Represents the spatial range that the camera can see. By converting the four corner points of the image to the normalized focal plane and then connecting them to the optical center, forming a viewing frustum. 1.5 Distortion Modeling and Correction 1.5.1 Sources of Camera Distortion Optical defects in actual camera lenses, especially in wide-angle lenses, causing image distortion, straight lines becoming curved, image edges stretched or compressed. 1.5.2 Distortion Model Distortion Function:\nApply a distortion function to ideal points on the normalized focal plane (from ideal image to distorted image) to obtain distorted points, which are actual $2D$ points on the distorted focal plane.\n$$\\underline{m}_d = d(\\underline{m}, k)$$ Where, $k$ are distortion parameters.\nExample: Polynomial Radial Distortion Model $$M_d = \\left(1 + k_1 \\|m\\|_2^2 + k_2 \\|m\\|_2^4 + \\dots \\right) m$$ Where: $|m|_2^2 = m_x^2 + m_y^2$\n1.6 Implementation of Distortion Correction 1.6.1 Task Description Goal: Correct the distorted actual image to an ideal undistorted image. 1.6.2 Implementation Steps Define Parameters: Ideal camera intrinsic matrix $K_{\\text{ideal}}$; distorted camera intrinsic matrix $K_{\\text{real}}$; distortion parameters $k$.\nFor each ideal image pixel coordinate, perform the following steps:\n​\t1.\tConvert pixel coordinates to normalized focal plane:\n$$\\underline{m} _{\\text{ideal}} = K_{\\text{ideal}}^{-1} \\cdot \\underline{P} _{\\text{ideal}}$$ ​\t2.\tApply distortion function:\n$$\\underline{m}_d = d(\\underline{m} _{\\text{ideal}}, k)$$ ​\t3.\tMap back to actual image coordinate system:\n$$\\underline{P} _{\\text{real}} = K_{\\text{real}} \\cdot \\underline{m}_d$$ ​\t4.\tInterpolation:\nPerform interpolation on $\\underline{P} _{\\text{real}}$ (since coordinates may be non-integer, possibly use bilinear interpolation)\n​\t5.\tGenerate corrected image\n2. 2D Rigid Transformation and Homography 2.1 2D Rigid Transformation 2D rigid transformations include translation and rotation.\n2.1.1 Rotation $$\\mathbf{U}^c = \\overrightarrow{O _c U}^c \\quad \\mathbf{U}^w = \\overrightarrow{O _w U}^w$$ $$\\mathbf{R} _{wc} \\underline{\\mathbf{U}}^c = \\mathbf{R} _{wc} \\cdot \\overrightarrow{O _c U}^c = \\overrightarrow{O _w U}^w$$ Select a vector from one reference frame and then transform it to another coordinate frame.\n$\\mathbf{R} _{wc}$ is an orthogonal matrix.\n2.1.2 Translation $$\\mathbf{T} _{wc} = \\overrightarrow{O _w O _c}^{w}$$ 2.1.3 Rigid Transformation Formula $$\\mathbf{U}^w = \\mathbf{R} _{wc} \\cdot \\mathbf{U}^c + \\mathbf{T} _{wc}$$ Proof:\n$$\\mathbf{R} _{wc} \\cdot \\mathbf{U}^c + \\mathbf{T} _{wc} = \\mathbf{R} _{wc} \\cdot \\overrightarrow{O _c U}^c + \\overrightarrow{O _w O _c}^w = \\overrightarrow{O _c U}^w + \\overrightarrow{O _w O _c}^w = \\overrightarrow{O _w U}^w = \\mathbf{U}^w$$ 2.1.4 Homogeneous Coordinates: $$\\underline{\\mathbf{U}}^w = \\begin{bmatrix} \\mathbf{U}^w \\\\ 1 \\end{bmatrix}$$ $$\\mathbf{M} _{wc} = \\begin{bmatrix} \\mathbf{R} _{wc} \u0026 \\mathbf{T} _{wc} \\\\ 0 \u0026 1 \\end{bmatrix} = \\begin{bmatrix} r _{11} \u0026 r _{12} \u0026 r _{13} \u0026 t _{x} \\\\ r _{21} \u0026 r _{22} \u0026 r _{23} \u0026 t _{y} \\\\ r _{31} \u0026 r _{32} \u0026 r _{33} \u0026 t _{z} \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\end{bmatrix}$$ 2.1.5 Inverse Transformation: $$\\mathbf{M} _{cw} = \\mathbf{M} _{wc}^{-1}$$ 2.1.6 Composability of Transformations: $$\\mathbf{M} _{ab} \\cdot \\mathbf{M} _{bc} = \\mathbf{M} _{ac}$$ 2.2 Homography 2.2.1 Plane Scene Assumption $$\\mathbf{U} _i^A = z _i^A \\cdot \\underline{\\mathbf{m}} _{Ai}$$ This equation means that the point $\\mathbf{U} _i ^ A$ can be represented by $\\underline{\\mathbf{m}} _{Ai}$ by multiplying its depth, since $\\underline{\\mathbf{m}} _{Ai}$ has unit depth.\n2.2.2 Finding the Correspondence Between $\\underline{\\mathbf{m}} _{Ai}$ and $\\underline{\\mathbf{m}} _{Bi}$ With only this equation, how do we find the correspondence between $\\underline{\\mathbf{m}} _{Ai}$ and $\\underline{\\mathbf{m}} _{Bi}$? In simple terms, how do we perform coordinate correspondence transformations?\n​\t1.\tKey Formula for the Normal\nWe need to recall a property to obtain a key formula involving the normal and the plane.\nIn reference frame $A$, the equation of plane $P$ is: $ax + by + cz + d = 0$, where $a, b, c$ are the components of the plane’s normal vector, and $d$ is a constant representing the relative distance between plane $P$ and the origin $O _A$.\nIn vector form, the plane equation can be simplified to:\n$$\\mathbf{n} _A^T \\mathbf{U} _i^A + d = 0$$ $\\mathbf{n} _A^T$ represents the normal vector of plane $P$ in reference frame $A$.\nThrough the vector form of the plane equation, we obtain a very important formula involving the normal vector.\n​\t2.\tObtaining the Depth Expression Using Variable Substitution\nSubstitute $\\mathbf{U} _i^A = z _i^A \\cdot \\underline{\\mathbf{m}} _{A,i}$ into the above equation:\n$$\\mathbf{n} _A^T \\cdot z _i^A \\cdot \\underline{\\mathbf{m}} _{A,i} + d = 0 \\quad \\Rightarrow \\quad z _i^A = -\\dfrac{d}{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}}$$ In this way, we have introduced $\\underline{\\mathbf{m}} _{Ai}$, where $z _i^A = -\\dfrac{d}{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}}$ represents the depth. In other words, by using the two equations of $\\mathbf{U} _i^A$, we have replaced $\\mathbf{U} _i^A$, thus obtaining the depth $z _i^A$. However, this still does not solve the problem $\\Rightarrow$ that is to say, having only the equation related to $\\underline{\\mathbf{m}} _{Ai}$ is not enough; we also need to approach from $\\underline{\\mathbf{m}} _{Bi}$.\n​\t3.\tNext, We Find the Point $\\underline{\\mathbf{m}} _{Bi}$ in Coordinate Frame $B$\nStarting from the rigid transformation formula $\\mathbf{U}^w = \\mathbf{R} _{wc} \\cdot \\mathbf{U}^c + \\mathbf{T} _{wc}$, we can see that projecting from $c$ to $w$ only requires transforming $\\mathbf{U}^c$. In other words, to obtain $\\underline{\\mathbf{m}} _{Bi}$, we only need to perform a rigid transformation on $\\underline{\\mathbf{m}} _{Ai}$.\n$$\\underline{\\mathbf{m}} _{B,i} = \\Pi \\left( \\mathbf{R} _{BA} \\mathbf{U} _i^A + \\mathbf{t} _{BA} \\right)$$ where $\\Pi(\\cdot)$ is the projection function.\n$$\\underline{\\mathbf{m}} _{B,i}= \\Pi \\left( \\mathbf{R} _{BA} \\left( -\\dfrac{d}{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}} \\right) \\cdot \\underline{\\mathbf{m}} _{A,i} + \\mathbf{t} _{BA} \\right)$$ Multiply both sides of the above equation by $-\\dfrac{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}}{d}$:\n$$\\underline{\\mathbf{m}} _{B,i}= \\Pi \\left( \\mathbf{R} _{BA} \\cdot \\underline{\\mathbf{m}} _{A,i} - \\dfrac{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}}{d} \\cdot \\mathbf{t} _{BA} \\right)$$ $$\\underline{\\mathbf{m}} _{B,i} = \\Pi \\left( \\left( \\mathbf{R} _{BA} - \\dfrac{\\mathbf{t} _{BA} \\cdot \\mathbf{n} _A^T}{d} \\right) \\cdot \\underline{\\mathbf{m}} _{A,i} \\right)$$ This establishes the correspondence between point $A$ and point $B$ on their respective normalized planes.\nQuestion: In the above formula, why does multiplying both sides by $-\\dfrac{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}}{d}$ not change the equation?\nThe projection function $\\Pi(\\cdot)$ is a scale-invariant operation (it only considers direction and relative position, not absolute scale). Therefore, even if we multiply the right side by $-\\dfrac{\\mathbf{n} _A^T \\cdot \\underline{\\mathbf{m}} _{A,i}}{d}$, it does not affect the condition for the equality to hold because the projection result remains the same.\n2.2.3 Finding the Correspondence Between $\\underline{\\mathbf{P}} _{A,i}$ and $\\underline{\\mathbf{P}} _{B,i}$ We know:\n$$\\left\\{ \\begin{aligned} \\underline{\\mathbf{m}} _{A,i} = K _A^{-1} \\cdot \\underline{\\mathbf{P}} _{A,i}\\\\ \\underline{\\mathbf{m}} _{B,i} = K _B^{-1} \\cdot \\underline{\\mathbf{P}} _{B,i} \\end{aligned} \\right.$$ $\\underline{\\mathbf{P}} _{B,i} = K _B \\cdot \\underline{\\mathbf{m}} _{B,i} \\Rightarrow$ Substitute the obtained $\\underline{\\mathbf{m}} _{B,i}$:\n$$\\underline{\\mathbf{P}} _{B,i} = K _B \\cdot \\Pi \\left( \\left( \\mathbf{R} _{BA} - \\dfrac{\\mathbf{t} _{BA} \\cdot \\mathbf{n} _A^T}{d} \\right) \\cdot \\underline{\\mathbf{m}} _{A,i} \\right)$$ $$\\underline{\\mathbf{P}} _{B,i} = K _B \\cdot \\Pi \\left( \\left( \\mathbf{R} _{BA} - \\dfrac{\\mathbf{t} _{BA} \\cdot \\mathbf{n} _A^T}{d} \\right) \\cdot K _A^{-1} \\cdot \\underline{\\mathbf{P}} _{A,i} \\right)$$ Recall the property:\n$$K \\cdot \\Pi \\left( \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} \\right) = \\Pi \\left( K \\cdot \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} \\right)$$ Using this property, we get:\n$$\\underline{\\mathbf{P}} _{B,i} = \\Pi \\left( K _B \\cdot \\left( \\mathbf{R} _{BA} - \\dfrac{\\mathbf{t} _{BA} \\cdot \\mathbf{n} _A^T}{d} \\right) \\cdot K _A^{-1} \\cdot \\underline{\\mathbf{P}} _{A,i}\\right)$$ 2.2.4 Obtaining the Homography Matrix $\\mathbf{H} _{AB}$ Assume:\n$$\\mathbf{H} _{AB} = K _B \\cdot \\left( \\mathbf{R} _{BA} - \\dfrac{\\mathbf{t} _{BA} \\cdot \\mathbf{n} _A^T}{d} \\right) \\cdot K _A^{-1}$$\nTherefore:\n$$\\left\\{ \\begin{aligned} \u0026\\underline{\\mathbf{P}} _{B,i} = \\Pi \\left( \\mathbf{H} _{BA} \\cdot \\underline{\\mathbf{P}} _{A,i} \\right) \\quad \\quad A \\Rightarrow B\\\\ \u0026\\underline{\\mathbf{P}} _{A,i} = \\Pi \\left( \\mathbf{H} _{BA}^{-1} \\cdot \\underline{\\mathbf{P}} _{B,i} \\right) = \\Pi \\left( \\mathbf{H} _{AB} \\cdot \\underline{\\mathbf{P}} _{B,i} \\right) \\quad \\quad B \\Rightarrow A \\\\ \\end{aligned} \\right.$$ Through the homography matrix, we can transform a point from one camera’s image coordinate system to another camera’s image coordinate system, establishing a point mapping relationship.\n2.2.5 Estimating and Solving the Homography Matrix $$\\mathbf{H} _{AB} = \\begin{bmatrix} h _1 \u0026 h _4 \u0026 h _7 \\\\ h _2 \u0026 h _5 \u0026 h _8 \\\\ h _3 \u0026 h _6 \u0026 h _9 \\end{bmatrix}$$ This is a homogeneous matrix with 9 parameters $h _1$ to $h _9$. Homogeneous matrices have redundancy in scale, leading to a loss of degrees of freedom.\nSimple Solution – Parameterization (Parameters to Estimate = Free Parameters) $$\\mathbf{H} _{AB} = \\begin{bmatrix} h _1 \u0026 h _4 \u0026 h _7 \\\\ h _2 \u0026 h _5 \u0026 h _8 \\\\ h _3 \u0026 h _6 \u0026 1 \\end{bmatrix}$$ $$\\mathbf{h} = \\begin{bmatrix} h _1 \\\\ \\vdots \\\\ h _8 \\end{bmatrix}$$ How to Estimate $\\mathbf{h}$?\nIn this case, as long as we know one corresponding point, we can determine $h _1$ to $h _8$. $$\\underline{\\mathbf{P}} _{A,i} = \\Pi \\left( \\begin{bmatrix} h _1 \u0026 h _4 \u0026 h _7 \\\\ h _2 \u0026 h _5 \u0026 h _8 \\\\ h _3 \u0026 h _6 \u0026 1 \\end{bmatrix} \\cdot \\underline{\\mathbf{P}} _{B,i} \\right)$$ Since $\\underline{\\mathbf{P}} _{A,i}$ and $\\underline{\\mathbf{P}} _{B,i}$ are homogeneous coordinates, we expand them:\n$$\\begin{bmatrix} P _{A,i,x} \\\\ P _{A,i,y} \\\\ 1 \\end{bmatrix} = \\Pi \\left( \\begin{bmatrix} h _1 \u0026 h _4 \u0026 h _7 \\\\ h _2 \u0026 h _5 \u0026 h _8 \\\\ h _3 \u0026 h _6 \u0026 1 \\end{bmatrix} \\cdot \\begin{bmatrix} P _{B,i,x} \\\\ P _{B,i,y} \\\\ 1 \\end{bmatrix} \\right)$$ $$\\left\\{ \\begin{aligned} P _{A,i,x} = \\dfrac{h _1 \\cdot P _{B,i,x} + h _4 \\cdot P _{B,i,y} + h _7}{h _3 \\cdot P _{B,i,x} + h _6 \\cdot P _{B,i,y} + 1} \\\\ P _{A,i,y} = \\dfrac{h _2 \\cdot P _{B,i,x} + h _5 \\cdot P _{B,i,y} + h _8}{h _3 \\cdot P _{B,i,x} + h _6 \\cdot P _{B,i,y} + 1} \\end{aligned} \\right.$$ $$\\left\\{ \\begin{aligned} P _{A,i,x} \\cdot \\left( h _3 \\cdot P _{B,i,x} + h _6 \\cdot P _{B,i,y} + 1 \\right) = h _1 \\cdot P _{B,i,x} + h _4 \\cdot P _{B,i,y} + h _7 \\\\ P _{A,i,y} \\cdot \\left( h _3 \\cdot P _{B,i,x} + h _6 \\cdot P _{B,i,y} + 1 \\right) = h _2 \\cdot P _{B,i,x} + h _5 \\cdot P _{B,i,y} + h _8 \\end{aligned} \\right.$$ $$\\begin{bmatrix} P _{B,i,x} \u0026 0 \u0026 -P _{A,i,x} \\cdot P _{B,i,x} \u0026 P _{B,i,y} \u0026 0 \u0026 -P _{A,i,x} \\cdot P _{B,i,y} \u0026 1 \u0026 0 \\\\ 0 \u0026 P _{B,i,x} \u0026 -P _{A,i,y} \\cdot P _{B,i,x} \u0026 0 \u0026 P _{B,i,y} \u0026 -P _{A,i,y} \\cdot P _{B,i,y} \u0026 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} h _1 \\\\ h _2 \\\\ h _3 \\\\ h _4 \\\\ h _5 \\\\ h _6 \\\\ h _7 \\\\ h _8 \\end{bmatrix} = \\begin{bmatrix} P _{A,i,x} \\\\ P _{A,i _y} \\end{bmatrix}$$ Since there are 8 unknowns, we need eight independent linear equations. Each pair of corresponding points provides two corresponding equations (i.e., equations 59), so at least four pairs of corresponding points are required. That is, four matching pairs $\\left( P _{A,i}, P _{B,i} \\right) \\quad i = 1, 2, 3, 4$ are needed.\n$\\Rightarrow \\mathbf{h}^* = \\arg\\min _{\\mathbf{h}} \\sum _{i=1}^{4} \\left\\lVert M _i \\mathbf{h} - P _{A,i} \\right\\rVert _2^2 \\Rightarrow$ Linear Least Squares\n3. Robust Homography Estimation Using the RANSAC Algorithm 3.1 Objective Image Alignment and Stitching: Achieve automatic image stitching by estimating the homography between two images. 3.2 Automatically Establishing Correspondences — SIFT Algorithm Interest Point Detection\nUse algorithms like SIFT to detect feature points in both images (this code is provided by the instructor), eliminating the need to manually label corresponding points and utilizing algorithms to automatically establish correspondences between images.\nTherefore, we can find the most similar point pairs in both images. However, note that the point pairs may not correspond correctly.\nThat is, there may be incorrect matches (outliers). In such cases, we cannot directly use the correspondences. Instead, we will use another algorithm called RANSAC to automatically assess the correctness of corresponding points and obtain the most optimal $H$ matrix to output.\n3.3 Robust Estimation Using the RANSAC Algorithm ​\t1.\tAlgorithm Concept:\nRandom Sample Consensus (RANSAC) is a robust algorithm for estimating model parameters ($H$) in the presence of outliers (incorrect points).\nIt repeatedly performs random sampling to find the best-fitting model.\n​\t2.\tRANSAC Procedure:\nRepeat $N$ times (The number of iterations is determined based on experience or computation):\n​\t1.\tRandomly Select 4 Pairs of Matching Points:\n4 is the minimum number of matching points required to estimate the homography matrix.\nRandomly select four from all matching points. Since it is uncertain which correspondences are correct, a subsequent estimation and evaluation criterion (Euclidean distance) is needed.\n​\t2.\tEstimate the Homography Matrix $H^k$:\nUse the selected 4 pairs of matching points and the $DLT$ algorithm (done in the previous experiment, its purpose and function are to estimate the homography matrix given known corresponding points) to estimate the homography matrix. ​\t3.\tCompute Errors and Evaluate the Model:\nFor all matching points (including those not selected), transform the second image’s point $P _{B _i}$ using the estimated $H^k$, i.e., $H^k P _{B _i}$.\nCalculate the Euclidean distance between the transformed point (estimated point) and the actual point $P _{A _i}$ in the first image.\nDefine the Cost Function: Use a binary kernel function $\\phi _c(d)$ (either 0 or 1):\nWhen the distance $d \u0026lt; \\tau$, consider the match correct, and the cost is 0.\nWhen the distance $d \\geq \\tau$, consider the match incorrect, and the cost is 1.\nTotal Cost: $L^k = \\sum _{i} \\phi _c(|P _{A _i} - H^k P _{B _i}|)$\n​\t4.\tUpdate the Best Model:\nIf the current cost $L^k$ is less than the previous minimum cost $L$, update $L$ and the corresponding $H$.\nFinal Output:\nThe homography matrix $H$ with the minimum cost.\n​\t3.\tSelection of Threshold $\\tau$:\n$\\tau$ is the distance threshold to determine whether a match is an inlier. It is usually chosen based on image resolution and matching accuracy, generally between $0.5$ to $3$ pixels.\nChoosing a too large $\\tau$ increases incorrect matches, while a too small $\\tau$ may ignore correct matches.\n3.4 Why Not Use Traditional Quadratic Cost Functions Sensitivity Issues:\nQuadratic cost functions (such as least squares) are very sensitive to outliers. If a point has a large error, it will cause the cost function value to be excessively large, making the errors of other points irrelevant.\nRobustness:\nBinary kernel functions are insensitive to those extremely large or outlying points (all equal to 1), effectively suppressing the influence of outliers and making the estimation result more robust.\nOther Kernel Functions:\nBesides binary kernel functions, there are other robust kernel functions like the $Huber$ kernel and $Lorentzian$ kernel, which can balance error magnitude and robustness to some extent.\n3.5 Limitations of the RANSAC Algorithm Influence of the Number of Parameters:\nAs the number of model parameters increases, the required number of random samples grows exponentially, significantly increasing computational cost.\nApplicable Range:\nRANSAC is suitable for cases with a small number of parameters, such as line fitting, fundamental matrix estimation, and homography estimation.\n4. Epipolar Geometry in Stereo Vision\nSo far, we have studied the case of planar scenes and used homography to describe the relationship between two views. However, for general three-dimensional scenes, the planar assumption no longer holds. To address this, we introduce epipolar geometry.\n4.1 Epipolar Geometry\nEpipolar geometry can be well explained through a schematic diagram:\n​\t1.\tConsider Two Cameras Located in Reference Frames 1 and 2 Respectively\nThe optical center of Camera 1 is $O_1$, and the optical center of Camera 2 is $O_2$. A point $U$ in space is projected onto the image planes of both cameras, resulting in points $\\underline{m}_1$ and $\\underline{m}_2$.\n​\t2.\tProblem Description:\nIn general cases, we cannot make any assumptions about point $U$ (unlike the previous planar scene).\nWe need to find a method to establish a relationship between $\\underline{m}_1$ and $\\underline{m}_2$ without knowing $U$.\n4.2 Epipolar Plane and Epipolar Lines\n​\t1.\tEpipolar Plane\n$U$ and the optical centers $O_1$, $O_2$ define a plane $\\Rightarrow$ Points $m_1$, $m_2$, $O_1$, $O_2$ are coplanar $\\Rightarrow$ This plane is called the epipolar plane.\nEpipolar Constraint = Coplanarity, meaning $\\underline{m}_1$, $\\underline{m}_2$, $O_1$, $O_2$ are coplanar.\nIn stereo vision, the fundamental matrix $F$ and the essential matrix $E$ both rely on the coplanarity condition for their computation.\n​\t2.\tEpipolar Lines\nThe epipolar plane intersects the image planes of the two cameras, resulting in epipolar lines $l_1$ and $l_2$ respectively.\n$m_2$ is the projection of the three-dimensional point $U$ onto the image plane of the second camera. However, according to the constraints of epipolar geometry, $m_2$ must lie on the epipolar line $l_2$.\n$\\Rightarrow$ Given the position of point $m_1$, the corresponding epipolar line $l_2$ can be determined using the fundamental matrix $F$: $l_2 = F \\cdot m_1$.\nThe fundamental matrix $F$ captures the relative pose and intrinsic parameters between the two cameras. This formula indicates that given point $m_1$, one can compute the epipolar line $l_2$ on which $m_2$ must lie.\n4.3 Epipolar Constraint\nObjective: Utilize the above geometric relationships to formalize the epipolar constraint and establish a mathematical relationship between $m_1$ and $m_2$.\nDefine Vectors:\n$$\\left\\{ \\begin{aligned} \u0026amp;\\mathbf{\\underline{m}_1} \\text{ is the vector from the optical center } O_1 \\text{ to the image point } \\underline{m}_1 \\quad \\overrightarrow{O_1 m_1}^{1} \\\n\u0026amp;\\mathbf{\\underline{m}_2} \\text{ is the vector from the optical center } O_2 \\text{ to the image point } \\underline{m}_2 \\quad \\overrightarrow{O_2 m_2}^{2} \\\n\u0026amp;\\mathbf{t_{12}} = \\overrightarrow{O_1 O_2}^{1} \\text{ is the translation vector between the two camera optical centers}\n\\end{aligned} \\right.$$\nDefine the Normal Vector of the Epipolar Plane:\n$$\\left\\{ \\begin{aligned} \u0026amp;\\text{In reference frame } 1, \\quad \\overrightarrow{\\mathbf{n}_1}^{1} = \\underline{\\mathbf{m}}_1 \\times \\mathbf{t} _{12} \\\n\u0026amp;\\text{In reference frame } 2, \\quad \\overrightarrow{\\mathbf{n}_2}^{2} = \\mathbf{R} _{21} \\overrightarrow{\\mathbf{n}_1}^{1}, \\text{ where } \\mathbf{R} \\text{ is the rotation matrix between the cameras}\n\\end{aligned} \\right.$$\nNote:\nHere, $\\times$ denotes the cross product operation between two vectors. The result of the cross product is a vector perpendicular to both vectors involved in the operation, with its direction determined by the right-hand rule and magnitude equal to the area of the parallelogram formed by the two vectors.\nCoordinate system transformations for the normal vector do not need to consider the translation component because unit normal vectors are not position coordinates. Direction vectors remain unchanged in magnitude during rotation and are unaffected by translation. In summary, normal vectors only consider the rotation matrix, while points need to consider both rotation and translation.\n$$\\overrightarrow{\\mathbf{n}_2}^{2} = \\mathbf{R} _{21} \\cdot \\overrightarrow{\\mathbf{n}_1}^{1} = \\mathbf{R} _{21} \\cdot \\left( \\underline{\\mathbf{m}}_1 \\times \\mathbf{t} _{12} \\right) = \\mathbf{R} _{21} \\cdot \\underline{\\mathbf{m}}_1 \\times \\mathbf{R} _{21} \\cdot \\mathbf{t} _{12}$$ Since we previously know that $\\mathbf{t} _{21} = \\mathbf{R}*{21} \\cdot \\mathbf{t} _{12}$, the above equation becomes\n$$\\overrightarrow{\\mathbf{n}_2}^{2} = \\mathbf{t} _{21} \\times \\left( \\mathbf{R} _{21} \\cdot \\underline{\\mathbf{m}}_1 \\right)$$ Recall Properties of Cross Product Operations:\n$$\\mathbf{a} \\times \\mathbf{b} = \\begin{bmatrix} a_x \\\\ a_y \\\\ a_z \\end{bmatrix} \\times \\begin{bmatrix} b_x \\\\ b_y \\\\ b_z \\end{bmatrix} = \\begin{bmatrix} a_y b_z - a_z b_y \\\\ a_z b_x - a_x b_z \\\\ a_x b_y - a_y b_x \\end{bmatrix} _{3 \\times 1} \\Rightarrow \\left[\\mathbf{a}\\right]_{\\times} = \\begin{bmatrix} 0 \u0026 -a_z \u0026 a_y \\\\ a_z \u0026 0 \u0026 -a_x \\\\ -a_y \u0026 a_x \u0026 0 \\end{bmatrix}$$ $$\\mathbf{a} \\times \\mathbf{b} = \\left[\\mathbf{a}\\right]_{\\times} \\mathbf{b} = \\begin{bmatrix} 0 \u0026 -a_z \u0026 a_y \\\\ a_z \u0026 0 \u0026 -a_x \\\\ -a_y \u0026 a_x \u0026 0 \\end{bmatrix} \\begin{bmatrix} b_x \\\\ b_y \\\\ b_z \\end{bmatrix}$$ Using the above property, we can see that the cross product operation can be transformed into matrix operations. Therefore, using the above property, we obtain:\n$$\\overrightarrow{\\mathbf{n}_2}^{2} = \\mathbf{t} _{21} \\times \\left( \\mathbf{R} _{21} \\cdot \\underline{\\mathbf{m}}_1 \\right) = \\left[ \\mathbf{t} _{21} \\right]_{\\times} \\cdot \\mathbf{R} _{21} \\cdot \\underline{\\mathbf{m}}_1$$ Because $\\overrightarrow{\\mathbf{n}_2}^{2}$ is the normal vector of $\\mathbf{m}_2$, we have\n$\\Rightarrow \\mathbf{m}_2^T \\cdot \\overrightarrow{\\mathbf{n}_2}^{2} = 0$\n$$\\mathbf{m}_2^T \\cdot \\left[ \\mathbf{t} _{21} \\right]_{\\times} \\cdot \\mathbf{R} _{21} \\cdot \\underline{\\mathbf{m}}_1 = 0$$ $$\\mathbf{m}_2^T \\cdot \\left( \\left[ \\mathbf{t} _{21} \\right]_{\\times} \\cdot \\mathbf{R} _{21} \\right) \\cdot \\underline{\\mathbf{m}}_1 = 0$$ 4.4 Essential Matrix (Matrice Essentielle)\n​\t1.\tFormula\nAssume\n$$\\mathbf{E} _{21} = \\left[ \\mathbf{t} _{21} \\right]_{\\times} \\cdot \\mathbf{R} _{21} \\quad \\Rightarrow \\quad \\text{essential matrix}$$ It contains information about the relative rotation $\\mathbf{R}$ and translation $\\mathbf{t}$ between the two cameras.\nThe original equation becomes $ \\underline{\\mathbf{m}}*2^T \\cdot \\mathbf{E} _{21} \\cdot \\underline{\\mathbf{m}}_1 = 0 $\n​\t2.\tDegrees of Freedom\n$$ 5 \\text{ degrees of freedom} \\ \\downarrow\\ 5 \\text{ DoF} \\left( \\begin{array}{c} 3 , \\mathbf{R} _{21} \\quad \\text{rotation} \\ \\quad 2 , \\mathbf{t} _{21} \\quad \\text{translation} \\end{array} \\right)\\ \\downarrow\\ \\quad \\quad | \\mathbf{t} _{21} |_2 \\quad \\text{ unknown}\n$$\nDegrees of Freedom:\n$$\\left\\{ \\begin{aligned} \u0026amp;\\text{The rotation matrix } \\mathbf{R} \\text{ has 3 degrees of freedom} \\\n\u0026amp;\\text{The translation vector } \\mathbf{t} \\text{ has 2 degrees of freedom (since the scale is unknown)} \\\n\u0026amp;\\text{Therefore, } \\mathbf{E} \\text{ has 5 degrees of freedom}\n\\end{aligned} \\right.$$\nDegrees of Freedom (DoF) refer to the number of independent parameters required to describe the essential matrix. In geometry and linear algebra, DoF reflects the number of independent directions or ways a system can vary without constraints.\nThe rotation matrix has 3 degrees of freedom, describing rotation in three-dimensional space.\nThe translation vector theoretically has 3 degrees of freedom in three-dimensional space. However, in the essential matrix, the translation vector typically only considers direction, ignoring magnitude (unknown scale), thus leaving the translation vector with only 2 effective degrees of freedom, describing the direction of translation.\n4.5 Fundamental Matrix (Matrix Fundamental)\nContinuing the transformation of the above formula:\n$$\\underline{\\mathbf{m}}_2^T \\cdot \\mathbf{E} _{21} \\cdot \\underline{\\mathbf{m}}_1 = 0$$ Given:\n$$\\left\\{ \\begin{aligned} \\underline{\\mathbf{m}}_2 = K^{-1} \\cdot \\underline{\\mathbf{P}}_2 \\\n\\underline{\\mathbf{m}}_1 = K^{-1} \\cdot \\underline{\\mathbf{P}}_1\n\\end{aligned} \\right.$$\n$$\\underline{\\mathbf{P}}_2^T \\cdot (K^{-1})^T \\cdot \\mathbf{E} _{21} \\cdot K^{-1} \\cdot \\underline{\\mathbf{P}}_1 = 0$$ When the camera intrinsics are unknown or not considered, we introduce a fundamental matrix $\\mathbf{F}$ to encapsulate $K$.\nAssume $\\mathbf{F} _{21} = (K^{-1})^T \\cdot \\mathbf{E} _{21} \\cdot K^{-1}$\n$$\\mathbf{F} _{21} : \\text{ fundamental matrix} \\quad \\Rightarrow \\quad 7 \\text{ DoF}\\quad \\left\\{ \\begin{aligned} \u0026amp; \\text{- homogeneous matrix} \\\n\u0026amp; \\text{- rank}(\\mathbf{F} _{21}) = 2 \\quad \\Rightarrow \\quad \\det(\\mathbf{F} _{21}) = 0\n\\end{aligned} \\right.$$\nProperties:\n$$\\left\\{ \\begin{aligned} \u0026amp;\\text{Homogeneous: The fundamental matrix } \\mathbf{F} \\text{ is a homogeneous matrix, and it can be scaled by any non-zero scalar without changing its properties} \\\n\u0026amp;\\text{Rank Constraint:} \\mathbf{F} \\text{ has rank } 2\n\\end{aligned} \\right.$$\nThe original equation becomes $ \\underline{\\mathbf{P}}*2^T \\cdot \\mathbf{F} _{21} \\cdot \\underline{\\mathbf{P}}_1 = 0 $\n$$\\text{Let:} \\quad \\mathbf{L}_2 = \\mathbf{F} _{21} \\cdot \\underline{\\mathbf{P}}_1 = \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix}$$ $$\\underline{\\mathbf{P}}_2^T \\cdot \\mathbf{L}_2 = 0 \\quad \\Leftrightarrow \\quad a P_{2,x} + b P_{2,y} + c = 0$$ This is the equation of a line on Camera 2’s image plane $\\Rightarrow$ Epipolar Line\n4.6 Estimation of Essential and Fundamental Matrices\nCamera Calibrated $\\Rightarrow$ Estimate the essential matrix $\\mathbf{E}$ (5 degrees of freedom) $\\Rightarrow$ 5-point correspondence algorithm\nCamera Uncalibrated $\\Rightarrow$ Estimate the fundamental matrix $\\mathbf{F}$ (7 degrees of freedom) $\\Rightarrow$ 7-point correspondence algorithm\nSolution $\\Rightarrow$ 8-point correspondence algorithm $\\Rightarrow$ Intentionally ignoring the constraint $\\det(\\mathbf{F}) = 0$\n4.7 Algorithm\nSteps of the 8-Point Correspondence Algorithm:\n​\t1.\tCollect Corresponding Point Pairs:\nAlthough $\\mathbf{F}$ has 7 degrees of freedom, the algorithm ignores the rank-2 constraint. Therefore, at least 8 pairs of corresponding points are required to estimate $\\mathbf{F}$.\n​\t2.\tConstruct a Linear System of Equations\nFor each pair of corresponding points $(\\mathbf{m}_1, \\mathbf{m}_2)$, construct the equation:\n$$\\underline{\\mathbf{m}}_2^T \\cdot \\mathbf{E} _{21} \\cdot \\underline{\\mathbf{m}}_1 = 0$$ $$\\underline{\\mathbf{P}}_2^T \\cdot \\mathbf{F} _{21} \\cdot \\underline{\\mathbf{P}}_1 = 0$$ ​\t3.\tSolve:\nRepresent the system of equations as: $\\underline{\\mathbf{P}}_2^T \\cdot \\mathbf{L}_2 = 0$\n​\t4.\tRANSAC Algorithm Steps\nHandle outliers (incorrect matches) in the set of corresponding points and robustly estimate $\\mathbf{F}$.\nRandom Sampling: Use the 8-point correspondence algorithm to estimate $\\mathbf{F}$.\nModel Evaluation: Use the estimated $\\mathbf{F}$ to calculate the epipolar constraint error for all corresponding point pairs, i.e., the distance from each point to its corresponding epipolar line.\nDetermine Inliers: Based on a set distance threshold, determine which corresponding points are inliers.\nIteration: Repeat the above process until the model with the highest number of inliers is found.\n5. Bundle Adjustment\nBundle adjustment is a technique that simultaneously optimizes camera parameters (including position, orientation, and intrinsic parameters) and the positions of three-dimensional points in the scene.\nIts core idea is to make the optimized model more consistent with actual observations by minimizing the re-projection error of three-dimensional points onto the images.\nRemember these five words: Minimize Re-projection Error\n5.1 Case of Two Cameras\n5.1.1 Data\n$$\\left( P_{A,i}, P_{B,i} \\right) _{i=1,\\dots,N} \\implies N \\text{ correspondences}$$\n5.1.2 Parameters to Estimate\nCamera poses and the three-dimensional point cloud data set.\n$$\\mathbf{R} _{W1} \\quad \\mathbf{t} _{W1} \\quad \\mathbf{R} _{W2} \\quad \\mathbf{t} _{W2} \\quad \\left\\{\\mathbf{U}^w_i \\right\\} _{i=1,\\dots,N}$$ 5.1.3 Loss Function\n$$\\mathcal{L} \\left( \\mathbf{R} _{w1}, \\mathbf{t} _{w1}, \\mathbf{R} _{w2}, \\mathbf{t} _{w2}, \\left\\{ \\mathbf{U}^w_i \\right\\} _{i=1,\\dots,N} \\right) = \\sum_{i=1}^{N} \\left( \\left\\lVert P_{1,i} - K_1 \\Pi \\left( \\mathbf{R} _{w1}^T \\mathbf{U}_i^{w} - \\mathbf{R} _{w1}^T \\mathbf{t} _{w1} \\right) \\right\\rVert_2^2 + \\left\\lVert P_{2,i} - K_2 \\Pi \\left( \\mathbf{R} _{w2}^T \\mathbf{U}_i^{w} - \\mathbf{R} _{w2}^T \\mathbf{t} _{w2} \\right) \\right\\rVert_2^2 \\right)$$ Where:\n$K_A$ and $K_B$ are the intrinsic matrices of cameras $A$ and $B$, respectively.\n$\\Pi(\\cdot)$ is the projection function that projects three-dimensional points onto a two-dimensional plane.\n$\\mathbf{R} _{w1}^T$ and $\\mathbf{R} _{w2}^T$ are equivalent to $\\mathbf{R} _{1w}$ and $\\mathbf{R} _{2w}$, which transform points from the world coordinate system to the camera coordinate system.\n$\\mathbf{R} _{w1}^T \\mathbf{t} _{w1}$ is equivalent to $\\mathbf{t} _{1w}$, representing the translation vector.\n$\\mathbf{U}_i^{1} = \\mathbf{R} _{w1}^T \\cdot \\mathbf{U}_i^{w} - \\mathbf{R} _{w1}^T \\cdot \\mathbf{t} _{w1}$, which transforms $\\mathbf{U}_i^{w}$ to $\\mathbf{U}_i^{1}$, i.e., from the world coordinate system to the camera coordinate system.\nDifference: The image coordinates in camera $A$ or $B$ (actual) minus the estimated image coordinates obtained through three-dimensional space rotation and transformation equals the re-projection error.\n5.2 Case of Multiple Cameras\n5.2.1 Data\nDetected points in each image are:\n$$\\left\\{ \\left\\{ P_{m,i} \\right\\} _{i=1,\\dots,N_m} \\right\\} _{m=1,\\dots,M}$$ These points form tracks across different viewpoints.\nPoints detected by the $m$-th camera, where $N_m$ is the number of points detected by the $m$-th camera.\n$$\\left\\{ \\text{p2d-id}_m, \\ \\text{p3d-id}_m \\right\\} _{m=1,\\dots,M}$$ Where:\n$\\text{p2d-id}_m$ is the index of the two-dimensional point in the image.\n$\\text{p3d-id}_m$ is the index of the corresponding three-dimensional point in the point cloud.\nBoth have dimensions of $C_m \\times 1$.\n5.2.2 Parameters to Estimate\nCamera Extrinsics: $$ \\left\\{ \\left( \\mathbf{R} _{wm}, \\mathbf{t} _{wm} \\right) \\right\\} _{m=1,\\dots,M} $$ Positions of Three-Dimensional Points: $$ \\left\\{ \\mathbf{U}_i^{w} \\right\\} _{i=1,\\dots,N} $$ 5.2.3 Loss Function\nThe cost function extends to calculate errors across all cameras and all detected points, minimizing the distance between projected points and actual observed points:\n$$\\mathcal{L}(x) = \\sum_{m=1}^{M} \\sum_{c=1}^{C_m} \\left\\| P_{m,\\ \\text{p2d-id}_m(c)} - K_m \\Pi \\left( \\mathbf{R} _{wm}^\\top \\mathbf{U} _{\\text{p3d-id}_m(c)}^{w} - \\mathbf{R} _{wm}^\\top \\mathbf{t} _{wm} \\right) \\right\\|_2^2$$ $C_m$ is the number of observations for the $m$-th camera.\n$\\mathbf{U} _{\\text{p3d-id}_m(c)}^{w}$ is the three-dimensional point corresponding to the observation.\nWe can simply simplify the above cost function to:\n$$\\mathcal{L}(x) = \\sum_{i=1}^{N} \\left\\| f_i(x) \\right\\|_2^2 \\quad \\left\\{ \\begin{array}{l} x \\in \\mathbb{R}^D \\\\ f_i : \\mathbb{R}^D \\rightarrow \\mathbb{R}^B \\end{array} \\right.$$ $x$ represents all parameters to be optimized (camera parameters and three-dimensional point coordinates).\n$f_i(x)$ is the $i$-th residual function, representing the re-projection error of the $i$-th observation.\nOur goal is to find $x$ that minimizes $\\mathcal{L}(x)$. This is a non-linear least squares problem, typically solved using iterative methods.\n5.3 Gauss-Newton Algorithm\nAn iterative optimization algorithm used for non-linear least squares problems. $\\Rightarrow$ Iterative $\\quad \\delta_{k+1} = \\delta_k + d_k$ ​\t1.\tLinearization of $f_i$:\n$$f_i(x_k + d_k) \\approx f_i(x_k) + \\mathbf{J}_i(x_k) \\cdot d_k$$ $\\delta x$ is the increment of the parameters to be solved.\nFor each iteration, we perform a Taylor expansion of $f_i(x)$ around the current estimate $x_k$ and ignore higher-order terms.\n$f_i(x_k + d_k) \\in \\mathbb{R}^B$\n$f_i(x_k) \\in \\mathbb{R}^B$\n$\\mathbf{J}_i(x_k) \\in \\mathbb{R}^{B \\times D}$\n$d_k \\in \\mathbb{R}^D$\n​\t2.\tJacobian Matrix:\n$$\\mathbf{J}_i(x_k) = \\frac{\\partial f_i(x_k + d_k)}{\\partial d_k} \\bigg|_{d_k=0}$$ Represents the partial derivatives of the function $f_i$ with respect to $d_k$ at the point $x_k$.\nDescribes the linear rate of change of the function $f_i$ at the point $x_k$.\n​\t3.\tLinear Least Squares:\n$$ L_k(d_k) = \\sum_{i=1}^{N} \\left| f_i(x_k) + \\mathbf{J}_i(x_k) \\cdot d_k \\right|_2^2 $$\n$$\\quad \\mathbf{J}_k = \\begin{bmatrix}\n\\quad J_1(x_k) \\\n\\quad J_2(x_k) \\\n\\quad J_3(x_k) \\\n\\vdots \\\n\\quad J_N(x_k)\n\\end{bmatrix} \\quad \\mathbf{b}_k =\n\\begin{bmatrix}\n\\quad f_1(x_k) \\\n\\quad f_2(x_k) \\\n\\quad \\vdots \\\n\\quad f_N(x_k)\n\\end{bmatrix}$$\n$\\mathbf{b}_k$ is the combination of all residuals.\nThe linear least squares problem becomes:\n$$ L_k(d_k) = \\lVert \\mathbf{b}_k + \\mathbf{J}_k \\cdot d_k \\rVert_2^2\n$$\nBy minimizing $L_k(d_k)$, we obtain the linear system of equations:\n$$\\mathbf{J}_k^\\top \\cdot \\mathbf{J}_k \\cdot d_k = -\\mathbf{J}_k^\\top \\cdot \\mathbf{b}_k \\quad $$ Here, the left matrix $\\mathbf{J}_k^T \\mathbf{J}_k$ is an approximation of the Hessian matrix, and the right vector $-\\mathbf{J}_k^T \\mathbf{b}_k$ is the negative of the gradient.\nSolving this linear system yields the parameter update $d_k$.\n​\t4.\tLevenberg-Marquardt Algorithm\nIntroduces a damping factor $\\lambda$ to the Gauss-Newton algorithm, allowing the optimization process to exhibit the fast convergence of Gauss-Newton when close to the solution and the stability of gradient descent when far from the solution.\nCommonly used for iterative optimization in non-linear least squares problems.\nObjective Function:\n$$L_k(d_k) = \\lVert \\mathbf{b}_k + \\mathbf{J}_k d_k \\rVert_2^2 + \\lambda \\lVert d_k \\rVert_2^2 \\quad \\quad \\Rightarrow (J_k^T J_k + \\lambda I_k) d_k = -J_k^T b_k$$ $\\lambda$ is the damping factor. $$\\begin{cases} \\text{Si } \\lambda = 0 \u0026amp; \\Rightarrow \\text{Gauss-Newton} \\\n\\text{Si } \\lambda \\rightarrow +\\infty \u0026amp; \\Rightarrow \\lambda d_k \\rightarrow -J_k^T b_k \\quad \\text{descente de gradient}\n\\end{cases}$$\nIf the new cost function value decreases (indicating an effective update), reduce $\\lambda$ to make the algorithm closer to Gauss-Newton, accelerating convergence.\nIf the cost function value does not decrease, increase $\\lambda$ to make the algorithm closer to gradient descent, ensuring stability.\n5.4 Summary of Algorithm Steps\nIn practical applications, the steps of the Levenberg-Marquardt algorithm are as follows:\n​\t1.\tInitialization:\nSet initial parameters $x$ and damping factor $\\lambda$.\nCompute the initial cost function $L_{\\min}$.\n​\t2.\tIteration:\nCompute Jacobian Matrix $\\mathbf{J}$ and residuals $\\mathbf{b}$.\nSolve Linear System:\n$$ (J^T J + \\lambda I_d) d = -J^T b$$ Update Parameters: $$x' = x + d$$ Compute New Cost Function $L’$ ​\t3.\tEvaluate Update Effectiveness:\nIf $L’ \u0026lt; L_{\\min}$ (cost function decreases):\nAccept the update: $x = x’$, $L_{\\min} = L’$.\nDecrease $\\lambda$: $\\lambda = \\lambda / 2$.\nContinue iteration.\nOtherwise (cost function does not decrease):\nReject the update, do not change $x$.\nIncrease $\\lambda$: $\\lambda = 2\\lambda$.\nCheck if $\\lambda$ exceeds the maximum value; if so, stop iteration.\n​\t4.\tTermination Conditions:\nWhen $\\lambda$ exceeds a preset maximum value or the parameter updates become smaller than a threshold, stop iterating. All content in this document is theoretical and part of the ‘Vidéo 3D - Computer Vision’ course, taught by instructor Guillaume Bourmaud. All rights are reserved by the instructor.\nFor specific experimental content and complete code, please refer to Guillaume Bourmaud’s official website: https://gbourmaud.github.io/teaching/\n","permalink":"https://zehua716.github.io/posts/signal/video-3d/","summary":"In the field of computer vision within artificial intelligence, the subject focuses on theoretical topics including camera model calibration, homography estimation, epipolar geometry, bundle adjustment, etc., to achieve applications such as image calibration, stitching, and bundle calibration.","title":"3D Reconstruction Theory"},{"content":"All theoretical content is based on course notes, initially handwritten during class and later converted into electronic versions, with further translations and explanations added. As such, I claim only the labor involved, while all academic achievements belong to the supervising instructors. Each article includes acknowledgments of the supervising instructor and their personal website (if available).\nAll practical content consists of the Chinese versions of post-lab reports. The theoretical and coding aspects were primarily completed by me.\n","permalink":"https://zehua716.github.io/about/","summary":"\u003cp\u003eAll theoretical content is based on course notes, initially handwritten during class and later converted into electronic versions, with further translations and explanations added. As such, I claim only the labor involved, while all academic achievements belong to the supervising instructors. Each article includes acknowledgments of the supervising instructor and their personal website (if available).\u003c/p\u003e\n\u003cp\u003eAll practical content consists of the Chinese versions of post-lab reports. The theoretical and coding aspects were primarily completed by me.\u003c/p\u003e","title":""},{"content":"Go 语言学习笔记 Envoy 学习笔记 ","permalink":"https://zehua716.github.io/notes/","summary":"\u003ch2 id=\"go-语言学习笔记httpszhaohuabingcomlearning-golang\"\u003e\u003ca href=\"https://zhaohuabing.com/learning-golang\"\u003eGo 语言学习笔记\u003c/a\u003e\u003c/h2\u003e\n\u003ch2 id=\"envoy-学习笔记httpszhaohuabingcomlearning-envoy\"\u003e\u003ca href=\"https://zhaohuabing.com/learning-envoy\"\u003eEnvoy 学习笔记\u003c/a\u003e\u003c/h2\u003e","title":""}]