[{"content":"$$ U_i = U_1 + U_0 $$\n中文测试\n","permalink":"https://zehua716.github.io/posts/machinelearning/test/","summary":"summary","title":"tst title"},{"content":"这是关乎概率论的测试\n","permalink":"https://zehua716.github.io/posts/probability/test/","summary":"summary","title":"tst title"},{"content":"$$ U_i = U_1 + U_0 $$\n中文测试\n","permalink":"https://zehua716.github.io/posts/signal/test/","summary":"summary","title":"tst title"},{"content":"All theoretical content is based on course notes, initially handwritten during class and later converted into electronic versions, with further translations and explanations added. As such, I claim only the labor involved, while all academic achievements belong to the supervising instructors. Each article includes acknowledgments of the supervising instructor and their personal website (if available).\nAll practical content consists of the Chinese versions of post-lab reports. The theoretical and coding aspects were primarily completed by me.\n","permalink":"https://zehua716.github.io/about/","summary":"\u003cp\u003eAll theoretical content is based on course notes, initially handwritten during class and later converted into electronic versions, with further translations and explanations added. As such, I claim only the labor involved, while all academic achievements belong to the supervising instructors. Each article includes acknowledgments of the supervising instructor and their personal website (if available).\u003c/p\u003e\n\u003cp\u003eAll practical content consists of the Chinese versions of post-lab reports. The theoretical and coding aspects were primarily completed by me.\u003c/p\u003e","title":""},{"content":"Go 语言学习笔记 Envoy 学习笔记 ","permalink":"https://zehua716.github.io/notes/","summary":"\u003ch2 id=\"go-语言学习笔记httpszhaohuabingcomlearning-golang\"\u003e\u003ca href=\"https://zhaohuabing.com/learning-golang\"\u003eGo 语言学习笔记\u003c/a\u003e\u003c/h2\u003e\n\u003ch2 id=\"envoy-学习笔记httpszhaohuabingcomlearning-envoy\"\u003e\u003ca href=\"https://zhaohuabing.com/learning-envoy\"\u003eEnvoy 学习笔记\u003c/a\u003e\u003c/h2\u003e","title":""},{"content":"L\u0026rsquo;objectif de VAE est de maximiser $ P(x)$\nPour simplifier les calculs, prenez le logarithme $\\log P(X)$\n$$ \\log P(X) = \\log \\int P(X, Z) , dZ $$ En raison de la difficulté à résoudre, on introduite une distribution auxiliaire Q(Z|X) $$ \\log P(X) = \\log \\int P(X, Z) \\frac{Q(Z)}{Q(Z)} , dZ $$\n$$ \\log P(X) = \\log \\mathbb{E}_{Q(Z)} \\left[ \\frac{P(X, Z)}{Q(Z)} \\right] $$\nFaire passer $\\log $ à travers l\u0026rsquo;intégrale, à travers l\u0026rsquo;espérance:\nSelon l\u0026rsquo;inégalité de Jensen, pour une fonction convexe f(x) et une variable aléatoire X, on a : $$ f(\\mathbb{E}[X]) \\leq \\mathbb{E}[f(X)] $$ $\\log$ est une fonction concave, donc $$ \\log \\mathbb{E}[f(Z)] \\geq \\mathbb{E}[\\log f(Z)] $$\n$$ \\log P(X) = \\log \\mathbb{E}{Q(Z)}\\left[\\frac{P(X, Z)}{Q(Z)}\\right] \\geq \\mathbb{E}{Q(Z)}\\left[\\log \\frac{P(X, Z)}{Q(Z)}\\right] $$\nInférence variationnelle: $$ \\log P(X) = \\mathcal{L}(Q) + \\mathcal{D}(Q(Z) | P(Z|X)) $$\n$$ D_{KL}(Q(Z) | P(Z|X)) = \\mathbb{E}_{Q(Z)} \\left[ \\log \\frac{Q(Z)}{P(Z|X)} \\right] $$\nPreuve:: $$ \\begin{align*} \\log P(X) \u0026amp;= \\mathbb{E}{Q(Z)} \\log P(X) \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z)}{P(Z \\mid X)} \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z) Q(Z)}{P(Z \\mid X) Q(Z)} \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z)}{Q(Z)} + \\mathbb{E}{Q(Z)} \\log \\frac{Q(Z)}{P(Z \\mid X)} \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z)}{Q(Z)} + D\\big[Q(Z) | P(Z \\mid X)\\big]\\\n\u0026amp;= \\mathcal{L}(Q) + D_{KL}(Q(Z) | P(Z|X)) \\end{align*} $$\n","permalink":"https://zehua716.github.io/posts/signal_cn/%E6%89%93%E5%8D%B0%E5%90%8E%E5%88%A0%E9%99%A4/","summary":"\u003cp\u003eL\u0026rsquo;objectif de VAE est de maximiser $ P(x)$\u003c/p\u003e\n\u003cp\u003ePour simplifier les calculs, prenez le logarithme $\\log P(X)$\u003cbr\u003e\n$$\n\\log P(X) = \\log \\int P(X, Z) , dZ\n$$\nEn raison de la difficulté  à résoudre, on introduite une distribution auxiliaire Q(Z|X)\n$$\n\\log P(X) = \\log \\int P(X, Z) \\frac{Q(Z)}{Q(Z)} , dZ\n$$\u003c/p\u003e\n\u003cp\u003e$$\n\\log P(X) = \\log \\mathbb{E}_{Q(Z)} \\left[ \\frac{P(X, Z)}{Q(Z)} \\right]\n$$\u003c/p\u003e\n\u003cp\u003eFaire passer $\\log $ à travers l\u0026rsquo;intégrale, à travers l\u0026rsquo;espérance:\u003c/p\u003e","title":""},{"content":"第三次演讲内容\nVAE 的目标是通过最大化 $\\log P(X)$ 来优化模型。其中的log 是通常对概率取对数，是为了方便计算。因此， $\\log P(X)$表示观测数据的对数边际似然。\n直接计算 $\\log P(X)$ 通常非常复杂，因为积分 $\\int P(X, Z) dZ$ 可能没有解析解。 $$ \\log P(X) = \\log \\int P(X, Z) , dZ $$ $ P(X, Z)$ ：联合分布，表示数据 X 和隐变量 Z 的联合概率。\n因此，VAE 采用变分推断的方法，引入一个可近似的分布 Q(Z|X) 来辅助计算。 $$ \\log P(X) = \\log \\int P(X, Z) \\frac{Q(Z)}{Q(Z)} , dZ $$\n$$ \\log P(X) = \\log \\mathbb{E}_{Q(Z)} \\left[ \\frac{P(X, Z)}{Q(Z)} \\right] $$\n其中 $$ \\mathbb{E}_{Q(Z)} \\left[ \\frac{P(X, Z)}{Q(Z)} \\right] = \\int \\frac{P(X, Z)}{Q(Z)} Q(Z) , dZ $$ 其中$Q(Z)$是分布\t$ \\mathbb{E}{Q(Z)}[\\cdot]$ 表示对 Q(Z) 的期望。\n接下来，我们想利用 Jensen 不等式，将 $\\log $穿过积分、穿过期望。\nJensen 不等式是概率论和convexe函数理论中的一个重要工具。它的形式如下：\n​\t•\t定义：对于一个convexe函数 f(x)，任意随机变量 X，有： $$ f(\\mathbb{E}[X]) \\leq \\mathbb{E}[f(X)] $$ ​\t•\tconvexe函数 f(x) 的值在平均值点上$ f(\\mathbb{E}[X])$，总是小于或等于对所有 X 的 f(X) 的加权平均值$ \\mathbb{E}[f(X)]$。\n$\\log$ 是一个concave函数（对 $(0, \\infty) $范围来说），因此，Jensen 不等式应用到 $\\log$ 上需要改一下方向，因此有 $$ \\log \\mathbb{E}[f(Z)] \\geq \\mathbb{E}[\\log f(Z)] $$\n$$ \\log P(X) = \\log \\mathbb{E}{Q(Z)}\\left[\\frac{P(X, Z)}{Q(Z)}\\right] \\geq \\mathbb{E}{Q(Z)}\\left[\\log \\frac{P(X, Z)}{Q(Z)}\\right] $$\n采样方面\n我们不选择直接从 P(Z) 采样，而是从 Q(Z|X) 采样\n因为 P(Z) 是先验分布 是我们假设的一个分布，他可能和 数据 $ x$ 没有过多的关系，这种采样方法，可能效率低\n因此我们从辅助分布中采样，由于是由数据$ x$ 引导的分布，因此更加接近于真实后验分布 $ P(Z|X) $，这种采样方法更加高效\n最后是 变分推断（Variational Inference, VI）方面 $$ \\log P(X) = \\mathcal{L}(Q) + \\mathcal{D}(Q(Z) | P(Z|X)) $$ \\mathcal{L}(Q)：证据下界（Evidence Lower Bound, ELBO） $$ \\mathcal{L}(Q) = \\mathbb{E}{Q(Z)} \\left[ \\log \\frac{P(X, Z)}{Q(Z)} \\right] $$ \\mathcal{D}(Q(Z) | P(Z|X))：KL 散度，用来衡量近似分布 Q(Z) 和真实后验 P(Z|X) 的差异。当 Q(Z) = P(Z|X) 时，KL 散度为零，优化就完美达成。 $$ D{KL}(Q(Z) | P(Z|X)) = \\mathbb{E}_{Q(Z)} \\left[ \\log \\frac{Q(Z)}{P(Z|X)} \\right] $$ 因此，最大化 ELBO 等价于同时最小化 KL 散度和提升重建能力。\n所以其变分的思想就是，通过最大化 $\\mathcal{L}(Q_\\phi) $来逼近$ \\log P(X)$，并找到能最大化$\\mathcal{L}(Q) $的那个$\\phi$ 即，$\\max_\\phi \\mathcal{L}(Q)$ ，所以现在最大化ELBO\n我们重写上述公式 $$ \\begin{align*} \\log P(X) \u0026amp;= \\mathbb{E}{Q(Z)} \\log P(X) \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z)}{P(Z \\mid X)} \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z) Q(Z)}{P(Z \\mid X) Q(Z)} \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z)}{Q(Z)} + \\mathbb{E}{Q(Z)} \\log \\frac{Q(Z)}{P(Z \\mid X)} \\ \u0026amp;= \\mathbb{E}{Q(Z)} \\log \\frac{P(X, Z)}{Q(Z)} + D\\big[Q(Z) | P(Z \\mid X)\\big]\\\n\u0026amp;= \\mathcal{L}(Q) + D_{KL}(Q(Z) | P(Z|X)) \\end{align*} $$\nELBO=重建误差+正则项 ","permalink":"https://zehua716.github.io/posts/signal_cn/%E7%AC%AC%E4%B8%89%E6%AC%A1%E6%BC%94%E8%AE%B2%E5%86%85%E5%AE%B9/","summary":"\u003cp\u003e第三次演讲内容\u003c/p\u003e\n\u003cp\u003eVAE 的目标是通过最大化  $\\log P(X)$  来优化模型。其中的log 是通常对概率取对数，是为了方便计算。因此， $\\log P(X)$表示观测数据的对数边际似然。\u003c/p\u003e\n\u003cp\u003e直接计算  $\\log P(X)$ 通常非常复杂，因为积分 $\\int P(X, Z) dZ$ 可能没有解析解。\n$$\n\\log P(X) = \\log \\int P(X, Z) , dZ\n$$\n$ P(X, Z)$ ：联合分布，表示数据 X 和隐变量 Z 的联合概率。\u003c/p\u003e\n\u003cp\u003e因此，VAE 采用变分推断的方法，引入一个可近似的分布 Q(Z|X) 来辅助计算。\n$$\n\\log P(X) = \\log \\int P(X, Z) \\frac{Q(Z)}{Q(Z)} , dZ\n$$\u003c/p\u003e\n\u003cp\u003e$$\n\\log P(X) = \\log \\mathbb{E}_{Q(Z)} \\left[ \\frac{P(X, Z)}{Q(Z)} \\right]\n$$\u003c/p\u003e\n\u003cp\u003e其中\n$$\n\\mathbb{E}_{Q(Z)} \\left[ \\frac{P(X, Z)}{Q(Z)} \\right] = \\int \\frac{P(X, Z)}{Q(Z)} Q(Z) , dZ\n$$\n其中$Q(Z)$是分布\t $ \\mathbb{E}{Q(Z)}[\\cdot]$  表示对 Q(Z) 的期望。\u003c/p\u003e","title":""}]