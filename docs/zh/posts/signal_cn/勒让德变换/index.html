<!DOCTYPE html>
<html lang="zh" dir="ltr">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>勒让德变换与半二次优化方法 | 主页</title>
<meta name="keywords" content="信号处理, 正则化, 反问题, Optimisation">
<meta name="description" content="勒让德变换将一个函数映射为其凸共轭函数，广泛用于优化理论中。将其与半二次优化方法结合，推导了正则化分解和辅助变量的更新策略。">
<meta name="author" content="Zehua">
<link rel="canonical" href="http://zehua.eu/zh/posts/signal_cn/%E5%8B%92%E8%AE%A9%E5%BE%B7%E5%8F%98%E6%8D%A2/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.0aec493a8d0485b0d85dd4e2e2ea202a2a2954009c175e96830de67966b695f3.css" integrity="sha256-CuxJOo0EhbDYXdTi4uogKiopVACcF16Wgw3meWa2lfM=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://zehua.eu/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://zehua.eu/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://zehua.eu/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://zehua.eu/apple-touch-icon.png">
<link rel="mask-icon" href="http://zehua.eu/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="http://zehua.eu/zh/posts/signal_cn/%E5%8B%92%E8%AE%A9%E5%BE%B7%E5%8F%98%E6%8D%A2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
    integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
    integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
    crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    }); 
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel="stylesheet">

<meta property="og:title" content="勒让德变换与半二次优化方法" />
<meta property="og:description" content="勒让德变换将一个函数映射为其凸共轭函数，广泛用于优化理论中。将其与半二次优化方法结合，推导了正则化分解和辅助变量的更新策略。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://zehua.eu/zh/posts/signal_cn/%E5%8B%92%E8%AE%A9%E5%BE%B7%E5%8F%98%E6%8D%A2/" />
<meta property="og:image" content="http://zehua.eu/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-11-22T16:25:17+01:00" />
<meta property="article:modified_time" content="2024-12-08T17:12:35+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://zehua.eu/images/papermod-cover.png" />
<meta name="twitter:title" content="勒让德变换与半二次优化方法"/>
<meta name="twitter:description" content="勒让德变换将一个函数映射为其凸共轭函数，广泛用于优化理论中。将其与半二次优化方法结合，推导了正则化分解和辅助变量的更新策略。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://zehua.eu/zh/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "信号处理",
      "item": "http://zehua.eu/zh/posts/signal_cn/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "勒让德变换与半二次优化方法",
      "item": "http://zehua.eu/zh/posts/signal_cn/%E5%8B%92%E8%AE%A9%E5%BE%B7%E5%8F%98%E6%8D%A2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "勒让德变换与半二次优化方法",
  "name": "勒让德变换与半二次优化方法",
  "description": "勒让德变换将一个函数映射为其凸共轭函数，广泛用于优化理论中。将其与半二次优化方法结合，推导了正则化分解和辅助变量的更新策略。",
  "keywords": [
    "信号处理", "正则化", "反问题", "Optimisation"
  ],
  "articleBody": "勒让德变换 定义 勒让德变换（$Legendre$ Transform，$LT$）或称作凸共轭（$Convex$ $Conjugate$，$CC$）\n勒让德变换是凸分析中的一个基本工具，广泛用于优化理论中，它将一个函数 $f(x)$ 映射为另一个凸函数 $f^*(t)$\n在进行 $LT$ 之前，我们需要确保原函数 $f $ 满足以下两个条件:\n严格凸性（strictly convex）： 函数 $f(x)$ 是严格凸的。 可导性（differentiability）： 函数 $f(x)$ 至少一次可导（一般要二次导）。 因此通过 勒让德变换，我们就可以得到一个新的函数 $f^{*}$\n$$ f^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - f(x) \\big] $$ 其中，$\\sup$ 表示取上确界（$supremum$），也就是取$x t - f(x)$ 的最大值，因此我们可以得到: $$ x t - f(x) \\leq f^{*}(t) $$ 说明 $f^ *(t)$ 是所有 $x t - f(x)$ 的上界\n我们再将 $f(x)$ 移到右边，可得: $$ x t \\leq f^ *(t) + f(x) $$ 这体现了 $f^ *(t)$ 和 $f(x)$ 的对偶性\n性质 我们现在关注勒让德变换在函数的横向伸缩（$dilatation$）、平移（$shift$）、以及纵向平移和伸缩的情况下的性质变化\n(a) 横向伸缩 (Horizontal Dilatation):\n设 $\\gamma \u003e 0$ 是横向伸缩系数，定义一个新函数 $g(x)$ ： $$ g(x) = f(\\gamma x) $$ 对应的勒让德变换为：\n$$ g^*(t) = f^*\\left(\\frac{t}{\\gamma}\\right) $$ 横向缩放（乘以 $\\gamma$ ）会导致勒让德共轭中的自变量 $t$ 被缩放为 $\\frac{t}{\\gamma}$\n证明\n我们有: $$ g(x) = f(\\gamma x) $$ 目标是推导 $g^ *(t)$ 的表达式，根据勒让德变换的定义，我们可得：\n$$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - g(x) \\big] $$ 代入 $g(x) = f(\\gamma x)$： $$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - f(\\gamma x) \\big] $$\n我们给 $xt$ 这部分配项，乘 $\\gamma$ 除 $\\gamma$ ，可得 $$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\left[ \\frac{\\gamma x}{\\gamma} t - f(\\gamma x) \\right] $$\n将 $\\gamma x$ 保存好，得到 $f(\\gamma x)$ 的 $LT$ 变换 $g^ *(t)$ 等于:\n$$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\left[ \\gamma x \\cdot \\frac{t}{\\gamma} - f(\\gamma x) \\right] $$ 我们发现， $$ f^ *\\left(\\frac{t}{\\gamma}\\right) =\\sup_{u \\in \\mathbb{R}} \\bigg[ u \\cdot \\frac{t}{\\gamma} - f(u) \\bigg] $$ 不用管 $u$ 是什么，只要一样就可以了，所以我们对比两个形式，观察到 $ \\sup _{x \\in \\mathbb{R}} \\big[ \\gamma x \\cdot \\frac{t}{\\gamma} - f(\\gamma x) \\big]$ 正是函数 $f^ *\\left(\\frac{t}{\\gamma}\\right)$ 的定义，因此:\n$$ g^*(t) = f^*\\left(\\frac{t}{\\gamma}\\right) $$ 注意一点，$\\gamma \u003e 0$ 的条件是必要的，这是为了保证变换方向和凸性不改变。\n(b) 横向平移 (Horizontal Shift):\n设 $x_0 \\in \\mathbb{R}$ 是横向平移的位移量，定义： $$ g(x) = f(x - x_0) $$ 对应的勒让德变换为：\n$$ g^*(t) = f^*(t) + x_0 t $$ 对 $x$ 进行平移，相当于在勒让德共轭中增加一项线性修正 $x_0 t$ 。\n证明\n定义: $$ g(x) = f(x - x_0) $$ 目标是推导 $g^*(t)$ 的表达式，根据勒让德变换的定义：\n$$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - g(x) \\big] $$ $$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - f(x - x_0) \\big] $$\n换元，令 $$ u = x - x_0 $$ 因此 $$ x = u + x_0 $$ 并且当 $x \\in \\mathbb{R}$ 时，$u \\in \\mathbb{R}$（无约束变化范围）。将 $x = u + x_0$ 带入原式：\n$$ g^*(t) = \\sup_{u \\in \\mathbb{R}} \\big[ (u + x_0)t - f(u) \\big] $$ 展开括号： $$ g^*(t) = \\sup_{u \\in \\mathbb{R}} \\big[ u t + x_0 t - f(u) \\big] $$\n注意到 $x_0 t$ 是与 $u$ 无关的常数，因此可以从 $\\sup$ 中提取出来： $$ g^*(t) = \\sup_{u \\in \\mathbb{R}} \\big[ u t - f(u) \\big] + x_0 t $$\n我们注意到，其中的 $\\sup_{u \\in \\mathbb{R}} \\big[ u t - f(u) \\big]$ 就是 $f^ *(t)$ 的定义:\n$$ f^*(t) = \\sup_{u \\in \\mathbb{R}} \\big[ u t - f(u) \\big] $$ 因此可以得到：\n$$ g^*(t) = f^*(t) + x_0 t $$ 证毕\n(c) 纵向平移和伸缩 (Vertical Shift-Dilatation):\n设 $\\alpha \\in \\mathbb{R}$ 和 $\\beta \u003e 0$ ，定义新的函数 $g(x)$ ： $$ g(x) = \\alpha + \\beta f(x) $$ 对应的勒让德变换为：\n$$ g^*(t) = \\beta f^*\\left(\\frac{t}{\\beta}\\right) - \\alpha $$ 纵向伸缩 $\\beta$ 会缩放勒让德变换的自变量 $t$ ，并乘以 $\\beta$ 。纵向平移 $\\alpha$ 直接导致勒让德共轭函数的值减去 $\\alpha$\n证明\n$$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - g(x) \\big] $$ 其中:\n$$ g(x) = \\alpha + \\beta f(x) $$ 因此:\n$$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - (\\alpha + \\beta f(x)) \\big] = \\sup_{x \\in \\mathbb{R}} \\big[ x t - \\beta f(x) - \\alpha \\big] $$ 由于 $\\alpha$ 与 $x$ 无关:\n$$ g^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - \\beta f(x) \\big] - \\alpha $$ 将 $sup$ 里面表达式 乘 $\\beta$ 除 $\\beta$ ，可得:\n$$ g^*(t) = \\beta \\sup_{x \\in \\mathbb{R}} \\left[ \\frac{t}{\\beta} x - f(x) \\right] - \\alpha $$ 我们注意到 $\\sup_{x \\in \\mathbb{R}} \\left[ \\frac{t}{\\beta} x - f(x) \\right]$ 就是 $f^*\\left( \\frac{t}{\\beta} \\right)$ 的定义，即：\n$$ f^*\\left( \\frac{t}{\\beta} \\right) = \\sup_{x \\in \\mathbb{R}} \\left[ \\frac{t}{\\beta} x - f(x) \\right] $$ 得到：\n$$ g^*(t) = \\beta f^*\\left( \\frac{t}{\\beta} \\right) - \\alpha $$ 证毕\n举例 下面我们以一个二次函数为例，详细计算推导它的勒让德变换（$Legendre$ Transform, $LT$）\n$$ f(x) = \\alpha + \\frac{1}{2} \\beta (x - x_0)^2 $$ 其中：\n$\\alpha \\in \\mathbb{R}$ 是一个常数，表示垂直偏移； $\\beta \u003e 0$ 是参数，控制二次项的系数； $x_0$ 是偏移中心。 目标是找到其勒让德变换： $$ f^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - f(x) \\big] $$ 推导过程\n我们先看里面 $x t - f(x)$ 这一项，因此定义辅助函数： $$ g_t(x) = x t - f(x) $$ 将 $f(x)$ 代入得到： $$ g_t(x) = x t - \\left(\\alpha + \\frac{\\beta}{2}(x - x_0)^2 \\right) $$ 展开： $$ g_t(x) = x t - \\alpha - \\frac{\\beta}{2}(x - x_0)^2 $$ 所以，原式等于: $$ f^*(t) = \\sup_{x \\in \\mathbb{R}} \\big[x t - \\alpha - \\frac{\\beta}{2}(x - x_0)^2 \\big] $$ 我们希望再次基础上更进一步，也就是拿掉 $sup$ 符号。为了完成这一点，需要找到内层函数 $g_t(x)$ 的极大值。\n对 $g_t(x)$ 求导数并找到极值点\n计算 $g_t(x)$ 的一阶导数： $$ g_t^{\\prime}(x) = t - \\beta (x - x_0) $$ 令 $g_t^{\\prime}(x) = 0$ 解出极值点： $$ t - \\beta (\\bar{x} - x_0) = 0 \\quad \\implies \\quad \\bar{x} = x_0 + \\frac{t}{\\beta} $$ 计算 $g_t(x)$ 的二阶导数： $$ g_t^{\\prime\\prime}(x) = -\\beta $$ 由于 $\\beta \u003e 0$ ，说明 $g_t(x)$ 是一个严格concave函数，因此在 $\\bar{x}$ 处确实取得最大值。\n将极值点代回 $g_t(x)$\n将 $\\bar{x} = x_0 + \\frac{t}{\\beta}$ 代入 $g_t(x)$ ：\n$$ f^*(t) = g_t(\\bar{x}) = \\bar{x} t - f(\\bar{x}) $$ 具体代入：\n$$ f^*(t) = \\left(x_0 + \\frac{t}{\\beta} \\right) t - \\left(\\alpha + \\frac{\\beta}{2} \\left(x_0 + \\frac{t}{\\beta} - x_0 \\right)^2 \\right) $$ 展开化简：\n$$ f^*(t) = x_0 t + \\frac{t^2}{\\beta} - \\alpha - \\frac{\\beta}{2} \\cdot \\frac{t^2}{\\beta^2} $$ 进一步整理：\n$$ f^*(t) = x_0 t + \\frac{t^2}{2\\beta} - \\alpha $$ 最终结果： $$ f^*(t) = \\frac{1}{2\\beta} t^2 + t x_0 - \\alpha $$ 具体过程是：\n定义辅助函数 $g_t(x) = x t - f(x)$ 求导数 $g_t^{\\prime}(x) = t - f^{\\prime}(x)$ 找到零点 $\\bar{x} = \\chi(t)$ 代回 $g_t( \\bar{x})$ 得到 $f^*(t)$ 求导 勒让德变换通用表达式为： $$ f^*(t) = t \\chi(t) - f[\\chi(t)] $$ 其中： $\\chi(t)$ 是 $f^{\\prime}(x)$ 的反函数，即 $\\chi(t) = (f^{\\prime})^{-1}(t)$ 。\n一阶导数\n为了求 $f^ *(t)$ 的一阶导数，对 $f^ *(t)$ 进行求导：\n$$ f^{*\\prime}(t) = \\frac{\\partial}{\\partial t} \\big( t \\chi(t) - f[\\chi(t)] \\big) $$ 利用链式法则，得到：\n$$ f^{*\\prime}(t) = \\chi(t) + t \\chi^{\\prime}(t) - \\chi^{\\prime}(t) f^{\\prime}[\\chi(t)] $$ 由于 $\\chi(t) = f^{\\prime-1}(t)$ ，并且 $f^{\\prime}[\\chi(t)] = t$ ，代入后有：\n$$ f^{*\\prime}(t) = \\chi(t) $$ 因此，一阶导数结果为： $$ f^{*\\prime}(t) = \\chi(t) = f^{\\prime-1}(t) $$ 勒让德变换的二阶导数\n对 $f^ { *\\prime}(t) = \\chi(t)$ 再求导：\n$$ f^{*\\prime\\prime}(t) = \\chi^{\\prime}(t) $$ 由于 $\\chi(t) = f^{\\prime-1}(t)$ ，求导得到： $$ \\chi^{\\prime}(t) = \\frac{1}{f^{\\prime\\prime}[\\chi(t)]} $$ 因此，勒让德变换的二阶导数为：\n$$ f^{*\\prime\\prime}(t)= \\frac{1}{f^{\\prime\\prime}[\\chi(t)]} $$ 由于 $f^{\\prime\\prime}(x) \u003e 0$ （$f(x)$ 是严格凸函数），所以 $f^ {*\\prime\\prime}(t) \u003e 0$ ，从而证明 $f^ *(t)$ 始终是凸函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 clear; close all; clc; %% 参数设置 (用于勒让德变换及半二次分解示例) alpha = 1.0; % f(x)的垂直偏移 beta = 2.0; % f(x)中二次项系数 \u003e 0 x0 = 0.5; % f(x)中心偏移 % 定义原函数 f(x) f = @(x) alpha + (beta/2)*(x - x0).^2; % 理论勒让德共轭 f*(t) f_star_analytic = @(t) (t.^2)/(2*beta) + t*x0 - alpha; % 定义 t 和 x 的取值范围用于数值求解 t_vals = linspace(-5,5,200); x_vals = linspace(-5,5,200); %% 数值求勒让德变换 f*(t) f_star_numeric = zeros(size(t_vals)); for i = 1:length(t_vals) t = t_vals(i); g_t = @(x) x*t - f(x); neg_g_t = @(x) -g_t(x); [~, fval_neg] = fminbnd(neg_g_t, min(x_vals), max(x_vals)); f_star_numeric(i) = -fval_neg; end 1 2 3 4 5 6 7 8 %% 对比数值结果和解析解 figure; plot(t_vals, f_star_numeric, 'r', 'LineWidth',2); hold on; plot(t_vals, f_star_analytic(t_vals), 'b--', 'LineWidth',2); xlabel('t','Interpreter','none'); ylabel('f*(t)','Interpreter','none'); legend({'Numerical f*(t)','Analytical f*(t)'},'Interpreter','none','Location','best'); title('Legendre transform: numerical vs analytical','Interpreter','none'); 双重共轭恢复原函数 勒让德变换的一个关键性质，即双重共轭恢复原函数\n$$ f^{**}(x) = f(x) $$ 证明\n双重共轭函数定义为：\n$$ f^{**}(t) = \\sup_{x \\in \\mathbb{R}} \\big[ x t - f^*(x) \\big] $$ 定义辅助函数 $h_t(x)$ ：\n$$ h_t(x) = x t - f^*(x) $$ 对 $h_t(x)$ 求导，计算 $h_t^{\\prime}(x)$ ：\n$$ h_t^{\\prime}(x) = t - f^{*\\prime}(x) $$ 根据勒让德变换的性质：\n$$ f^{*\\prime}(x) = \\chi(x) = f^{\\prime-1}(x) $$ 因此： $$ h_t^{\\prime}(x) = t - \\chi(x) $$ 令导数 $h_t^{\\prime}(x) = 0$ ，得： $$ t - \\chi(\\bar{x}) = 0 \\quad \\implies \\quad \\bar{x} = \\chi(t) $$ 将极值点代入\n将 $\\bar{x} = \\chi(t)$ 代入 $h_t(x)$ ：\n$$ f^{**}(t) = h_t(\\bar{x}) = \\bar{x} t - f^*(\\bar{x}) $$ $$ f^{**}(t) = \\chi(t) t - f^*(\\bar{x}) $$ 根据勒让德变换的定义 $f^*(\\bar{x}) = \\bar{x} \\chi(t) - f[\\chi(t)]$ ，可以展开为：\n$$ f^{**}(t) = \\chi(t) t - \\big[\\chi(t) t - f[\\chi(t)]\\big] $$ 化简得到：\n$$ f^{**}(t) = f[\\chi(t)] $$ 由于 $\\chi(t) = f^{\\prime-1}(t)$ ，因此: $$ f[\\chi(t)] = f(f^{\\prime-1}(t)) $$ 因此：\n$$ f^{**}(t) = f(t) $$ 双重共轭性质表明，严格凸且下半连续的函数在进行两次勒让德变换后会恢复原函数。这一性质保证了勒让德变换的对偶性，因此在在优化问题中构造对偶关系来解决问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 %% 双重共轭验证 f^{**}(x) = f(x) x_test = linspace(-1,2,200); f_dd_star = zeros(size(x_test)); for i = 1:length(x_test) x_val = x_test(i); h_xt = @(tau) x_val*tau - f_star_analytic(tau); neg_h_xt = @(tau) -h_xt(tau); [~, h_min_val] = fminbnd(neg_h_xt, -10, 10); f_dd_star(i) = -h_min_val; end figure; plot(x_test, f(x_test), 'b', 'LineWidth',2); hold on; plot(x_test, f_dd_star, 'r--','LineWidth',2); xlabel('x','Interpreter','none'); ylabel('Function value','Interpreter','none'); legend({'f(x)','f**(x)'},'Interpreter','none','Location','best'); title('Double conjugate check: f**(x) vs f(x)','Interpreter','none'); 半二次优化方法的原理和实现 原始准则（Criterion）\n定义的优化目标函数 $\\mathcal{J}(x)$ 为： $$ \\mathcal{J}(x) = | \\mathbf{y} - \\mathbf{H} \\mathbf{x} |^2 + \\mu \\sum_{p \\sim q} \\varphi(x_p - x_q) $$\n第一项 $| \\mathbf{y} - \\mathbf{H} \\mathbf{x} |^2$ 是数据拟合项，用来度量 $\\mathbf{x}$ 和观测数据 $\\mathbf{y}$ 之间的误差\n第二项 $\\mu \\sum_{p \\sim q} \\varphi(x_p - x_q)$ 是正则化项，用于惩罚相邻变量（如图像像素邻点）间的差异\n半二次优化的核心是将非二次函数 $\\varphi(\\delta)$ 转化为带有辅助变量 $a$ 的二次形式，因此我们为每个 $x_p - x_q$ 引入辅助变量 $a_{pq}$ ，使得：\n$$ \\varphi(\\delta) = \\inf_a \\left[ \\frac{1}{2} (\\delta - a)^2 + \\zeta(a) \\right] $$ 其中， $\\zeta(a)$ 是一个自定义构造的函数，这种引入将非二次函数 $\\varphi(\\delta)$ 分解为关于变量 $a$ 的优化问题。\n引入辅助变量后，原始准则扩展为： $$ \\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a}) = | \\mathbf{y} - \\mathbf{H} \\mathbf{x} |^2 + \\mu \\sum_{p \\sim q} \\left[ \\frac{1}{2} ( (x_p - x_q) - a_{pq} )^2 + \\zeta(a_{pq}) \\right] $$ 新准则 $\\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a})$ 现在是关于 $\\mathbf{x}$ 和辅助变量 $\\mathbf{a}$ 的联合优化问题。\n原始准则和扩展准则之间有如下关系： $$ \\mathcal{J}(\\mathbf{x}) = \\inf_{\\mathbf{a}} \\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a}) $$ 这说明通过优化 $\\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a})$ 的辅助变量 $\\mathbf{a}$ ，可以间接得到原始问题的解。\n这里一定有一个疑问，为什么一定要引入一个辅助变量呢？直接对原式进行运算不好吗？问题就在非二次函数 $φ(δ)$ 上面，非二次的优化问题可能要处理复杂的非线性和非凸问题，很难求解。通过引入一个辅助变量，将非二次函数 $φ(δ)$ 分解为二次形式和一个新的函数 $ζ(a)$ ，这样就好优化多了，多引入一个变量 $a$ 也不要紧，可以分离 $\\mathbf{x}$ 和 $\\mathbf{a}$ ，固定一个，优化另一个，并且优化交替进行，通过迭代逐步收敛到全局最优解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 %% 半二次分解示例 (Huber函数) % 设置Huber函数阈值参数 s s = 0.5; varphi = @(delta) (abs(delta)\u003c=s).* (delta.^2/2) + (abs(delta)\u003es).*(s*abs(delta)-s^2/2); % g(delta) = (delta^2)/2 - varphi(delta) g = @(delta) (delta.^2)/2 - varphi(delta); % 数值上计算g*(a) a_vals = linspace(-3,3,200); g_star_vals = zeros(size(a_vals)); for i=1:length(a_vals) a_ = a_vals(i); h_a_delta = @(delta) g(delta)-a_*delta; [~,h_min_val] = fminbnd(h_a_delta, -5,5); g_star_vals(i) = -h_min_val; end % 定义zeta(a)=g*(a)-a^2/2 zeta = @(a) interp1(a_vals,g_star_vals,a,'linear','extrap') - a.^2/2; % 检验半二次分解 varphi(delta)=inf_a[(delta - a)^2/2 + zeta(a)] delta_test = linspace(-3,3,100); varphi_recons = zeros(size(delta_test)); for i=1:length(delta_test) delta_ = delta_test(i); Phi = @(a) ((delta_-a).^2)/2 + zeta(a); [~,Phi_min] = fminbnd(Phi,-5,5); varphi_recons(i) = Phi_min; end figure; plot(delta_test,varphi(delta_test),'b','LineWidth',2); hold on; plot(delta_test,varphi_recons,'r--','LineWidth',2); xlabel('delta','Interpreter','none'); ylabel('varphi(delta)','Interpreter','none'); legend({'varphi(delta)','Half-quadratic decomposition'},'Interpreter','none','Location','best'); title('Half-quadratic decomposition check','Interpreter','none'); disp('Legendre transform and half-quadratic decomposition demonstrations completed.'); 在半二次优化中引入勒让德变换 我们刚刚的思路非常美好，现在只需要分开优化就好了，但是现在我们有两个前置问题\n$ \\varphi(\\delta) = \\inf_a \\left[ \\frac{1}{2} (\\delta - a)^2 + \\zeta(a) \\right] $ 怎么构建的？\n$\\zeta(a)$ 怎么构建？\n我们现在推导证明: $$ \\varphi(\\delta) = \\inf_a \\left[ \\frac{1}{2} (\\delta - a)^2 + \\zeta(a) \\right] $$ 证明\n引入一个新的辅助函数 $g(\\delta)$ ，定义为： $$ g(\\delta) = \\frac{\\delta^2}{2} - \\varphi(\\delta). $$ 这里 $g(\\delta)$ 被设计为一个严格凸函数（二次项 $\\frac{\\delta^2}{2}$ 保证了凸性）。\n我们对 $g(\\delta)$ 应用勒让德变换 $g^*(a)$ ：\n$$ g^*(a) = \\sup_{\\delta \\in \\mathbb{R}} \\big[ a \\delta - g(\\delta) \\big] $$ 代入 $g(\\delta) = \\frac{\\delta^2}{2} - \\varphi(\\delta)$ ，勒让德变换展开为：\n$$ g^*(a) = \\sup_{\\delta \\in \\mathbb{R}} \\left[ a \\delta - \\frac{\\delta^2}{2} + \\varphi(\\delta) \\right] $$ 将辅助函数 $\\zeta(a)$ 定义为：\n$$ \\zeta(a) = g^*(a) - \\frac{a^2}{2} $$ 代入 $g^*(a)$ 的表达式，得： $$ \\zeta(a) = \\sup_{\\delta \\in \\mathbb{R}} \\left[ \\varphi(\\delta) - \\frac{ (\\delta - a)^2 }{2} \\right] $$ 这表明 $\\zeta(a)$ 是由 $\\varphi(\\delta)$ 和二次项 $\\frac{ (\\delta - a)^2 }{2}$ 的优化分解所定义的。\n利用双重勒让德变换的性质 $g = g^{**}$ 的性质，我们可以写出\n$$ g(\\delta) = g^{**}(\\delta) $$ $$ g(\\delta) = \\sup_{a} \\big[ a \\delta - g^*(a) \\big] $$ 结合 $g(\\delta) = \\frac{\\delta^2}{2} - \\varphi(\\delta)$ ，可以进一步推导出：\n$$ \\frac{\\delta^2}{2} - \\varphi(\\delta) = \\sup_{a} \\big[ a \\delta - g^*(a) \\big] $$ 由上述方程，可以得到：\n$$ \\varphi(\\delta) = \\frac{\\delta^2}{2} - \\sup_{a} \\big[ a \\delta - g^*(a) \\big] $$ 进一步等价为：\n$$ \\varphi(\\delta) = \\frac{\\delta^2}{2} + \\inf_{a} \\big[ g^*(a) - a \\delta \\big] $$ 将 $g^*(a)$ 的定义代入： $$ \\varphi(\\delta) = \\frac{\\delta^2}{2} + \\inf_{a} \\left[ \\zeta(a) + \\frac{a^2}{2} - a \\delta \\right] $$ 重新整理： $$ \\varphi(\\delta) = \\inf_{a} \\left[ \\frac{ (\\delta - a)^2 }{2} + \\zeta(a) \\right] $$ 这就得到了半二次分解的基本形式。\n为了进一步分析辅助变量 $a$，考虑优化问题： $$ \\inf_{a} \\left[ \\frac{ (\\delta - a)^2 }{2} + \\zeta(a) \\right] $$ 对优化准则求导： $$ \\frac{\\partial}{\\partial a} \\left[ \\frac{ (\\delta - a)^2 }{2} + \\zeta(a) \\right] = (a - \\delta) + \\zeta^{\\prime}(a) = 0 $$ 解出最优 $a = \\bar{a}$： $$ \\bar{a} = \\delta - \\zeta^{\\prime}(a) $$ 结合 $\\zeta^{\\prime}(a) = g^{\\prime}(a)$ ，可以进一步得到： $$ \\bar{a} = g^{*\\prime -1} (\\delta) $$ 或简化为： $$ \\bar{a} = g^{\\prime}(\\delta) = \\delta - \\varphi^{\\prime}(\\delta) $$\n通过上述推导，我们得到：\n半二次分解的标准形式： $$ \\varphi(\\delta) = \\inf_{a} \\left[ \\frac{ (\\delta - a)^2 }{2} + \\zeta(a) \\right] $$\n其中 $\\zeta(a) = g^*(a) - \\frac{a^2}{2}$ 是辅助函数。\n最优辅助变量的表达式： $$ \\bar{a} = \\delta - \\varphi^{\\prime}(\\delta) $$\n这个理论保证了对于任何给定的 $\\varphi(\\delta)$，我们都能通过构造辅助变量 $a$ 来优化原始函数。\n总结\n原始优化问题的目标函数为： $$ \\mathcal{J}(x) = | \\mathbf{y} - \\mathbf{H} \\mathbf{x} |^2 + \\mu \\sum_{p \\sim q} \\varphi(x_p - x_q) $$ 为了解决非二次项 $\\varphi(x_p - x_q)$ ，引入辅助变量 $a_{pq}$ ，将原始准则扩展为： $$ \\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a}) = | \\mathbf{y} - \\mathbf{H} \\mathbf{x} |^2 + \\mu \\sum_{p \\sim q} \\left[ \\frac{1}{2} \\big( (x_p - x_q) - a_{pq} \\big)^2 + \\zeta(a_{pq}) \\right] $$\n$a_{pq}$ 是辅助变量，用于解耦 $x_p$ 和 $x_q$ 。 $\\zeta(a_{pq})$ 是通过勒让德变换定义的辅助函数。 算法策略：交替优化（Alternating Minimization）\n(1) 对 $\\mathbf{x}$ 固定 $\\mathbf{a}$ 进行优化\n在固定 $\\mathbf{a}$ 的情况下，优化目标函数变为关于 $\\mathbf{x}$ 的二次问题： $$ \\widetilde{\\mathbf{x}}(\\mathbf{a}) = \\arg\\min_{\\mathbf{x}} \\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a}) $$ 这是一个标准的二次优化问题，可以通过解析解（如线性代数方法）或数值方法高效求解。\n(2) 对 $\\mathbf{a}$ 固定 $\\mathbf{x}$ 进行优化\n在固定 $\\mathbf{x}$ 的情况下，优化目标函数变为关于 $\\mathbf{a}$ 的问题： $$ \\widetilde{\\mathbf{a}}(\\mathbf{x}) = \\arg\\min_{\\mathbf{a}} \\widetilde{\\mathcal{J}}(\\mathbf{x}, \\mathbf{a}) $$ 这个优化问题也可以通过显式公式解出，因为 $\\zeta(a)$ 是预定义的。\n通过在这两个步骤之间交替迭代，逐步接近全局最优解。\n变量的相互作用（Interacting Variables）：\n原始问题中的变量 $x_p$ 和 $x_q$ 存在耦合关系（通过 $\\varphi(x_p - x_q)$）。 扩展准则通过引入 $a_{pq}$ ，解耦了变量 $\\mathbf{x}$ 和 $\\mathbf{a}$ ，从而简化了优化问题。 优化问题的本质：\n原始问题是非二次的，且变量相互作用； 扩展后，尽管存在交互，但问题本质上是二次的，因此易于求解。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 %% 半二次优化示例 % 注意：我们已定义 s 和 varphi，上述 s=0.5 也适用于此 % 新增phi_prime定义(在之前未定义，需新增) phi_prime = @(delta) (abs(delta)\u003c=s).*delta + (abs(delta)\u003es).*s.*sign(delta); % 以下半二次优化1D信号示例 % 参数设置(对于优化问题) N = 100; % 信号长度 mu = 1; % 正则化参数 maxIter = 50; % 最大迭代次数 % 生成观测数据 y (用 x_true 加噪声) x_true = sin(linspace(0,2*pi,N))'; % 真值 noise = 0.1 * randn(N,1); y = x_true + noise; % 定义算子H为单位映射，这里H = I H = eye(N); % 定义初始值 x = y; % 初始解 a = zeros(N-1,1); % 辅助变量 % 构造差分矩阵 R (N-1 x N) R = spdiags([ones(N-1,1), -ones(N-1,1)], [0,1], N-1, N); % 系数矩阵A_x = 2I + mu R'R A_x = 2*speye(N) + mu*(R'*R); % 迭代求解 for iter = 1:maxIter % Step 1: 固定 a 更新 x rhs = 2*y + mu*R'*a; x = A_x\\rhs; % Step 2: 固定 x 更新 a delta = R*x; a = delta - phi_prime(delta); % 显示进度(每10次迭代显示一次) if mod(iter,10)==0 phi_val = zeros(N-1,1); for k=1:(N-1) d = delta(k); if abs(d)\u003c=s phi_val(k) = d^2/2; else phi_val(k) = s*abs(d)-s^2/2; end end J_val = norm(y - x)^2 + mu*sum(phi_val); fprintf('Iter %d, J = %f\\n', iter, J_val); end end % 结果展示 figure; plot(x_true, 'k-', 'LineWidth',2); hold on; plot(y, 'b:', 'LineWidth',1); plot(x, 'r--', 'LineWidth',2); legend('True x','Noisy y','Reconstructed x','Interpreter','none'); xlabel('Index','Interpreter','none'); ylabel('Amplitude','Interpreter','none'); title('Half-Quadratic Optimization with Huber Regularization','Interpreter','none'); grid on; 半二次优化和相关问题中变量更新的可能方法\n1. 直接计算（Direct Calculus）\n这类方法通过解析表达式或直接矩阵操作更新变量，常用技术包括：\n闭式解（Compact or Closed Form）：当问题有解析解时，可以通过直接计算得到。例如，二次优化问题可以通过矩阵代数方法解决。 矩阵求逆（Matrix Inversion）：对于线性系统，可以通过求解方程 $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ 来更新 $\\mathbf{x}$，如通过矩阵求逆或其他方法。 适用场景：\n问题规模较小，或系统稀疏，矩阵求逆的成本可接受。 2. 线性系统的算法（Algorithms for Linear Systems）\n这部分涵盖了经典的线性系统求解算法，适用于优化问题中涉及的线性方程组：\n高斯消元法（Gauss）和高斯-约当法（Gauss-Jordan）：通过消元法求解线性系统。 代入法（Substitution）：在某些特定的线性系统中，可以逐步代入解。 三角分解（Triangularisation）：将矩阵分解为上下三角矩阵以加速求解。 适用场景：\n当优化目标是二次形式，且涉及线性方程组时。 3. 数值优化（Numerical Optimization）\n针对非线性或复杂目标函数，使用数值优化技术逐步更新变量：\n梯度下降（Gradient Descent）及其变种： 标准梯度下降法通过计算梯度逐步逼近最优解； 可以结合动量、学习率调整等技术加速收敛。 逐像素更新（Pixel-Wise Update）： 在图像处理问题中，逐像素优化是常用策略，尤其是涉及稀疏正则化的场景。 适用场景：\n问题非线性或不可微，梯度信息可用但解析解不可得。 4. 对角化（Diagonalization）\n通过对矩阵的对角化或循环近似来加速计算：\n循环矩阵近似（Circulant Approximation）：在某些场景下，可以将矩阵近似为循环矩阵，从而通过快速傅里叶变换（FFT）简化运算。 通过快速傅里叶变换（Diagonalization by FFT）：对角化操作可以通过 FFT 快速实现，极大加速求解过程。 适用场景：\n当系统是周期性或卷积形式，FFT 是高效的选择。 5. 特殊算法（Special Algorithms for 1D Cases）\n针对一维情况，可以利用特别设计的算法：\n递归最小二乘法（Recursive Least Squares, RLS）： 适用于时间序列数据或动态系统建模。 卡尔曼滤波或平滑（Kalman Smoother/Filter）： 经典算法，用于估计动态系统的状态，可以扩展到快速变种以适应实时应用。 适用场景：\n动态系统、一维优化问题，尤其是涉及时间序列数据的场景。 辅助变量的更新策略 或者说 辅助变量的分离性\n扩展的准则为： $$ \\widetilde{\\mathcal{J}}(a) = \\sum_{p \\sim q} \\left[ \\frac{1}{2} \\big( (x_p - x_q) - a_{pq} \\big)^2 + \\zeta(a_{pq}) \\right] $$ 这表明该问题：\n非二次：因为 $\\zeta(a_{pq})$ 的形式可能不是二次的； 可分离：由于各 $a_{pq}$ 之间无交互，因此可以并行计算 $a_{pq}$。 2. 第二个优化优势：增强特性\n通过对辅助变量的分离优化，得到以下特性：\n并行计算（Parallel Computation）：每个 $a_{pq}$ 可以独立更新，无需遍历或循环。 显式更新（Explicit Updates）：辅助变量的更新可以通过解析公式完成，无需进一步的内层迭代。 这使得优化过程高效且适合并行处理硬件，如 GPU。\n3. 辅助变量的更新公式\n通过优化准则对 $a_{pq}$ 求导，得到更新公式：\n$$ \\widetilde{a}_{pq} = \\delta_{pq} - \\varphi^{\\prime}(\\delta_{pq}) $$ 其中：\n$\\delta_{pq} = x_p - x_q$ 表示当前变量 $x_p$ 和 $x_q$ 的差异； $\\varphi^{\\prime}(\\delta_{pq})$ 是正则化函数 $\\varphi(\\delta_{pq})$ 的导数。 Huber 函数特例\n对于 Huber 函数： $$ \\varphi(\\delta) = \\begin{cases} \\frac{\\delta^2}{2} \u0026 |\\delta| \\leq s, \\ s |\\delta| - \\frac{s^2}{2} \u0026 |\\delta| \u003e s, \\end{cases} $$ 其导数为： $$ \\varphi^{\\prime}(\\delta) = \\begin{cases} \\delta \u0026 |\\delta| \\leq s, \\ s \\cdot \\text{sign}(\\delta) \u0026 |\\delta| \u003e s. \\end{cases} $$ 对应的辅助变量更新为：\n$$ \\widetilde{a}_{pq} = \\delta_{pq} \\cdot \\left[ 1 - 2\\alpha \\cdot \\min\\left(1, \\frac{s}{|\\delta_{pq}|} \\right) \\right] $$ 总结与扩展\n图像反卷积（Image Deconvolution）：\n主要目标是通过正则化方法恢复原始图像。\n边缘保持与非二次正则化（Edge Preserving and Non-Quadratic Penalties）：\n包括灰度梯度（如边缘检测）的惩罚； 支持凸或部分非凸的正则化。 数值计算与半二次方法（Numerical Computations: Half-Quadratic Approach）：\n迭代优化策略结合分离性质； 使用循环矩阵近似（Circulant Approximation）或快速傅里叶变换（FFT）加速计算。 下一步研究方向包括：\n加入约束条件以提高图像分辨率； 自动估计超参数（正则化参数）或设备参数。 ",
  "wordCount" : "6779",
  "inLanguage": "zh",
  "image": "http://zehua.eu/images/papermod-cover.png","datePublished": "2024-11-22T16:25:17+01:00",
  "dateModified": "2024-12-08T17:12:35+08:00",
  "author":{
    "@type": "Person",
    "name": "Zehua"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://zehua.eu/zh/posts/signal_cn/%E5%8B%92%E8%AE%A9%E5%BE%B7%E5%8F%98%E6%8D%A2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "主页",
    "logo": {
      "@type": "ImageObject",
      "url": "http://zehua.eu/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://zehua.eu/zh/" accesskey="h" title="主页 (Alt + H)">主页</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="http://zehua.eu/" title="English"
                            aria-label="English">English</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://zehua.eu/zh/posts/" title="列表">
                    <span>列表</span>
                </a>
            </li>
            <li>
                <a href="http://zehua.eu/zh/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="http://zehua.eu/zh/archives/" title="时间轴">
                    <span>时间轴</span>
                </a>
            </li>
            <li>
                <a href="http://zehua.eu/zh/about/" title="版权说明">
                    <span>版权说明</span>
                </a>
            </li>
            <li>
                <a href="http://zehua.eu/zh/search/" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://zehua.eu/zh/">主页</a>&nbsp;»&nbsp;<a href="http://zehua.eu/zh/posts/">Posts</a>&nbsp;»&nbsp;<a href="http://zehua.eu/zh/posts/signal_cn/">信号处理</a></div>
    <h1 class="post-title entry-hint-parent">
      勒让德变换与半二次优化方法
    </h1>
    <div class="post-meta">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/v4-shims.css"><span class="meta-tag"><span class="fa fa-calendar-plus-o"></span>&nbsp;<span title='2024-11-22 16:25:17 +0100 CET'>11月22日, 2024</span></span>&nbsp; | &nbsp;<span class="meta-tag"><span class="fa fa-file-word-o"></span>&nbsp;<span>共6779字</span></span>&nbsp; | &nbsp;<span class="meta-tag"><span class="fa fa-user-circle-o"></span>&nbsp;<span>Zehua</span></span>

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">目录</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#%e5%8b%92%e8%ae%a9%e5%be%b7%e5%8f%98%e6%8d%a2" aria-label="勒让德变换">勒让德变换</a><ul>
                            
                    <li>
                        <a href="#%e5%ae%9a%e4%b9%89" aria-label="定义">定义</a></li>
                    <li>
                        <a href="#%e6%80%a7%e8%b4%a8" aria-label="性质">性质</a></li>
                    <li>
                        <a href="#%e4%b8%be%e4%be%8b" aria-label="举例">举例</a></li>
                    <li>
                        <a href="#%e6%b1%82%e5%af%bc" aria-label="求导">求导</a></li>
                    <li>
                        <a href="#%e5%8f%8c%e9%87%8d%e5%85%b1%e8%bd%ad%e6%81%a2%e5%a4%8d%e5%8e%9f%e5%87%bd%e6%95%b0" aria-label="双重共轭恢复原函数">双重共轭恢复原函数</a></li></ul>
                    </li>
                    <li>
                        <a href="#%e5%8d%8a%e4%ba%8c%e6%ac%a1%e4%bc%98%e5%8c%96%e6%96%b9%e6%b3%95%e7%9a%84%e5%8e%9f%e7%90%86%e5%92%8c%e5%ae%9e%e7%8e%b0" aria-label="半二次优化方法的原理和实现">半二次优化方法的原理和实现</a><ul>
                            
                    <li>
                        <a href="#%e5%9c%a8%e5%8d%8a%e4%ba%8c%e6%ac%a1%e4%bc%98%e5%8c%96%e4%b8%ad%e5%bc%95%e5%85%a5%e5%8b%92%e8%ae%a9%e5%be%b7%e5%8f%98%e6%8d%a2" aria-label="在半二次优化中引入勒让德变换">在半二次优化中引入勒让德变换</a>
                    </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>

  <div class="post-content"><h1 id="勒让德变换">勒让德变换<a hidden class="anchor" aria-hidden="true" href="#勒让德变换">#</a></h1>
<h2 id="定义">定义<a hidden class="anchor" aria-hidden="true" href="#定义">#</a></h2>
<p>勒让德变换（$Legendre$ Transform，$LT$）或称作凸共轭（$Convex$ $Conjugate$，$CC$）</p>
<p>勒让德变换是凸分析中的一个基本工具，广泛用于优化理论中，它将一个函数 $f(x)$ 映射为另一个凸函数 $f^*(t)$</p>
<p>在进行 $LT$ 之前，我们需要确保原函数 $f $ 满足以下两个条件:</p>
<ul>
<li><strong>严格凸性（strictly convex）：</strong> 函数 $f(x)$ 是严格凸的。</li>
<li><strong>可导性（differentiability）：</strong> 函数 $f(x)$ 至少一次可导（一般要二次导）。</li>
</ul>
<p>因此通过 <strong>勒让德变换</strong>，我们就可以得到一个新的函数 $f^{*}$</p>
<div> $$  f^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - f(x) \big]  $$ </div>
<p>其中，$\sup$ 表示取上确界（$supremum$），也就是取$x t - f(x)$ 的最大值，因此我们可以得到:
$$
x t - f(x) \leq f^{*}(t)
$$
说明 $f^ *(t)$ 是所有 $x t - f(x)$ 的上界</p>
<p>我们再将 $f(x)$ 移到右边，可得:
$$
x t \leq f^ *(t) + f(x)
$$
这体现了 $f^ *(t)$ 和 $f(x)$ 的对偶性</p>
<h2 id="性质">性质<a hidden class="anchor" aria-hidden="true" href="#性质">#</a></h2>
<p>我们现在关注勒让德变换在函数的横向伸缩（$dilatation$）、平移（$shift$）、以及纵向平移和伸缩的情况下的性质变化</p>
<p><strong>(a) 横向伸缩 (Horizontal Dilatation):</strong></p>
<p>设 $\gamma &gt; 0$ 是横向伸缩系数，定义一个新函数 $g(x)$ ：
$$
g(x) = f(\gamma x)
$$
对应的勒让德变换为：</p>
<div> $$ g^*(t) = f^*\left(\frac{t}{\gamma}\right) $$ </div>
<p>横向缩放（乘以 $\gamma$ ）会导致勒让德共轭中的自变量 $t$ 被缩放为 $\frac{t}{\gamma}$</p>
<div
    class="alert alert-warning"    role="alert"><text><p><strong>证明</strong></p>
<p>我们有:
$$
g(x) = f(\gamma x)
$$
目标是推导 $g^ *(t)$ 的表达式，根据勒让德变换的定义，我们可得：</p>
<div> $$ g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - g(x) \big] $$ </div>
<p>代入 $g(x) = f(\gamma x)$：
$$
g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - f(\gamma x) \big]
$$</p>
<p>我们给 $xt$ 这部分配项，乘 $\gamma$ 除 $\gamma$ ，可得
$$
g^*(t) = \sup_{x \in \mathbb{R}} \left[ \frac{\gamma x}{\gamma} t - f(\gamma x) \right]
$$</p>
<p>将 $\gamma x$ 保存好，得到 $f(\gamma x)$ 的 $LT$ 变换 $g^ *(t)$ 等于:</p>
<div> $$ g^*(t) = \sup_{x \in \mathbb{R}} \left[ \gamma x \cdot \frac{t}{\gamma} - f(\gamma x) \right] $$ </div>
<p>我们发现，
$$
f^ *\left(\frac{t}{\gamma}\right) =\sup_{u \in \mathbb{R}} \bigg[ u \cdot \frac{t}{\gamma} - f(u) \bigg]
$$
不用管 $u$ 是什么，只要一样就可以了，所以我们对比两个形式，观察到  $ \sup _{x \in \mathbb{R}} \big[ \gamma x \cdot \frac{t}{\gamma} - f(\gamma x) \big]$ 正是函数 $f^ *\left(\frac{t}{\gamma}\right)$ 的定义，因此:</p>
<div> $$ g^*(t) = f^*\left(\frac{t}{\gamma}\right) $$ </div>
<p>注意一点，$\gamma &gt; 0$ 的条件是必要的，这是为了保证变换方向和凸性不改变。</p>
</text></div>

<p><strong>(b) 横向平移 (Horizontal Shift):</strong></p>
<p>设 $x_0 \in \mathbb{R}$ 是横向平移的位移量，定义：
$$
g(x) = f(x - x_0)
$$
对应的勒让德变换为：</p>
<div> $$ g^*(t) = f^*(t) + x_0 t $$ </div>
<p>对 $x$ 进行平移，相当于在勒让德共轭中增加一项线性修正 $x_0 t$ 。</p>
<div
    class="alert alert-warning"    role="alert"><text><p><strong>证明</strong></p>
<p>定义:
$$
g(x) = f(x - x_0)
$$
目标是推导 $g^*(t)$ 的表达式，根据勒让德变换的定义：</p>
<div> $$ g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - g(x) \big] $$ </div>
<p>$$
g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - f(x - x_0) \big]
$$</p>
<p>换元，令
$$
u = x - x_0
$$
因此
$$
x = u + x_0
$$
并且当 $x \in \mathbb{R}$ 时，$u \in \mathbb{R}$（无约束变化范围）。将 $x = u + x_0$ 带入原式：</p>
<div> $$ g^*(t) = \sup_{u \in \mathbb{R}} \big[ (u + x_0)t - f(u) \big] $$ </div>
<p>展开括号：
$$
g^*(t) = \sup_{u \in \mathbb{R}} \big[ u t + x_0 t - f(u) \big]
$$</p>
<p>注意到 $x_0 t$ 是与 $u$ 无关的常数，因此可以从 $\sup$ 中提取出来：
$$
g^*(t) = \sup_{u \in \mathbb{R}} \big[ u t - f(u) \big] + x_0 t
$$</p>
<p>我们注意到，其中的 $\sup_{u \in \mathbb{R}} \big[ u t - f(u) \big]$ 就是 $f^ *(t)$ 的定义:</p>
<div> $$ f^*(t) = \sup_{u \in \mathbb{R}} \big[ u t - f(u) \big] $$ </div>
<p>因此可以得到：</p>
<div> $$ g^*(t) = f^*(t) + x_0 t $$ </div>
<p>证毕</p>
</text></div>

<p><strong>(c) 纵向平移和伸缩 (Vertical Shift-Dilatation):</strong></p>
<p>设 $\alpha \in \mathbb{R}$ 和 $\beta &gt; 0$ ，定义新的函数 $g(x)$ ：
$$
g(x) = \alpha + \beta f(x)
$$
对应的勒让德变换为：</p>
<div> $$ g^*(t) = \beta f^*\left(\frac{t}{\beta}\right) - \alpha $$ </div>
<p>纵向伸缩 $\beta$ 会缩放勒让德变换的自变量 $t$ ，并乘以 $\beta$ 。纵向平移 $\alpha$ 直接导致勒让德共轭函数的值减去 $\alpha$</p>
<div
    class="alert alert-warning"    role="alert"><text><p><strong>证明</strong></p>
<div> $$ g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - g(x) \big] $$ </div>
<p>其中:</p>
<div> $$ g(x) = \alpha + \beta f(x) $$ </div>
<p>因此:</p>
<div> $$ g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - (\alpha + \beta f(x)) \big] = \sup_{x \in \mathbb{R}} \big[ x t - \beta f(x) - \alpha \big] $$ </div>
<p>由于 $\alpha$ 与 $x$ 无关:</p>
<div> $$ g^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - \beta f(x) \big] - \alpha $$ </div>
<p>将 $sup$ 里面表达式 乘 $\beta$ 除 $\beta$ ，可得:</p>
<div> $$ g^*(t) = \beta \sup_{x \in \mathbb{R}} \left[ \frac{t}{\beta} x - f(x) \right] - \alpha $$ </div>
<p>我们注意到 $\sup_{x \in \mathbb{R}} \left[ \frac{t}{\beta} x - f(x) \right]$ 就是 $f^*\left( \frac{t}{\beta} \right)$ 的定义，即：</p>
<div> $$ f^*\left( \frac{t}{\beta} \right) = \sup_{x \in \mathbb{R}} \left[ \frac{t}{\beta} x - f(x) \right] $$ </div>
<p>得到：</p>
<div> $$ g^*(t) = \beta f^*\left( \frac{t}{\beta} \right) - \alpha $$ </div>
<p>证毕</p>
</text></div>

<h2 id="举例">举例<a hidden class="anchor" aria-hidden="true" href="#举例">#</a></h2>
<p>下面我们以一个二次函数为例，详细计算推导它的勒让德变换（$Legendre$ Transform, $LT$）</p>
<p>$$
f(x) = \alpha + \frac{1}{2} \beta (x - x_0)^2
$$
其中：</p>
<ul>
<li>$\alpha \in \mathbb{R}$ 是一个常数，表示垂直偏移；</li>
<li>$\beta &gt; 0$ 是参数，控制二次项的系数；</li>
<li>$x_0$ 是偏移中心。</li>
</ul>
<p>目标是找到其勒让德变换：
$$
f^*(t) = \sup_{x \in \mathbb{R}} \big[ x t - f(x) \big]
$$
<strong>推导过程</strong></p>
<p>我们先看里面 $x t - f(x)$ 这一项，因此定义辅助函数：
$$
g_t(x) = x t - f(x)
$$
将 $f(x)$ 代入得到：
$$
g_t(x) = x t - \left(\alpha + \frac{\beta}{2}(x - x_0)^2 \right)
$$
展开：
$$
g_t(x) = x t - \alpha - \frac{\beta}{2}(x - x_0)^2
$$
所以，原式等于:
$$
f^*(t) = \sup_{x \in \mathbb{R}} \big[x t - \alpha - \frac{\beta}{2}(x - x_0)^2 \big]
$$
我们希望再次基础上更进一步，也就是拿掉 $sup$ 符号。为了完成这一点，需要找到内层函数 $g_t(x)$ 的极大值。</p>
<p><strong>对 $g_t(x)$ 求导数并找到极值点</strong></p>
<p>计算 $g_t(x)$ 的一阶导数：
$$
g_t^{\prime}(x) = t - \beta (x - x_0)
$$
令 $g_t^{\prime}(x) = 0$ 解出极值点：
$$
t - \beta (\bar{x} - x_0) = 0 \quad \implies \quad \bar{x} = x_0 + \frac{t}{\beta}
$$
计算 $g_t(x)$ 的二阶导数：
$$
g_t^{\prime\prime}(x) = -\beta
$$
由于 $\beta &gt; 0$ ，说明 $g_t(x)$ 是一个严格concave函数，因此在 $\bar{x}$ 处确实取得最大值。</p>
<p><strong>将极值点代回</strong> $g_t(x)$</p>
<p>将 $\bar{x} = x_0 + \frac{t}{\beta}$ 代入 $g_t(x)$ ：</p>
<div> $$ f^*(t) = g_t(\bar{x}) = \bar{x} t - f(\bar{x}) $$ </div>
<p>具体代入：</p>
<div> $$ f^*(t) = \left(x_0 + \frac{t}{\beta} \right) t - \left(\alpha + \frac{\beta}{2} \left(x_0 + \frac{t}{\beta} - x_0 \right)^2 \right) $$ </div>
<p>展开化简：</p>
<div> $$ f^*(t) = x_0 t + \frac{t^2}{\beta} - \alpha - \frac{\beta}{2} \cdot \frac{t^2}{\beta^2} $$ </div>
<p>进一步整理：</p>
<div> $$ f^*(t) = x_0 t + \frac{t^2}{2\beta} - \alpha $$ </div>
<p>最终结果：
$$
f^*(t) = \frac{1}{2\beta} t^2 + t x_0 - \alpha
$$
具体过程是：</p>
<ol>
<li>定义辅助函数 $g_t(x) = x t - f(x)$</li>
<li>求导数 $g_t^{\prime}(x) = t - f^{\prime}(x)$</li>
<li>找到零点 $\bar{x} = \chi(t)$</li>
<li>代回 $g_t( \bar{x})$ 得到 $f^*(t)$</li>
</ol>
<h2 id="求导">求导<a hidden class="anchor" aria-hidden="true" href="#求导">#</a></h2>
<p>勒让德变换通用表达式为：
$$
f^*(t) = t \chi(t) - f[\chi(t)]
$$
其中： $\chi(t)$ 是 $f^{\prime}(x)$ 的反函数，即 $\chi(t) = (f^{\prime})^{-1}(t)$ 。</p>
<p><strong>一阶导数</strong></p>
<p>为了求 $f^ *(t)$  的一阶导数，对  $f^ *(t)$ 进行求导：</p>
<div> $$ f^{*\prime}(t) = \frac{\partial}{\partial t} \big( t \chi(t) - f[\chi(t)] \big) $$ </div>
<p>利用链式法则，得到：</p>
<div> $$ f^{*\prime}(t) = \chi(t) + t \chi^{\prime}(t) - \chi^{\prime}(t) f^{\prime}[\chi(t)] $$ </div>
<p>由于 $\chi(t) = f^{\prime-1}(t)$ <em>，并且</em> $f^{\prime}[\chi(t)] = t$ ，代入后有：</p>
<div> $$ f^{*\prime}(t) = \chi(t) $$ </div>
<p>因此，一阶导数结果为：
$$
f^{*\prime}(t) = \chi(t) = f^{\prime-1}(t)
$$
<strong>勒让德变换的二阶导数</strong></p>
<p>对 $f^ { *\prime}(t) = \chi(t)$ <em>再求导：</em></p>
<div> $$ f^{*\prime\prime}(t) = \chi^{\prime}(t) $$ </div>
<p>由于 $\chi(t) = f^{\prime-1}(t)$ ，求导得到：
$$
\chi^{\prime}(t) = \frac{1}{f^{\prime\prime}[\chi(t)]}
$$
因此，勒让德变换的二阶导数为：</p>
<div> $$ f^{*\prime\prime}(t)= \frac{1}{f^{\prime\prime}[\chi(t)]} $$ </div>
<p>由于 $f^{\prime\prime}(x) &gt; 0$ （$f(x)$ 是严格凸函数），所以 $f^ {*\prime\prime}(t) &gt; 0$ ，从而证明 $f^ *(t)$ 始终是凸函数。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="n">clear</span><span class="p">;</span> <span class="n">close</span> <span class="n">all</span><span class="p">;</span> <span class="n">clc</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">%% 参数设置 (用于勒让德变换及半二次分解示例)</span>
</span></span><span class="line"><span class="cl"><span class="n">alpha</span> <span class="p">=</span> <span class="mf">1.0</span><span class="p">;</span>  <span class="c">% f(x)的垂直偏移</span>
</span></span><span class="line"><span class="cl"><span class="nb">beta</span> <span class="p">=</span> <span class="mf">2.0</span><span class="p">;</span>   <span class="c">% f(x)中二次项系数 &gt; 0</span>
</span></span><span class="line"><span class="cl"><span class="n">x0</span> <span class="p">=</span> <span class="mf">0.5</span><span class="p">;</span>     <span class="c">% f(x)中心偏移</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 定义原函数 f(x)</span>
</span></span><span class="line"><span class="cl"><span class="n">f</span> <span class="p">=</span> <span class="p">@(</span><span class="n">x</span><span class="p">)</span> <span class="n">alpha</span> <span class="o">+</span> <span class="p">(</span><span class="nb">beta</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 理论勒让德共轭 f*(t)</span>
</span></span><span class="line"><span class="cl"><span class="n">f_star_analytic</span> <span class="p">=</span> <span class="p">@(</span><span class="n">t</span><span class="p">)</span> <span class="p">(</span><span class="n">t</span><span class="o">.^</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="nb">beta</span><span class="p">)</span> <span class="o">+</span> <span class="n">t</span><span class="o">*</span><span class="n">x0</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 定义 t 和 x 的取值范围用于数值求解</span>
</span></span><span class="line"><span class="cl"><span class="n">t_vals</span> <span class="p">=</span> <span class="nb">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">200</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">x_vals</span> <span class="p">=</span> <span class="nb">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">200</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">%% 数值求勒让德变换 f*(t)</span>
</span></span><span class="line"><span class="cl"><span class="n">f_star_numeric</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">t_vals</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="nb">i</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="nb">length</span><span class="p">(</span><span class="n">t_vals</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">t</span> <span class="p">=</span> <span class="n">t_vals</span><span class="p">(</span><span class="nb">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">g_t</span> <span class="p">=</span> <span class="p">@(</span><span class="n">x</span><span class="p">)</span> <span class="n">x</span><span class="o">*</span><span class="n">t</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">neg_g_t</span> <span class="p">=</span> <span class="p">@(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span><span class="n">g_t</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="o">~</span><span class="p">,</span> <span class="n">fval_neg</span><span class="p">]</span> <span class="p">=</span> <span class="n">fminbnd</span><span class="p">(</span><span class="n">neg_g_t</span><span class="p">,</span> <span class="n">min</span><span class="p">(</span><span class="n">x_vals</span><span class="p">),</span> <span class="n">max</span><span class="p">(</span><span class="n">x_vals</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="n">f_star_numeric</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="o">-</span><span class="n">fval_neg</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="c">%% 对比数值结果和解析解</span>
</span></span><span class="line"><span class="cl"><span class="n">figure</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">t_vals</span><span class="p">,</span> <span class="n">f_star_numeric</span><span class="p">,</span> <span class="s">&#39;r&#39;</span><span class="p">,</span> <span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span> <span class="n">hold</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">t_vals</span><span class="p">,</span> <span class="n">f_star_analytic</span><span class="p">(</span><span class="n">t_vals</span><span class="p">),</span> <span class="s">&#39;b--&#39;</span><span class="p">,</span> <span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;t&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl"><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;f*(t)&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">legend</span><span class="p">({</span><span class="s">&#39;Numerical f*(t)&#39;</span><span class="p">,</span><span class="s">&#39;Analytical f*(t)&#39;</span><span class="p">},</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">,</span><span class="s">&#39;Location&#39;</span><span class="p">,</span><span class="s">&#39;best&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">title</span><span class="p">(</span><span class="s">&#39;Legendre transform: numerical vs analytical&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><img src="/img/legendre/1.png" style="width:100%;" />
<h2 id="双重共轭恢复原函数">双重共轭恢复原函数<a hidden class="anchor" aria-hidden="true" href="#双重共轭恢复原函数">#</a></h2>
<p>勒让德变换的一个关键性质，即<strong>双重共轭恢复原函数</strong></p>
<div> $$ f^{**}(x) = f(x) $$ </div>
<div
    class="alert alert-warning"    role="alert"><text><p><strong>证明</strong></p>
<p>双重共轭函数定义为：</p>
<div> $$ f^{**}(t) = \sup_{x \in \mathbb{R}} \big[ x t - f^*(x) \big] $$ </div>
<p>定义辅助函数 $h_t(x)$ ：</p>
<div> $$ h_t(x) = x t - f^*(x) $$ </div>
<p>对 $h_t(x)$ 求导，计算 $h_t^{\prime}(x)$ ：</p>
<div> $$ h_t^{\prime}(x) = t - f^{*\prime}(x) $$ </div>
<p>根据勒让德变换的性质：</p>
<div> $$ f^{*\prime}(x) = \chi(x) = f^{\prime-1}(x) $$ </div>
<p>因此：
$$
h_t^{\prime}(x) = t - \chi(x)
$$
令导数 $h_t^{\prime}(x) = 0$ ，得：
$$
t - \chi(\bar{x}) = 0 \quad \implies \quad \bar{x} = \chi(t)
$$
<strong>将极值点代入</strong></p>
<p>将 $\bar{x} = \chi(t)$ 代入 $h_t(x)$ ：</p>
<div> $$ f^{**}(t) = h_t(\bar{x}) = \bar{x} t - f^*(\bar{x}) $$ </div>
<div> $$ f^{**}(t) = \chi(t) t - f^*(\bar{x}) $$ </div>
<p>根据勒让德变换的定义 $f^*(\bar{x}) = \bar{x} \chi(t) - f[\chi(t)]$ ，可以展开为：</p>
<div> $$ f^{**}(t) = \chi(t) t - \big[\chi(t) t - f[\chi(t)]\big] $$ </div>
<p>化简得到：</p>
<div> $$ f^{**}(t) = f[\chi(t)] $$ </div>
<p>由于 $\chi(t) = f^{\prime-1}(t)$ ，因此:
$$
f[\chi(t)] = f(f^{\prime-1}(t))
$$
因此：</p>
<div> $$ f^{**}(t) = f(t) $$ </div>
</text></div>

<p>双重共轭性质表明，严格凸且下半连续的函数在进行两次勒让德变换后会恢复原函数。这一性质保证了勒让德变换的对偶性，因此在在优化问题中构造对偶关系来解决问题。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="c">%% 双重共轭验证 f^{**}(x) = f(x)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_test</span> <span class="p">=</span> <span class="nb">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">200</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">f_dd_star</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">x_test</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="nb">i</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="nb">length</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x_val</span> <span class="p">=</span> <span class="n">x_test</span><span class="p">(</span><span class="nb">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">h_xt</span> <span class="p">=</span> <span class="p">@(</span><span class="n">tau</span><span class="p">)</span> <span class="n">x_val</span><span class="o">*</span><span class="n">tau</span> <span class="o">-</span> <span class="n">f_star_analytic</span><span class="p">(</span><span class="n">tau</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">neg_h_xt</span> <span class="p">=</span> <span class="p">@(</span><span class="n">tau</span><span class="p">)</span> <span class="o">-</span><span class="n">h_xt</span><span class="p">(</span><span class="n">tau</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="o">~</span><span class="p">,</span> <span class="n">h_min_val</span><span class="p">]</span> <span class="p">=</span> <span class="n">fminbnd</span><span class="p">(</span><span class="n">neg_h_xt</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">f_dd_star</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="o">-</span><span class="n">h_min_val</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">figure</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span> <span class="n">hold</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">f_dd_star</span><span class="p">,</span> <span class="s">&#39;r--&#39;</span><span class="p">,</span><span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl"><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Function value&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">legend</span><span class="p">({</span><span class="s">&#39;f(x)&#39;</span><span class="p">,</span><span class="s">&#39;f**(x)&#39;</span><span class="p">},</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">,</span><span class="s">&#39;Location&#39;</span><span class="p">,</span><span class="s">&#39;best&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">title</span><span class="p">(</span><span class="s">&#39;Double conjugate check: f**(x) vs f(x)&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><img src="/img/legendre/2.png" style="width:100%;" />
<h1 id="半二次优化方法的原理和实现">半二次优化方法的原理和实现<a hidden class="anchor" aria-hidden="true" href="#半二次优化方法的原理和实现">#</a></h1>
<p><strong>原始准则（Criterion）</strong></p>
<p>定义的优化目标函数 $\mathcal{J}(x)$ 为：
$$
\mathcal{J}(x) = | \mathbf{y} - \mathbf{H} \mathbf{x} |^2 + \mu \sum_{p \sim q} \varphi(x_p - x_q)
$$</p>
<ul>
<li>
<p>第一项 $| \mathbf{y} - \mathbf{H} \mathbf{x} |^2$ 是数据拟合项，用来度量 $\mathbf{x}$ 和观测数据 $\mathbf{y}$ 之间的误差</p>
</li>
<li>
<p>第二项 $\mu \sum_{p \sim q} \varphi(x_p - x_q)$ 是正则化项，用于惩罚相邻变量（如图像像素邻点）间的差异</p>
</li>
</ul>
<p>半二次优化的核心是将非二次函数 $\varphi(\delta)$ 转化为带有辅助变量 $a$ 的二次形式，因此我们为每个 $x_p - x_q$ 引入辅助变量 $a_{pq}$ ，使得：</p>
<p>$$
\varphi(\delta) = \inf_a \left[ \frac{1}{2} (\delta - a)^2 + \zeta(a) \right]
$$
其中， $\zeta(a)$ 是一个自定义构造的函数，这种引入将非二次函数 $\varphi(\delta)$ 分解为关于变量 $a$ 的优化问题。</p>
<p>引入辅助变量后，原始准则扩展为：
$$
\widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a}) = | \mathbf{y} - \mathbf{H} \mathbf{x} |^2 + \mu \sum_{p \sim q} \left[ \frac{1}{2} ( (x_p - x_q) - a_{pq} )^2 + \zeta(a_{pq}) \right]
$$
新准则 $\widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a})$ 现在是关于 $\mathbf{x}$ 和辅助变量 $\mathbf{a}$ 的联合优化问题。</p>
<p>原始准则和扩展准则之间有如下关系：
$$
\mathcal{J}(\mathbf{x}) = \inf_{\mathbf{a}} \widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a})
$$
这说明通过优化 $\widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a})$ 的辅助变量 $\mathbf{a}$ ，可以间接得到原始问题的解。</p>
<p>这里一定有一个疑问，为什么一定要引入一个辅助变量呢？直接对原式进行运算不好吗？问题就在非二次函数 $φ(δ)$ 上面，非二次的优化问题可能要处理复杂的非线性和非凸问题，很难求解。通过引入一个辅助变量，将非二次函数 $φ(δ)$ 分解为二次形式和一个新的函数 $ζ(a)$ ，这样就好优化多了，多引入一个变量 $a$ 也不要紧，可以分离 $\mathbf{x}$ 和 $\mathbf{a}$ ，固定一个，优化另一个，并且优化交替进行，通过迭代逐步收敛到全局最优解。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="c">%% 半二次分解示例 (Huber函数)</span>
</span></span><span class="line"><span class="cl"><span class="c">% 设置Huber函数阈值参数 s</span>
</span></span><span class="line"><span class="cl"><span class="n">s</span> <span class="p">=</span> <span class="mf">0.5</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl"><span class="n">varphi</span> <span class="p">=</span> <span class="p">@(</span><span class="n">delta</span><span class="p">)</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span><span class="o">&lt;</span><span class="p">=</span><span class="n">s</span><span class="p">)</span><span class="o">.*</span> <span class="p">(</span><span class="n">delta</span><span class="o">.^</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span><span class="o">&gt;</span><span class="n">s</span><span class="p">)</span><span class="o">.*</span><span class="p">(</span><span class="n">s</span><span class="o">*</span><span class="nb">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span><span class="o">-</span><span class="n">s</span>^<span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% g(delta) = (delta^2)/2 - varphi(delta)</span>
</span></span><span class="line"><span class="cl"><span class="n">g</span> <span class="p">=</span> <span class="p">@(</span><span class="n">delta</span><span class="p">)</span> <span class="p">(</span><span class="n">delta</span><span class="o">.^</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="n">varphi</span><span class="p">(</span><span class="n">delta</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 数值上计算g*(a)</span>
</span></span><span class="line"><span class="cl"><span class="n">a_vals</span> <span class="p">=</span> <span class="nb">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">200</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">g_star_vals</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">a_vals</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="nb">i</span><span class="p">=</span><span class="mi">1</span><span class="p">:</span><span class="nb">length</span><span class="p">(</span><span class="n">a_vals</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">a_</span> <span class="p">=</span> <span class="n">a_vals</span><span class="p">(</span><span class="nb">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">h_a_delta</span> <span class="p">=</span> <span class="p">@(</span><span class="n">delta</span><span class="p">)</span> <span class="n">g</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span><span class="o">-</span><span class="n">a_</span><span class="o">*</span><span class="n">delta</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="o">~</span><span class="p">,</span><span class="n">h_min_val</span><span class="p">]</span> <span class="p">=</span> <span class="n">fminbnd</span><span class="p">(</span><span class="n">h_a_delta</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">g_star_vals</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="o">-</span><span class="n">h_min_val</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 定义zeta(a)=g*(a)-a^2/2</span>
</span></span><span class="line"><span class="cl"><span class="n">zeta</span> <span class="p">=</span> <span class="p">@(</span><span class="n">a</span><span class="p">)</span> <span class="n">interp1</span><span class="p">(</span><span class="n">a_vals</span><span class="p">,</span><span class="n">g_star_vals</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="s">&#39;linear&#39;</span><span class="p">,</span><span class="s">&#39;extrap&#39;</span><span class="p">)</span> <span class="o">-</span> <span class="n">a</span><span class="o">.^</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 检验半二次分解 varphi(delta)=inf_a[(delta - a)^2/2 + zeta(a)]</span>
</span></span><span class="line"><span class="cl"><span class="n">delta_test</span> <span class="p">=</span> <span class="nb">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">100</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">varphi_recons</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">size</span><span class="p">(</span><span class="n">delta_test</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="nb">i</span><span class="p">=</span><span class="mi">1</span><span class="p">:</span><span class="nb">length</span><span class="p">(</span><span class="n">delta_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">delta_</span> <span class="p">=</span> <span class="n">delta_test</span><span class="p">(</span><span class="nb">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">Phi</span> <span class="p">=</span> <span class="p">@(</span><span class="n">a</span><span class="p">)</span> <span class="p">((</span><span class="n">delta_</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">zeta</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="o">~</span><span class="p">,</span><span class="n">Phi_min</span><span class="p">]</span> <span class="p">=</span> <span class="n">fminbnd</span><span class="p">(</span><span class="n">Phi</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">varphi_recons</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="n">Phi_min</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">figure</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">delta_test</span><span class="p">,</span><span class="n">varphi</span><span class="p">(</span><span class="n">delta_test</span><span class="p">),</span><span class="s">&#39;b&#39;</span><span class="p">,</span><span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span> <span class="n">hold</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">delta_test</span><span class="p">,</span><span class="n">varphi_recons</span><span class="p">,</span><span class="s">&#39;r--&#39;</span><span class="p">,</span><span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;delta&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl"><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;varphi(delta)&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">legend</span><span class="p">({</span><span class="s">&#39;varphi(delta)&#39;</span><span class="p">,</span><span class="s">&#39;Half-quadratic decomposition&#39;</span><span class="p">},</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">,</span><span class="s">&#39;Location&#39;</span><span class="p">,</span><span class="s">&#39;best&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">title</span><span class="p">(</span><span class="s">&#39;Half-quadratic decomposition check&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">disp</span><span class="p">(</span><span class="s">&#39;Legendre transform and half-quadratic decomposition demonstrations completed.&#39;</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><img src="/img/legendre/3.png" style="width:100%;" />
<h2 id="在半二次优化中引入勒让德变换">在半二次优化中引入勒让德变换<a hidden class="anchor" aria-hidden="true" href="#在半二次优化中引入勒让德变换">#</a></h2>
<p>我们刚刚的思路非常美好，现在只需要分开优化就好了，但是现在我们有两个前置问题</p>
<ul>
<li>
<p>$ \varphi(\delta) = \inf_a \left[ \frac{1}{2} (\delta - a)^2 + \zeta(a) \right] $ 怎么构建的？</p>
</li>
<li>
<p>$\zeta(a)$ 怎么构建？</p>
</li>
</ul>
<p>我们现在推导证明:
$$
\varphi(\delta) = \inf_a \left[ \frac{1}{2} (\delta - a)^2 + \zeta(a) \right]
$$
<div
    class="alert alert-warning"    role="alert"><text><p><strong>证明</strong></p>
<p>引入一个新的<strong>辅助函数</strong> $g(\delta)$ ，定义为：
$$
g(\delta) = \frac{\delta^2}{2} - \varphi(\delta).
$$
这里 $g(\delta)$ 被设计为一个严格凸函数（二次项 $\frac{\delta^2}{2}$ 保证了凸性）。</p>
<p>我们对 $g(\delta)$ 应用勒让德变换 $g^*(a)$ <em>：</em></p>
<div> $$ g^*(a) = \sup_{\delta \in \mathbb{R}} \big[ a \delta - g(\delta) \big] $$ </div>
<p>代入 $g(\delta) = \frac{\delta^2}{2} - \varphi(\delta)$ ，勒让德变换展开为：</p>
<div> $$ g^*(a) = \sup_{\delta \in \mathbb{R}} \left[ a \delta - \frac{\delta^2}{2} + \varphi(\delta) \right] $$ </div>
<p>将辅助函数 $\zeta(a)$ 定义为：</p>
<div> $$ \zeta(a) = g^*(a) - \frac{a^2}{2} $$ </div>
<p><em>代入</em> $g^*(a)$ 的表达式，得：
$$
\zeta(a) = \sup_{\delta \in \mathbb{R}} \left[ \varphi(\delta) - \frac{ (\delta - a)^2 }{2} \right]
$$
这表明 $\zeta(a)$ 是由 $\varphi(\delta)$ 和二次项 $\frac{ (\delta - a)^2 }{2}$ 的优化分解所定义的。</p>
<p>利用双重勒让德变换的性质 $g = g^{**}$ 的性质，我们可以写出</p>
<div> $$ g(\delta) = g^{**}(\delta) $$ </div>
<div> $$ g(\delta) = \sup_{a} \big[ a \delta - g^*(a) \big] $$ </div>
<p>结合 $g(\delta) = \frac{\delta^2}{2} - \varphi(\delta)$ ，可以进一步推导出：</p>
<div> $$ \frac{\delta^2}{2} - \varphi(\delta) = \sup_{a} \big[ a \delta - g^*(a) \big] $$ </div>
<p>由上述方程，可以得到：</p>
<div> $$ \varphi(\delta) = \frac{\delta^2}{2} - \sup_{a} \big[ a \delta - g^*(a) \big] $$ </div>
<p>进一步等价为：</p>
<div> $$ \varphi(\delta) = \frac{\delta^2}{2} + \inf_{a} \big[ g^*(a) - a \delta \big] $$ </div>
<p>将 $g^*(a)$ 的定义代入：
$$
\varphi(\delta) = \frac{\delta^2}{2} + \inf_{a} \left[ \zeta(a) + \frac{a^2}{2} - a \delta \right]
$$
重新整理：
$$
\varphi(\delta) = \inf_{a} \left[ \frac{ (\delta - a)^2 }{2} + \zeta(a) \right]
$$
这就得到了半二次分解的基本形式。</p>
</text></div>
</p>
<p>为了进一步分析辅助变量 $a$，考虑优化问题：
$$
\inf_{a} \left[ \frac{ (\delta - a)^2 }{2} + \zeta(a) \right]
$$
对优化准则求导：
$$
\frac{\partial}{\partial a} \left[ \frac{ (\delta - a)^2 }{2} + \zeta(a) \right] = (a - \delta) + \zeta^{\prime}(a) = 0
$$
解出最优 $a = \bar{a}$：
$$
\bar{a} = \delta - \zeta^{\prime}(a)
$$
结合 $\zeta^{\prime}(a) = g^{\prime}(a)$ ，可以进一步得到：
$$
\bar{a} = g^{*\prime -1} (\delta)
$$
或简化为：
$$
\bar{a} = g^{\prime}(\delta) = \delta - \varphi^{\prime}(\delta)
$$</p>
<p>通过上述推导，我们得到：</p>
<ol>
<li>半二次分解的标准形式：</li>
</ol>
<p>$$
\varphi(\delta) = \inf_{a} \left[ \frac{ (\delta - a)^2 }{2} + \zeta(a) \right]
$$</p>
<p>其中 $\zeta(a) = g^*(a) - \frac{a^2}{2}$ 是辅助函数。</p>
<ol start="2">
<li>最优辅助变量的表达式：</li>
</ol>
<p>$$
\bar{a} = \delta - \varphi^{\prime}(\delta)
$$</p>
<p>这个理论保证了对于任何给定的 $\varphi(\delta)$，我们都能通过构造辅助变量 $a$ 来优化原始函数。</p>
<p><strong>总结</strong></p>
<p>原始优化问题的目标函数为：
$$
\mathcal{J}(x) = | \mathbf{y} - \mathbf{H} \mathbf{x} |^2 + \mu \sum_{p \sim q} \varphi(x_p - x_q)
$$
为了解决非二次项 $\varphi(x_p - x_q)$ ，引入辅助变量 $a_{pq}$ ，将原始准则扩展为：
$$
\widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a}) = | \mathbf{y} - \mathbf{H} \mathbf{x} |^2 + \mu \sum_{p \sim q} \left[ \frac{1}{2} \big( (x_p - x_q) - a_{pq} \big)^2 + \zeta(a_{pq}) \right]
$$</p>
<ul>
<li>$a_{pq}$ 是辅助变量，用于解耦 $x_p$ 和 $x_q$ 。 $\zeta(a_{pq})$ 是通过勒让德变换定义的辅助函数。</li>
</ul>
<p><strong>算法策略：交替优化（Alternating Minimization）</strong></p>
<p><strong>(1) 对</strong> $\mathbf{x}$ <strong>固定</strong> $\mathbf{a}$ <strong>进行优化</strong></p>
<p>在固定 $\mathbf{a}$ 的情况下，优化目标函数变为关于 $\mathbf{x}$ 的二次问题：
$$
\widetilde{\mathbf{x}}(\mathbf{a}) = \arg\min_{\mathbf{x}} \widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a})
$$
这是一个标准的二次优化问题，可以通过解析解（如线性代数方法）或数值方法高效求解。</p>
<p><strong>(2) 对</strong> $\mathbf{a}$ <strong>固定</strong> $\mathbf{x}$ <strong>进行优化</strong></p>
<p>在固定 $\mathbf{x}$ 的情况下，优化目标函数变为关于 $\mathbf{a}$ 的问题：
$$
\widetilde{\mathbf{a}}(\mathbf{x}) = \arg\min_{\mathbf{a}} \widetilde{\mathcal{J}}(\mathbf{x}, \mathbf{a})
$$
这个优化问题也可以通过显式公式解出，因为 $\zeta(a)$ 是预定义的。</p>
<p>通过在这两个步骤之间交替迭代，逐步接近全局最优解。</p>
<ul>
<li>
<p><strong>变量的相互作用（Interacting Variables）</strong>：</p>
<ul>
<li>原始问题中的变量 $x_p$ 和 $x_q$ 存在耦合关系（通过 $\varphi(x_p - x_q)$）。</li>
<li>扩展准则通过引入 $a_{pq}$ ，解耦了变量 $\mathbf{x}$ 和 $\mathbf{a}$ ，从而简化了优化问题。</li>
</ul>
</li>
<li>
<p><strong>优化问题的本质</strong>：</p>
<ul>
<li>原始问题是非二次的，且变量相互作用；</li>
<li>扩展后，尽管存在交互，但问题本质上是二次的，因此易于求解。</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="c">%% 半二次优化示例</span>
</span></span><span class="line"><span class="cl"><span class="c">% 注意：我们已定义 s 和 varphi，上述 s=0.5 也适用于此</span>
</span></span><span class="line"><span class="cl"><span class="c">% 新增phi_prime定义(在之前未定义，需新增)</span>
</span></span><span class="line"><span class="cl"><span class="n">phi_prime</span> <span class="p">=</span> <span class="p">@(</span><span class="n">delta</span><span class="p">)</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span><span class="o">&lt;</span><span class="p">=</span><span class="n">s</span><span class="p">)</span><span class="o">.*</span><span class="n">delta</span> <span class="o">+</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span><span class="o">&gt;</span><span class="n">s</span><span class="p">)</span><span class="o">.*</span><span class="n">s</span><span class="o">.*</span><span class="nb">sign</span><span class="p">(</span><span class="n">delta</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 以下半二次优化1D信号示例</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 参数设置(对于优化问题)</span>
</span></span><span class="line"><span class="cl"><span class="n">N</span> <span class="p">=</span> <span class="mi">100</span><span class="p">;</span>            <span class="c">% 信号长度</span>
</span></span><span class="line"><span class="cl"><span class="n">mu</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>           <span class="c">% 正则化参数</span>
</span></span><span class="line"><span class="cl"><span class="n">maxIter</span> <span class="p">=</span> <span class="mi">50</span><span class="p">;</span>       <span class="c">% 最大迭代次数</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 生成观测数据 y (用 x_true 加噪声)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_true</span> <span class="p">=</span> <span class="nb">sin</span><span class="p">(</span><span class="nb">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="p">,</span><span class="n">N</span><span class="p">))</span><span class="o">&#39;</span><span class="p">;</span> <span class="c">% 真值</span>
</span></span><span class="line"><span class="cl"><span class="n">noise</span> <span class="p">=</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="nb">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="p">=</span> <span class="n">x_true</span> <span class="o">+</span> <span class="n">noise</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 定义算子H为单位映射，这里H = I</span>
</span></span><span class="line"><span class="cl"><span class="n">H</span> <span class="p">=</span> <span class="nb">eye</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 定义初始值</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="p">=</span> <span class="n">y</span><span class="p">;</span>              <span class="c">% 初始解</span>
</span></span><span class="line"><span class="cl"><span class="n">a</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>   <span class="c">% 辅助变量</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 构造差分矩阵 R (N-1 x N)</span>
</span></span><span class="line"><span class="cl"><span class="n">R</span> <span class="p">=</span> <span class="n">spdiags</span><span class="p">([</span><span class="nb">ones</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="nb">ones</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 系数矩阵A_x = 2I + mu R&#39;R</span>
</span></span><span class="line"><span class="cl"><span class="n">A_x</span> <span class="p">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">speye</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span><span class="o">*</span><span class="p">(</span><span class="n">R</span><span class="o">&#39;*</span><span class="n">R</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 迭代求解</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">iter</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">maxIter</span>
</span></span><span class="line"><span class="cl">    <span class="c">% Step 1: 固定 a 更新 x</span>
</span></span><span class="line"><span class="cl">    <span class="n">rhs</span> <span class="p">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">y</span> <span class="o">+</span> <span class="n">mu</span><span class="o">*</span><span class="n">R</span><span class="o">&#39;*</span><span class="n">a</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="p">=</span> <span class="n">A_x</span><span class="o">\</span><span class="n">rhs</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c">% Step 2: 固定 x 更新 a</span>
</span></span><span class="line"><span class="cl">    <span class="n">delta</span> <span class="p">=</span> <span class="n">R</span><span class="o">*</span><span class="n">x</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">    <span class="n">a</span> <span class="p">=</span> <span class="n">delta</span> <span class="o">-</span> <span class="n">phi_prime</span><span class="p">(</span><span class="n">delta</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c">% 显示进度(每10次迭代显示一次)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">mod</span><span class="p">(</span><span class="n">iter</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="n">phi_val</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">k</span><span class="p">=</span><span class="mi">1</span><span class="p">:(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">d</span> <span class="p">=</span> <span class="n">delta</span><span class="p">(</span><span class="n">k</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">&lt;</span><span class="p">=</span><span class="n">s</span>
</span></span><span class="line"><span class="cl">                <span class="n">phi_val</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="p">=</span> <span class="n">d</span>^<span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span>
</span></span><span class="line"><span class="cl">                <span class="n">phi_val</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="p">=</span> <span class="n">s</span><span class="o">*</span><span class="nb">abs</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">-</span><span class="n">s</span>^<span class="mi">2</span><span class="o">/</span><span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="k">end</span>
</span></span><span class="line"><span class="cl">        <span class="k">end</span>
</span></span><span class="line"><span class="cl">        <span class="n">J_val</span> <span class="p">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>^<span class="mi">2</span> <span class="o">+</span> <span class="n">mu</span><span class="o">*</span><span class="n">sum</span><span class="p">(</span><span class="n">phi_val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">fprintf</span><span class="p">(</span><span class="s">&#39;Iter %d, J = %f\n&#39;</span><span class="p">,</span> <span class="n">iter</span><span class="p">,</span> <span class="n">J_val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">end</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c">% 结果展示</span>
</span></span><span class="line"><span class="cl"><span class="n">figure</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span> <span class="s">&#39;k-&#39;</span><span class="p">,</span> <span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span> <span class="n">hold</span> <span class="n">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s">&#39;b:&#39;</span><span class="p">,</span> <span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span> 
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s">&#39;r--&#39;</span><span class="p">,</span> <span class="s">&#39;LineWidth&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">legend</span><span class="p">(</span><span class="s">&#39;True x&#39;</span><span class="p">,</span><span class="s">&#39;Noisy y&#39;</span><span class="p">,</span><span class="s">&#39;Reconstructed x&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;Index&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Amplitude&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">title</span><span class="p">(</span><span class="s">&#39;Half-Quadratic Optimization with Huber Regularization&#39;</span><span class="p">,</span><span class="s">&#39;Interpreter&#39;</span><span class="p">,</span><span class="s">&#39;none&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">grid</span> <span class="n">on</span><span class="p">;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><img src="/img/legendre/4.png" style="width:100%;" />
<p>半二次优化和相关问题中<strong>变量更新的可能方法</strong></p>
<p><strong>1. 直接计算（Direct Calculus）</strong></p>
<p>这类方法通过解析表达式或直接矩阵操作更新变量，常用技术包括：</p>
<ul>
<li><strong>闭式解（Compact or Closed Form）</strong>：当问题有解析解时，可以通过直接计算得到。例如，二次优化问题可以通过矩阵代数方法解决。</li>
<li><strong>矩阵求逆（Matrix Inversion）</strong>：对于线性系统，可以通过求解方程 $\mathbf{A} \mathbf{x} = \mathbf{b}$ 来更新 $\mathbf{x}$，如通过矩阵求逆或其他方法。</li>
</ul>
<p>适用场景：</p>
<ul>
<li>问题规模较小，或系统稀疏，矩阵求逆的成本可接受。</li>
</ul>
<p><strong>2. 线性系统的算法（Algorithms for Linear Systems）</strong></p>
<p>这部分涵盖了经典的线性系统求解算法，适用于优化问题中涉及的线性方程组：</p>
<ul>
<li><strong>高斯消元法（Gauss）和高斯-约当法（Gauss-Jordan）</strong>：通过消元法求解线性系统。</li>
<li><strong>代入法（Substitution）</strong>：在某些特定的线性系统中，可以逐步代入解。</li>
<li><strong>三角分解（Triangularisation）</strong>：将矩阵分解为上下三角矩阵以加速求解。</li>
</ul>
<p>适用场景：</p>
<ul>
<li>当优化目标是二次形式，且涉及线性方程组时。</li>
</ul>
<p><strong>3. 数值优化（Numerical Optimization）</strong></p>
<p>针对非线性或复杂目标函数，使用数值优化技术逐步更新变量：</p>
<ul>
<li><strong>梯度下降（Gradient Descent）及其变种</strong>：
<ul>
<li>标准梯度下降法通过计算梯度逐步逼近最优解；</li>
<li>可以结合动量、学习率调整等技术加速收敛。</li>
</ul>
</li>
<li><strong>逐像素更新（Pixel-Wise Update）</strong>：
<ul>
<li>在图像处理问题中，逐像素优化是常用策略，尤其是涉及稀疏正则化的场景。</li>
</ul>
</li>
</ul>
<p>适用场景：</p>
<ul>
<li>问题非线性或不可微，梯度信息可用但解析解不可得。</li>
</ul>
<p><strong>4. 对角化（Diagonalization）</strong></p>
<p>通过对矩阵的对角化或循环近似来加速计算：</p>
<ul>
<li><strong>循环矩阵近似（Circulant Approximation）</strong>：在某些场景下，可以将矩阵近似为循环矩阵，从而通过快速傅里叶变换（FFT）简化运算。</li>
<li><strong>通过快速傅里叶变换（Diagonalization by FFT）</strong>：对角化操作可以通过 FFT 快速实现，极大加速求解过程。</li>
</ul>
<p>适用场景：</p>
<ul>
<li>当系统是周期性或卷积形式，FFT 是高效的选择。</li>
</ul>
<p><strong>5. 特殊算法（Special Algorithms for 1D Cases）</strong></p>
<p>针对一维情况，可以利用特别设计的算法：</p>
<ul>
<li><strong>递归最小二乘法（Recursive Least Squares, RLS）</strong>：
<ul>
<li>适用于时间序列数据或动态系统建模。</li>
</ul>
</li>
<li><strong>卡尔曼滤波或平滑（Kalman Smoother/Filter）</strong>：
<ul>
<li>经典算法，用于估计动态系统的状态，可以扩展到快速变种以适应实时应用。</li>
</ul>
</li>
</ul>
<p>适用场景：</p>
<ul>
<li>动态系统、一维优化问题，尤其是涉及时间序列数据的场景。</li>
</ul>
<p><strong>辅助变量的更新策略</strong> 或者说 <strong>辅助变量的分离性</strong></p>
<p>扩展的准则为：
$$
\widetilde{\mathcal{J}}(a) = \sum_{p \sim q} \left[ \frac{1}{2} \big( (x_p - x_q) - a_{pq} \big)^2 + \zeta(a_{pq}) \right]
$$
这表明该问题：</p>
<ul>
<li><strong>非二次</strong>：因为 $\zeta(a_{pq})$ 的形式可能不是二次的；</li>
<li><strong>可分离</strong>：由于各 $a_{pq}$ 之间无交互，因此可以并行计算 $a_{pq}$。</li>
</ul>
<p><strong>2. 第二个优化优势：增强特性</strong></p>
<p>通过对辅助变量的分离优化，得到以下特性：</p>
<ul>
<li><strong>并行计算（Parallel Computation）</strong>：每个 $a_{pq}$ 可以独立更新，无需遍历或循环。</li>
<li><strong>显式更新（Explicit Updates）</strong>：辅助变量的更新可以通过解析公式完成，无需进一步的内层迭代。</li>
</ul>
<p>这使得优化过程高效且适合并行处理硬件，如 GPU。</p>
<p><strong>3. 辅助变量的更新公式</strong></p>
<p>通过优化准则对 $a_{pq}$ 求导，得到更新公式：</p>
<div> $$ \widetilde{a}_{pq} = \delta_{pq} - \varphi^{\prime}(\delta_{pq}) $$ </div>
<p>其中：</p>
<ul>
<li>$\delta_{pq} = x_p - x_q$ 表示当前变量 $x_p$ 和 $x_q$ 的差异；</li>
<li>$\varphi^{\prime}(\delta_{pq})$ 是正则化函数 $\varphi(\delta_{pq})$ 的导数。</li>
</ul>
<p><strong>Huber 函数特例</strong></p>
<p>对于 Huber 函数：
$$
\varphi(\delta) = \begin{cases}
\frac{\delta^2}{2} &amp; |\delta| \leq s, \
s |\delta| - \frac{s^2}{2} &amp; |\delta| &gt; s,
\end{cases}
$$
其导数为：
$$
\varphi^{\prime}(\delta) = \begin{cases}
\delta &amp; |\delta| \leq s, \
s \cdot \text{sign}(\delta) &amp; |\delta| &gt; s.
\end{cases}
$$
对应的辅助变量更新为：</p>
<div> $$ \widetilde{a}_{pq} = \delta_{pq} \cdot \left[ 1 - 2\alpha \cdot \min\left(1, \frac{s}{|\delta_{pq}|} \right) \right] $$ </div>
<p><strong>总结与扩展</strong></p>
<ul>
<li>
<p><strong>图像反卷积（Image Deconvolution）</strong>：</p>
<p>主要目标是通过正则化方法恢复原始图像。</p>
</li>
<li>
<p><strong>边缘保持与非二次正则化（Edge Preserving and Non-Quadratic Penalties）</strong>：</p>
<ul>
<li>包括灰度梯度（如边缘检测）的惩罚；</li>
<li>支持凸或部分非凸的正则化。</li>
</ul>
</li>
<li>
<p><strong>数值计算与半二次方法（Numerical Computations: Half-Quadratic Approach）</strong>：</p>
<ul>
<li>迭代优化策略结合分离性质；</li>
<li>使用循环矩阵近似（Circulant Approximation）或快速傅里叶变换（FFT）加速计算。</li>
</ul>
</li>
</ul>
<p>下一步研究方向包括：</p>
<ul>
<li>加入约束条件以提高图像分辨率；</li>
<li>自动估计超参数（正则化参数）或设备参数。</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="http://zehua.eu/zh/posts/machinelearning_cn/diffusevae%E7%BD%91%E7%AB%99%E7%89%88/">
    <span class="title">« 上一页</span>
    <br>
    <span>论文阅读 - DiffuseVAE 详解</span>
  </a>
  <a class="next" href="http://zehua.eu/zh/posts/machinelearning_cn/vae/">
    <span class="title">下一页 »</span>
    <br>
    <span>变分自编码器VAE</span>
  </a>
</nav>

  </footer>
</article>

<div class="post-password"></div>
  
</div>
    </main>
    
<footer class="footer">
        <span><a href="https://github.com/adityatelange/hugo-PaperMod/graphs/contributors">PaperMod</a></span> · 


    <span>
        
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a>  
        
    </span>
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
    <br>
    <span id="busuanzi_container_page_pv" style='display:none'>
        一共有<span id="busuanzi_value_page_pv"></span>人来过这里
    </span>
    · <span id="last_change">
        最后更新于2024年12月8日
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
