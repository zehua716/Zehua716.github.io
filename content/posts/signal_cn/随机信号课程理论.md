---
title: "随机信号与噪音"
# author: "Zehua"
date: "2023-12-20T16:25:17+01:00"
lastmod: "2024-11-13T17:12:35+08:00"
lang: "zh"
draft: false
summary: "主要介绍随机信号及其统计特性，包括协方差函数与功率谱密度，最后简单介绍维纳滤波器在信号处理中的应用"
description: ""
tags: ["信号处理", "随机过程", "统计分析", "滤波器设计"]
# categories: "posts"
#cover:
    #image: "img/signal.png"
# comments: true
# hideMeta: false
searchHidden: true
# ShowBreadCrumbs: true
# ShowReadingTime: false

---

##  一维随机变量

#### 概率密度函数 

对随机变量  $X$ 来说，其概率密度函数  $f_x(x)$ 满足：
$$
\int_{-\infty}^{\infty} f_x(x)\,dx = 1, \quad f_x(x) \geq 0 \,\, \forall x \in \mathbb{R}
$$

即  $f_x(x)$ 是非负函数，其积分总和为 1。

#### 一维高斯分布

对于一维正态（高斯）分布  $X \sim \mathcal{N}(\mu, \sigma^2)$  ，其概率密度函数为：
$$
f_X(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$

```matlab
% 生成一维高斯随机变量
N = 10^6; % 样本数
mu = 2;   % 均值
sigma = 3;% 标准差
X = mu + sigma*randn(N,1);

% 定义符号变量x
syms x 

% 一维高斯分布pdf定义
fX = (1/(sqrt(2*pi)*sigma))*exp(-((x - mu)^2)/(2*sigma^2));

% 验证归一化: ∫ fX(x) dx = 1
int_fX = int(fX, x, -inf, inf); 
disp(['一维高斯分布积分验证（应为1）：', char(vpa(simplify(int_fX),10))]);
```

#### 概率的计算

若需计算事件  $\{X \in [m,M]\}$ 的概率，有：

<div>$$P\left\{ x \in [m, M] \right\} = \int_{m}^{M} f_x(x) \, dx$$</div>

#### 数学期望 

对随机变量  $X$ ，其期望为：
$$
E(X) = \int_{-\infty}^{\infty} x f_x(x) \, dx
$$

对任意函数  $\varphi(X)$ 的期望：
$$
E(\varphi(X)) = \int_{-\infty}^{\infty} \varphi(x) f_x(x) \, dx
$$
期望是加权平均值（加权由概率密度给出）

#### 方差与标准差

方差定义为：
$$
\sigma_x^2 = \mathrm{Var}[X] = E[(X - E[X])^2]
$$
标准差为方差的平方根：
$$
\sigma_x = \sqrt{\mathrm{Var}[X]}
$$
方差和标准差度量随机变量取值围绕其期望的离散程度。分布越分散，方差和标准差越大。

#### 均方根误差 (RMSE)  

在数据拟合、预测或信号处理领域，用均方根误差来衡量预测值  $\hat{y}_i$ 与真实值  $y_i$ 之间的偏差：
<div>
$$\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$
</div>
RMSE 体现了预测误差的平均幅度，值越小说明预测越接近真实值。在信号与控制领域，RMSE 常用于评价模型的估计精度或滤波效果。

#### 代码示例

```matlab
% 验证期望与方差
est_mu = mean(X);
est_var = var(X);

fprintf('理论均值 = %.2f, 实际估计均值 = %.2f\n', mu, est_mu);
fprintf('理论方差 = %.2f, 实际估计方差 = %.2f\n', sigma^2, est_var);

% 验证概率计算：P(X in [m,M])
m = 0; M = 5;
p_est = mean(X>=m & X<=M);
fprintf('P(X in [%.1f, %.1f])的模拟值为: %.4f\n', m, M, p_est);
```

在上述代码中，我们使用 `means` 来计算`p_est`即概率值，而不是使用之前定义中的对概率密度进行积分的形式。这个方法叫做蒙特卡罗模拟法，其思路是，先统计区间中随机样本 `x` 个数，然后再除以 `X` 样本总数，得到这部分区域占总区域的比例就是概率。

```matlab
% RMSE示例（其中真实值和预测值替换成实际数据）
y = randn(N,1);          % 假设的真实值
hat_y = y + 0.5*randn(N,1); % 假设的预测值
RMSE = sqrt(mean((y - hat_y).^2));
fprintf('RMSE = %.4f\n', RMSE);
```



## 两维随机变量

#### 联合概率密度函数

对两个随机变量   $X, Y$   而言，其联合概率密度函数   $f_{X,Y}(x,y)$   满足：
$$
\iint_{\mathbb{R} \times \mathbb{R}} f_{X,Y}(x,y)\,dx\,dy = 1,\quad f_{X,Y}(x,y) \geq 0
$$

这里   $f_{X,Y}(x,y)$   对所有   $x, y \in \mathbb{R}$   非负，并通过对整个二维平面的积分为 1 来保证这是一个有效的概率密度函数。

- 在一维情况下，概率密度函数  $f_X(x)$  表示  $X$  在点  $x$  的密度。
- 在二维情况下，联合概率密度函数  $f_{X,Y}(x,y)$  则表示  $X,Y$  同时在点  $(x,y)$  附近出现的“概率密度”。由于是密度值，对它进行二维积分才能得到相应的概率。

```matlab
clear; clc; close all;

%% 定义符号变量与参数
syms x y real

% 二维高斯分布参数
mu_y = 2;          % E[Y]
sigma_y = 1.5;     % Var(Y)=sigma_y^2
rho_xy = 0.3;      % 相关系数rho_{xy}, 范围(-1,1)
```

#### 二维高斯分布

若  $X,Y$  联合呈正态分布  $\mathcal{N}(\mu_x, \mu_y, \sigma_x^2, \sigma_y^2, \rho_{xy}) $，其联合概率密度函数为：
$$
f_{X,Y}(x,y) = \frac{1}{2\pi \sigma_x \sigma_y \sqrt{1-\rho_{xy}^2}} \exp\left(-\frac{1}{2(1-\rho_{xy}^2)}\left[\left(\frac{x-\mu_x}{\sigma_x}\right)^2 + \left(\frac{y-\mu_y}{\sigma_y}\right)^2 - 2\rho_{xy}\left(\frac{x-\mu_x}{\sigma_x}\right)\left(\frac{y-\mu_y}{\sigma_y}\right)\right]\right)
$$

-  $\rho_{xy}$  为  $X,Y$  的相关系数（取值范围在  $-1$ 至 $1$ 之间）。当  $\rho_{xy}=0$  时，两变量在统计意义上不相关。

```matlab
%% 二维高斯分布pdf定义
fXY = (1/(2*pi*sigma_x*sigma_y*sqrt(1-rho_xy^2))) * ...
      exp(-1/(2*(1-rho_xy^2)) * ( ((x - mu_x)/sigma_x)^2 + ((y - mu_y)/sigma_y)^2 ...
      - 2*rho_xy*((x - mu_x)/sigma_x)*((y - mu_y)/sigma_y) ) );

% 验证二维高斯分布归一化: ∫∫ f_{X,Y}(x,y) dx dy = 1
int_fXY = int(int(fXY, x, -inf, inf), y, -inf, inf);
disp(['二维高斯分布积分验证（应为1）：', char(vpa(simplify(int_fXY),10))]);
```

#### 二维概率的计算

对于二维随机变量  $X,Y$  ，任意矩形区域  $[x_m,x_M]\times[y_m,y_M]$  上的概率为：

$$
P[x_m \leq X \leq x_M, \; y_m \leq Y \leq y_M] = \int_{x_m}^{x_M}\int_{y_m}^{y_M} f_{X,Y}(x, y)\,dy\,dx
$$

```matlab
%% 二维概率区域积分
% P[x_m<=X<=x_M, y_m<=Y<=y_M] = ∫_{x_m}^{x_M}∫_{y_m}^{y_M} fXY dx dy
x_m = -1; x_M = 1;
y_m = 1;  y_M = 3;
region_prob = vpa(int(int(fXY, y, y_m, y_M), x, x_m, x_M),10);
disp(['给定区域下的概率：', char(vpa(region_prob, 10))]);
```



#### 边缘概率密度函数

给定联合概率密度函数  $f_{X,Y}(x,y)$ ，对于  $X$  的边缘分布由联合分布对  $y$  积分得到：
$$
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dy
$$

同理，对  $x$  积分可得  $f_Y(y)$ :
$$
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y)\,dx.
$$
边缘分布描述单个变量的分布情况，是由联合分布“合并”掉另一维度获得的。

```matlab
%% 边缘分布计算
fX_from_joint = int(fXY, y, -inf, inf);  % 对y积分得到fX
fY_from_joint = int(fXY, x, -inf, inf);  % 对x积分得到fY

% 验证fX_from_joint归一化
disp(['X的边缘分布归一化验证（应为1）：', char(vpa(simplify(int(fX_from_joint, x, -inf, inf)),10))]);

% 验证fY_from_joint归一化
disp(['Y的边缘分布归一化验证（应为1）：', char(vpa(simplify(int(fY_from_joint, y, -inf, inf)),10))]);
```



#### 条件概率密度函数

条件分布描述在已知一个变量取值的前提下，另一个变量的分布特性，从而反映随机变量之间的条件依赖关系。在给定  $Y=y_0$  条件下， $X$  的条件概率密度函数定义为：
$$
f_{X|Y}(x|y_0) = \frac{f_{X,Y}(x, y_0)}{f_Y(y_0)}
$$

分母不能为0



**重要性质:** 对于给定条件 $Y=y_0$ 的条件概率密度函数 $f_{X|Y}(x|y_0)$，在 $x$ 上的积分必为 1

{{< alert class="warning" >}}
**证明:**  

将该条件密度对 $x$ 从 $-\infty$ 到 $\infty$ 积分时，有：
$$
\int_{-\infty}^{\infty} f_{X|Y}(x|y_0) dx = \frac{\int_{-\infty}^{\infty} f_{X,Y}(x,y_0) dx}{f_Y(y_0)} = \frac{f_Y(y_0)}{f_Y(y_0)} = 1
$$
其本质在于，$f_{X|Y}(x|y_0)$ 是已知 $Y$ 取某个值时 $X$ 的条件概率密度，就是 $X$ 的概率密度函数，对 $x$ 积分必定为1

{{< /alert >}}



```matlab
%% 条件概率分布验证
% f_{X|Y}(x|y) = f_{X,Y}(x,y)/f_Y(y)
y0 = 2; 
fX_given_Y = simplify(fXY / subs(fY_from_joint, y, y0)); 
int_fX_given_Y = int(subs(fX_given_Y, y, y0), x, -inf, inf);
disp(['条件分布 在x上的积分（应为1）：', char(vpa(simplify(int_fX_given_Y),10))]);
```

`subs(fY, y, y0)`：用 `y0=2` 替换 `fY(y)` 中的 `y` ，得到 $f_Y(2)$。然后再用`simplify` 函数进行代数化简

#### 协方差 

对于随机变量  $X,Y$ ，协方差定义为：
$$
\text{Cov}[X,Y] = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]
$$

其中:

- $\text{Cov}[X,X] = \text{Var}[X]$，$\text{Cov}[Y,Y] = \text{Var}[Y]$  

- 对常数因子有线性性质：  
  $$
  \text{Cov}[\alpha X, Y] = \alpha \text{Cov}[X,Y], \quad \text{Cov}[\alpha X, \beta Y] = \alpha \beta \text{Cov}[X,Y]
  $$

#### 相关系数 

相关系数是协方差的归一化版本，其定义为：
$$
\rho_{X,Y} = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X)} \cdot \sqrt{\text{Var}(Y)}}
$$

-  $\rho_{X,Y}$  在  $-1$ 和 $1$  之间。  
-  $\rho_{X,Y}=1$  表示完美正线性相关， $\rho_{X,Y}=-1$  表示完美负线性相关， $\rho_{X,Y}=0$  表示无线性相关性。  

```matlab
%% 协方差与相关系数计算验证
% E[X]=mu_x, E[Y]=mu_y, Cov(X,Y)=rho_xy*sigma_x*sigma_y
% E[XY] = E[X]E[Y] + Cov(X,Y)
E_X = mu_x;
E_Y = mu_y;
Cov_XY = rho_xy*sigma_x*sigma_y;
E_XY = E_X*E_Y + Cov_XY;

calc_rho = Cov_XY/(sigma_x*sigma_y);

disp(['理论计算的协方差Cov(X,Y)=', num2str(Cov_XY)]);
disp(['由协方差计算得到的rho_{X,Y}=', num2str(calc_rho), '，与设定的rho_xy = ', num2str(rho_xy), ' 对比']);
```



#### 随机变量对的特性

- 线性特性

  对任意实常数  $\alpha, \beta$  与随机变量函数  $\varphi(x)$  和  $\psi(x)$  有：

$$
\quad E \left[ \alpha \varphi(x) + \beta \psi(x) \right] = \alpha E[\varphi(x)] + \beta E[\psi(x)]
$$

- 常数特性

$$
\quad E[\alpha] = \alpha
$$

- 期望与方差

  若  $Y = aX + b$  ，其中  $a,b$  为常数，则有：
  $$
  \quad E[Y] = E[ax + b] = aE[x] + b
  $$
  方差对加法不敏感（仅对乘法敏感），有：

$$
\text{Var}[Y] = E[(Y - E[Y])^2] = E[a^2(X - E[X])^2] = a^2 \text{Var}[X]
$$



#### 不相关与独立性条件

若  $X,Y$  独立，则：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$
由此可推得：


$$
\begin{cases}
f_{y|x}(y|x) = f_y(y) \\\\
f_{x|y}(x|y) = f_x(x)\\
\end{cases}
$$

条件概率等于单独发生的概率，即在独立条件下，另一随机变量的已知并不改变某一随机变量的分布特征。

```matlab
%% 独立性验证
% 当rho_xy=0时，fXY应能分解为fX*fY
if abs(rho_xy) < 1e-12
    fXY_factorized = simplify(fX_from_joint * fY_from_joint);
    diff_expr = simplify(fXY - fXY_factorized);
    disp('rho_xy=0时，fXY与fX*fY的差值应为0：');
    disp(diff_expr);
else
    disp('rho_xy不为0，故X与Y不独立，此时fXY不等于fX*fY。');
end
```

回顾之前的协方差定义式:
$$
\text{Cov}[X,Y] = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]
$$
在**独立条件下**，有  $E[XY] = E[X]E[Y]$  ，故  $\text{Cov}[X,Y]=0$ 。但  $\text{Cov}[X,Y]=0$  不一定代表独立，只能代表不线性相关（零相关）。独立是更强的条件。**但是特殊情况下**：若  $X,Y$  联合服从二元高斯分布，则不相关 ( $\rho_{X,Y}=0$ ) 即可以推出独立。这是高斯分布下的特殊性质。当  $\rho_{X,Y}=0$  时，二元高斯分布的联合密度函数因子化为单独的  $X$  与  $Y$  密度函数之积，即：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$
因此，对于二维高斯分布：
$$
\rho_{X,Y}=0 \iff \text{Cov}[X,Y]=0 \implies X,Y \text{ 独立。}
$$

对于非高斯分布，不相关不保证独立，但独立却一定能保证不相关，因为独立必然导致  $E[XY] = E[X]E[Y]$ 。



{{< alert class="warning" >}}
**证明:**  不相关无法推出独立

**证明思路**：通过给出一个反例，展示存在不相关但不独立的随机变量。

设随机变量  $X$  满足：  
$$
P(X=1)=\tfrac{1}{2}, \quad P(X=-1)=\tfrac{1}{2}.
$$
则  $E[X]=0$  且  $X$  对称分布。定义随机变量  $Y=X^2$  ，则无论  $X=1$  还是  $X=-1$ ，有  $Y=1$ 。因此  $Y$  是一个退化随机变量，恒为1。

计算协方差：  
$$
E[XY] = E[X \cdot X^2] = E[X^3] = E[X] = 0,
$$
且  
$$
E[X]=0, \quad E[Y]=E[X^2]=1.
$$

所以：  
$$
\text{Cov}(X,Y) = E[XY] - E[X]E[Y] = 0 - 0\cdot1 = 0.
$$

此时  $X,Y$  不相关。但  $Y=X^2$  表明 $Y$ 的取值随 $X$ 的变化而定，二者不是独立关系。

由此举例可见，不相关并不能推出独立。

{{< /alert >}}



```matlab
%% 不相关但不独立的反例
% X: P(X=1)=0.5, P(X=-1)=0.5 => E[X]=0
% Y=X^2 => Y=1总是恒定 => E[Y]=1
% E[XY]=E[X]=0, Cov(X,Y)=0, 但Y由X决定，不独立
E_X_example = 0;
E_Y_example = 1;
E_XY_example = E_X_example; 
Cov_XY_example = E_XY_example - E_X_example*E_Y_example;
disp(['反例中Cov(X,Y)=', num2str(Cov_XY_example), ' -> Cov=0但X,Y不独立。']);
```



{{< alert class="warning" >}}
**证明：** 高斯分布的联合概率密度情况下，可以由不相关 $\to$ 独立，即 $\text{Cov}(x, y) = 0 \implies \rho_{xy} = 0$
$$
f_{xy}(x, y) = \dfrac{1}{2\pi \sigma_x \sigma_y \sqrt{1 - \rho_{xy}^2}} 
e^{-\dfrac{1}{2(1 - \rho_{xy}^2)} \left[ \left( \dfrac{x - \mu_x}{\sigma_x} \right)^2 + \left( \dfrac{y - \mu_y}{\sigma_y} \right)^2 - 2\rho_{xy} \left( \dfrac{x - \mu_x}{\sigma_x} \right) \left( \dfrac{y - \mu_y}{\sigma_y} \right) \right]}
$$

当  $\rho_{xy}=0$  时，上式中  $-2\rho_{xy}(\cdots)$  项消失，化简为：

$$
f_{X,Y}(x,y) = \frac{1}{2\pi \sigma_x \sigma_y}\exp\left(-\frac{1}{2}\left(\frac{x-\mu_x}{\sigma_x}\right)^2\right)\exp\left(-\frac{1}{2}\left(\frac{y-\mu_y}{\sigma_y}\right)^2\right)
$$

注意该表达式可分解为：
<div>
$$f_{X,Y}(x,y) = \underbrace{\frac{1}{\sqrt{2\pi}\sigma_x}e^{-\frac{(x-\mu_x)^2}{2\sigma_x^2}}}_{f_X(x)} \cdot \underbrace{\frac{1}{\sqrt{2\pi}\sigma_y}e^{-\frac{(y-\mu_y)^2}{2\sigma_y^2}}}_{f_Y(y)}$$
</div>

因此：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$

这表明  $X,Y$  是独立的。

{{< /alert >}}





{{< alert class="warning" >}}
**证明:**  若  $X,Y$  独立，则  $\text{Cov}(X,Y)=0$  （不相关）

若  $X,Y$  独立，则其联合概率密度函数满足：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y).
$$

计算  $E[XY]$ ：
$$
E[XY] = \iint xy f_{X,Y}(x,y)\,dx\,dy = \iint xy f_X(x)f_Y(y)\,dx\,dy
$$

由于可分离积分：
$$
E[XY] = \left(\int x f_X(x)\,dx\right)\left(\int y f_Y(y)\,dy\right) = E[X]E[Y]
$$

协方差定义为：
$$
\text{Cov}(X,Y) = E[XY] - E[X]E[Y]
$$

代入  $E[XY]=E[X]E[Y]$  得：
$$
\text{Cov}(X,Y) = E[X]E[Y] - E[X]E[Y] = 0
$$

由此可见，独立必然导致不相关。

{{< /alert >}}







## 随机向量

给定一个 $n$ 维随机向量 $\mathbf{x} = [x_1, x_2, \dots, x_n]^T$，其联合概率密度函数为 $f_x(x_1, x_2, \dots, x_n)$。该函数满足：

$$
f_x(x_1, x_2, \dots, x_n) \geq 0, \quad \forall x_1, x_2, \dots, x_n \in \mathbb{R}
$$

$$
\int_{-\infty}^{\infty} \dots \int_{-\infty}^{\infty} f_x(x_1, \dots, x_n) \, dx_1 \dots dx_n = 1
$$

对于任意超矩形区域 $[m_1,M_1]\times[m_2,M_2]\times\dots\times[m_n,M_n]$ 上的概率为：

$$
P\{x_1 \in [m_1,M_1], x_2 \in [m_2,M_2], \dots, x_n \in [m_n,M_n]\} 
= \int_{m_1}^{M_1} \int_{m_2}^{M_2} \dots \int_{m_n}^{M_n} f_x(x_1,\dots,x_n) \, dx_1 \dots dx_n
$$



#### 一阶矩（期望向量）

$$
m_x = E[\mathbf{x}] = 
\begin{bmatrix}
E[x_1] \\\\
E[x_2] \\\\
\vdots \\\\
E[x_n]
\end{bmatrix} \quad
$$

其中：

$$
E[x_n] =  \int_{-\infty}^{\infty} x_n \cdot f_{x_n}(x_n) \, dx_n
$$

这里 $f_{x_n}(x_n)$ 是 $x_n$ 的边缘分布。



#### 二阶矩（协方差矩阵）

定义随机向量 $\mathbf{x}$ 的协方差矩阵 $C_x$ 为：
$$
C_x = E[(\mathbf{x} - m_x)(\mathbf{x} - m_x)^T]
$$

将 $\mathbf{x}-m_x$ 展开：

$$
\mathbf{x}-m_x = 
\begin{bmatrix}
x_1 - E[x_1] \\\\
x_2 - E[x_2] \\\\
\vdots \\\\
x_n - E[x_n]\\
\end{bmatrix}
$$

因此：

$$
C_x = E \left[
\begin{bmatrix}
x_1 - E[x_1] \\\\
x_2 - E[x_2]  \\\\
\vdots  \\\\
x_n - E[x_n] \\\\ 
\end{bmatrix} \quad
\begin{bmatrix}
x_1 - E[x_1] & x_2 - E[x_2] & \dots & x_n - E[x_n] \quad
\end{bmatrix} 
\right]
$$

所以：

$$
C_x =
\begin{bmatrix}
\text{Var}(x_1) & \text{Cov}(x_1, x_2) & \dots & \text{Cov}(x_1, x_n) \\\\
\text{Cov}(x_2, x_1) & \text{Var}(x_2) & \dots & \text{Cov}(x_2, x_n) \\\\
\vdots & \vdots & \ddots & \vdots \\\\
\text{Cov}(x_n, x_1) & \text{Cov}(x_n, x_2) & \dots & \text{Var}(x_n)
\end{bmatrix}\quad
$$

若 $\mathbf{x}$ 的分量相互独立，则对任意 $i \neq j$，$\text{Cov}(x_i, x_j) = 0$，协方差矩阵为对角阵：

$$
C_x =
\begin{bmatrix}
\text{Var}(x_1) & 0 & \dots & 0 \\\\
0 & \text{Var}(x_2) & \dots & 0 \\\\
\vdots & \vdots & \ddots & \vdots \\\\
0 & 0 & \dots & \text{Var}(x_n)
\end{bmatrix}
$$





#### 协方差矩阵 $C_x$ 

- **对称性**：$C_x = C_x^T$

{{< alert class="warning" >}}

**证明**：
$$
C_x^T = \left( E[(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T] \right)^T 
= E[((\mathbf{x}-m_x)(\mathbf{x}-m_x)^T)^T] 
= E[(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T] = C_x
$$

{{< /alert >}}





对不对称看特征值即可，如果是实对称矩阵必定有实特征值，且特征向量构成一组正交基。但是需要注意，这个是不严谨的，因为有些非对称矩阵在特殊情况下也可能拥有全实特征值，因此后续加了 `issymmetric(C_x)`命令来再次检查对称性。

- **正定性**：$C_x$ 是一个半正定矩阵

{{< alert class="warning" >}}

**证明**：
对任意向量 $u$：
$$
u^T C_x u = u^T E[(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T] u 
= E[u^T(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T u] 
= E[(u^T(\mathbf{x}-m_x))^2] \geq 0
$$

若所有分量方差均大于0，那么意味着协方差矩阵特征值都大于0，则 $C_x$ 正定。

{{< /alert >}}







- 所有特征值非负，迹为方差和，必然 $\text{Tr}(C_x) \geq 0$。



**线性变换下的协方差**

若 $Y = A x + B$，则：

$$
C_y = E[(Y - E[Y])(Y - E[Y])^T]
= A E[(X - E[X])(X - E[X])^T] A^T
= A C_x A^T
$$





#### 不相关与独立性条件

- **不相关 (Uncorrelated)**：若 $\text{Cov}(x_i, x_j)=0$ 对所有 $i\neq j$ 成立，则称 $x_i$ 与 $x_j$ 不相关。但不相关不保证独立。

- **独立 (Independent)**：若满足
  $$
  f_{x_1,\dots,x_n}(x_1,\dots,x_n) = \prod_{i=1}^n f_{x_i}(x_i),
  $$
  则称 $x_1,\dots,x_n$ 独立。

**重要结论**：一般情况下，不相关 $\not\to$ 独立。但对于高斯（正态）分布，在不相关条件下可以推出独立。前面我们已经证明过一次了，不过之前是二维情况，现在我们证明更普遍的 $n$ 维。



{{< alert class="warning" >}}

**证明**：在高斯分布下，不相关可以推出独立。并且用 $n$ 维情况来举例子

对于多维高斯随机向量 $\mathbf{x}$，其概率密度函数为：

$$
f_x(\mathbf{x}) = (2\pi)^{-N/2} [\det(C_x)]^{-1/2} \exp\left(-\frac{1}{2}(\mathbf{x}-m_x)^T C_x^{-1} (\mathbf{x}-m_x)\right)
$$



当各分量不相关时，$C_x$ 为对角矩阵：

$$
C_x =
\begin{bmatrix}
\text{Var}(x_1) & 0 & \dots & 0 \\\\\\
0 & \text{Var}(x_2) & \dots & 0 \\\\
\vdots & \vdots & \ddots & \vdots \\\\
0 & 0 & \dots & \text{Var}(x_n)
\end{bmatrix}
$$

于是：

$$
C_x^{-1} = \text{diag}\left(\frac{1}{\gamma_1}, \frac{1}{\gamma_2}, \dots, \frac{1}{\gamma_n}\right)
$$

带入指数项中：

$$
\exp\left(-\frac{1}{2}(\mathbf{x}-m_x)^T C_x^{-1} (\mathbf{x}-m_x)\right)
= \exp\left(-\frac{1}{2}\sum_{i=1}^n \frac{(x_i - m_{x_i})^2}{\gamma_i}\right)
$$

密度函数分解为各分量的高斯密度乘积：

$$
f_x(\mathbf{x}) = \prod_{i=1}^n \left( (2\pi)^{-1/2} \gamma_i^{-1/2} \exp\left(-\frac{(x_i - m_{x_i})^2}{2\gamma_i}\right) \right)
= \prod_{i=1}^n f_{x_i}(x_i)
$$

举例：


$$
假设
\begin{cases}
  f_{x_1}(x_1) = (2\pi)^{-\frac{1}{2}} \gamma_1^{-\frac{1}{2}} \cdot \exp\left( -\frac{1}{2} \cdot \frac{(x_1 - m_{x_1})^2}{\gamma_1} \right)   \\\\
  f_{x_2}(x_2) = (2\pi)^{-\frac{1}{2}} \gamma_2^{-\frac{1}{2}} \cdot\exp\left( -\frac{1}{2} \cdot \frac{(x_2 - m_{x_2})^2}{\gamma_2} \right) &
\end{cases}
$$

$$
f_{x_1, x_2}(x_1, x_2) = f_{x_1}(x_1) \cdot f_{x_2}(x_2)
$$

结论：高斯向量在不相关条件下的联合分布可分解为独立分布的乘积，即此时 $x_i$ 相互独立。

{{< /alert >}}

## 随机信号

设有离散时间随机过程(信号) $\{X_n\}$。从统计特性角度，若满足以下条件则称其为平稳（stationary）：

一阶稳态：均值不随时间变化

$$
m_x(n) = \mathbb{E}[X_n] = m_x
$$

二阶稳态：协方差 $ r_x(n, p)$ 仅与时间差有关，不随绝对时间点  $n$ 变化 
$$
r_x(n, p) = \text{Cov}(X_n, X_{n+p}) = \mathbb{E} \left[ \left( X_n - \mathbb{E}(X_n) \right) \left( X_{n+p} - \mathbb{E}(X_{n+p}) \right) \right]
$$

若该函数仅依赖于时间差 $p$，即对所有 $n$：
$$
r_x(n, p) = r_x(p)
$$

#### 实例分析

给定一个随机信号：
$$
x_n = \alpha \cdot e^{j\left(2\pi v n + \phi\right)}
$$
其中 $\phi$ 在区间 $[-\pi, \pi]$ 上均匀分布且独立于 $n$

```matlab
clear; close all; clc;

%% 部分1：验证 x_n = alpha * exp(j(2*pi*nu0*n + phi)) 的特性

% 参数设置
N = 100000;          % 信号长度
alpha = 1;           % 幅值
nu0 = 0.1;           % 信号频率(归一化频率)
% 产生 phi 均匀分布于[-pi, pi]
phi = (rand(1)*2*pi - pi); 

% 产生信号 x_n
n = (0:N-1);

NumTrials = 1000;  % 多次重复试验以计算期望
X_all = zeros(NumTrials, N);

for trial = 1:NumTrials
    phi_rand = (rand(1)*2*pi - pi);
    X_all(trial,:) = alpha * exp(1j*(2*pi*nu0*n + phi_rand));
end
```



1. 计算均值：

$$
m_x(n) = \mathbb{E}[x_n] = \mathbb{E} \left[ \alpha \cdot e^{j \left( 2\pi v \cdot n + \phi \right)} \right] = \alpha \cdot e^{j 2\pi v n} \cdot \mathbb{E} \left[ e^{j \phi} \right]
$$

由于 $\phi$ 在 $[-\pi, \pi]$ 上均匀分布，因此期望：

$$
\mathbb{E}[e^{j\phi}] = \int_{-\pi}^{\pi} e^{j\phi} \frac{1}{2\pi}d\phi= \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{j\phi} d\phi
$$

对指数函数进行积分：
$$
\int_{-\pi}^{\pi} e^{j\phi}   d\phi = \left.\frac{e^{j\phi}}{j}\right|_{\phi=-\pi}^{\phi=\pi} = \frac{e^{j\pi} - e^{-j\pi}}{j} 
$$
注意到 $e^{j\pi} = \cos(\pi) + j\sin(\pi) = -1$，且 $e^{-j\pi} = \cos(-\pi) + j\sin(-\pi) = \cos(\pi) = -1$。因此：
$$
e^{j\pi} - e^{-j\pi} = (-1) - (-1) = 0
$$
最终可得:
$$
\mathbb{E} \left[ e^{j \phi} \right] = 0
$$
因此：
$$
m_x(n) = 0
$$
因此与 $n$ 无关，满足一阶稳态。

```matlab
% 计算均值 (对试验数和时间长度求平均)
m_x_est = mean(mean(X_all,2));  
disp(['估计的均值 m_x = ', num2str(m_x_est)]);
```



2. 计算协方差函数：

$$
r_x(n, p) = \mathbb{E}[x_n x_{n+p}^*] 
$$

将定义代入：
$$
x_n x_{n+p}^* = \alpha e^{j(2\pi v n + \phi)} \cdot \alpha e^{-j(2\pi v (n+p) + \phi)}
$$
化简：
$$
x_n x_{n+p}^* = \alpha^2 e^{j2\pi v n + j\phi}e^{-j2\pi v n - j2\pi v p - j\phi} = \alpha^2 e^{-j2\pi v p}
$$
 $\phi$ 出现在 $x_n$ 和 $x_{n+p}$ 中会相互抵消，所以求期望时：
$$
r_x(n,p) = \mathbb{E}[x_n x_{n+p}^*] = \alpha^2 e^{-j2\pi v p}
$$
该函数不依赖于 $n$，只依赖于 $p$，满足二阶稳态。



#### 协方差函数的特性（在一二阶稳态的情况下）

1. **对称性**： 
   $$
   r_x(-p) = r_x(p)
   $$
   {{< alert class="warning" >}}

   **证明**：
   
   从协方差函数的定义出发，有
   $$
   r_x(p) = E[(X_n - m_x)(X_{n+p}-m_x)].
   $$
   进行变量代换，引入新索引 $m = n + p$ ，则 $n = m - p$ 
   $$
   r_x(p) = E[(X_{m-p} - m_x)(X_m - m_x)]
   $$
   这就对应于
   $$
   r_x(-p) = E[(X_{m-p} - m_x)(X_m - m_x)]
   $$
   因此
   $$
   r_x(-p) = r_x(p)
   $$
   证明完毕
   
   
   
   {{< /alert >}}
   
   更换索引 $n \to n-p$，不影响统计特性：
   $$
   r_x(-p) = \mathbb{E}[(X_{n-p} - m_x)(X_n - m_x)] = r_x(p)
   $$
   
2. **移位不变性**： 
   $$
   \text{Cov}[X_n, X_m] =\text{Cov}[X_{n+k}, X_{m+k}] = \gamma(n-m) = \gamma(m-n)
   $$
   

   {{< alert class="warning" >}}
   
   **证明**：
   
   现在我们对时间索引进行整体平移，$n{\prime} = n + k, \quad m{\prime} = m + k$ ，由于过程为二阶平稳，这种整体平移不改变统计性质，因此方差和协方差并不改变
   $$
   E[X_n] = E[X_{n+k}] = m_x \quad \forall k
   $$
   
   $$
   \text{Cov}[X_n, X_m] = \text{Cov}[X_{n+k}, X_{m+k}] \quad \forall k
   $$
   
   也就是说协方差仅依赖于时间差 $(m-n)$
   
   {{< /alert >}}
   
   
   
3. **方差和协方差的关系**： 
   $$
   r_x(0) = \mathbb{E}[(X_n - m_x)^2] = \text{Var}(X_n)
   $$

4. **最大值性质**： 
   $$
   \gamma_x(p) \leq \gamma_x(0)
   $$
   即在 $p=0$ 处取得最大值。这直观上表明，一个信号与其自身的重合（无延迟）协方差最大。



#### 功率谱密度 (PSD)

功率谱密度 $S_x(\nu)$ 是协方差函数 $r_x(p)$ 的离散时间傅里叶变换（DTFT）：

$$
S_x(\nu) = \text{TF}[r_x(p)] = \sum_{p=-\infty}^{\infty} r_x(p) e^{-j2\pi \nu p} \quad v \in \mathbb{R}
$$



为什么叫做功率谱密度？首先，随机过程的自协方差函数在零延迟 p=0 处给出信号的均方值（方差），即信号的平均功率，而频域中的 $S_x(ν)$积分求和得到的总功率与时域的方差是一致的，然后将总功率在不同频率上分解，描述不同频率下功率的分布情况。

反变换：

$$
r_x(p)  = \text{TFI} \left[ S_x(\nu) \right]= \int_{-\frac{1}{2}}^{\frac{1}{2}} S_x(\nu) e^{j 2 \pi \nu p} d\nu
$$

**性质**：

- $S_x(\nu)$ 是 周期为1的周期函数： 

  因为:
  $$
  e^{-j2\pi(\nu+1)k} = e^{-j2\pi\nu k} \cdot e^{-j2\pi k} = e^{-j2\pi\nu k} \cdot 1
  $$
  对任意整数 $k$ 都成立，所以 $S_x(\nu+1)=S_x(\nu)$。

  

- $S_x(\nu)$ 是实且非负的： 
  $$
  S_x(\nu) \geq 0
  $$

  

  首先因为自相关函数 $r_x(p)$ 是正定函数，并且任何正定函数的傅里叶变换都是非负的（Wiener-Khinchin 定理）。其次功率谱密度描述的是随机过程在不同频率下的能量分布。能量或功率不能为负，因此在物理上要求 $Sx(ν)$ 非负。

- 频域积分等于时域协方差在零点的值，即方差：  
  $$
  r_x(0) = \text{Var}(X_n) = \int_{-1/2}^{1/2} S_x(\nu) d\nu
  $$

  

  这表明在频域对功率谱密度积分，得到时域零延迟协方差，即方差。令 $p=0$ 可以很简单的证明。



#### 实例继续说明

对于之前定义的 $x_n = \alpha e^{j(2\pi \nu_0 n + \phi)}$，我们已知：

$$
m_x=0
$$

$$
\gamma_x(p)=\alpha^2 e^{j2\pi\nu_0 p}
$$

根据功率谱密度的定义:
$$
S_x(\nu) = \text{TF}[r_x(p)] = \sum_{p=-\infty}^{\infty} r_x(p) e^{-j2\pi \nu p} \quad v \in \mathbb{R}
$$
将$ r_x(p) = \alpha^2 e^{j2\pi \nu_0 p}$ 代入上述公式
$$
S_x(\nu) = \alpha^2 \sum_{p=-\infty}^{\infty} e^{j2\pi \nu_0 p} e^{-j2\pi \nu p} 
= \alpha^2 \sum_{p=-\infty}^{\infty} e^{-j2\pi(\nu - \nu_0)p}
$$
上式中，当 $\nu = \nu_0$ 时，指数项为 $e^0 = 1$，对所有 $p$ 都是1，相当于求和 $\sum_{p=-\infty}^{\infty} 1$ 理解为能量完全集中在特定频率 $ν_0$ 上。因此 $S_x(\nu)$ 将在 $\nu=\nu_0$ 处表现为一个冲激函数 $\delta(\nu-\nu_0)$
$$
S_x(\nu)=\alpha^2 \delta(\nu-\nu_0)
$$




#### 白噪声示例

对白噪声信号 $\{B_n\}$ 而言：

- $E[B_n]=0$
- 在两个不同时间点不相关，即 $\text{Cov}(B_n,B_m)=0$ 当 $n \neq m$
- 对于 $n=m$ 时，$\text{Var}(B_n)=\gamma_0$（某个常量）

故协方差函数（自相关函数）：
$$
r_{B}(p) = \gamma_0 \cdot  \delta_p
$$
{{< alert class="warning" >}}

**证明**：

对于一个随机过程 $B(n)$，当其功率谱密度 $S_B(\nu)$ 是常量时，也就是说白噪声频谱平坦时，即：
$$
S_B(\nu)=\gamma_0
$$

- 其中 $v$ 的频率范围为 $[-1/2, 1/2]$

根据维纳-辛钦定理，自相关函数 $r_B(p)$ 是功率谱密度 $S_B(\nu)$ 的逆傅立叶变换：
$$
r_B(p) = \int_{-1/2}^{1/2} S_B(\nu) e^{j2\pi\nu p} d\nu
$$

将 $S_B(\nu) = \gamma_0$ 代入：

$$
r_B(p) = \gamma_0 \int_{-1/2}^{1/2} e^{j2\pi \nu p}\,d\nu
$$
当 $p = 0$ 时：

$$
r_B(0) = \gamma_0 \int_{-1/2}^{1/2} d\nu = \gamma_0 \cdot 1 = \gamma_0.
$$
这说明在延迟为0的时刻，自相关函数为 $γ_0$。这与白噪声的直观印象吻合：白噪声在时域上没有记忆性，只有在相同时间点才有相干性（能量）。当 $p \neq 0$ 时，最终结果是一个类似 $ \frac{\sin(\pi p)}{\pi p}$ 类型的函数（具体计算可得出一个sinc函数的形态），当 $p \neq 0$ 时，该函数值会很小或者近似为0。因此用冲击函数来描绘这个情况。
$$
r_{B}(p) = \gamma_0 \cdot  \delta_p
$$
证毕

{{< /alert >}}

## 随机信号滤波

考虑一个输入为随机信号 $x_n$，输出为 $y_n$ 的线性时不变(LTI)系统。该系统可以用卷积描述：

$$
y_n = x_n * h_n = \sum_{k=-\infty}^{+\infty} h(k) \cdot x(n-k)
$$

- 其中 $h_n$ 为系统脉冲响应。

#### 输出协方差的推导

给定输出信号：

$$
y_n = \sum_{k=-\infty}^{+\infty} h(k) \cdot x(n-k),
$$

$$
(y_n - m_y) = \sum_{k=-\infty}^{+\infty} h(k) \cdot [x(n-k) - m_x].
$$

同理，对于延迟 $p$ 个点的输出：

$$
(y_{n+p} - m_y) = \sum_{e=-\infty}^{+\infty} h(e) \cdot [x(n+p-e) - m_x].
$$

这两式说明输出减去均值后的值仍是由输入减去其均值的值通过相同的脉冲响应 $h(\cdot)$ 线性叠加得到的。

输出的协方差定义为：

$$
r_y(p) = \mathbb{E}[(y_n - m_y)(y_{n+p}-m_y)]
$$

代入前面去均值的表达式：

$$
\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)]
= \mathbb{E}\left[\left(\sum_{k} h(k)[x(n-k)-m_x]\right)\left(\sum_{e} h(e)[x(n+p-e)-m_x]\right)\right]
$$

由于期望是线性算子，可以先将 $h(k)$ 和 $h(e)$ 提出来，再对 $x(\cdot)-m_x$ 的乘积项求期望：

$$
\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)]= \sum_{k=-\infty}^{+\infty} \sum_{e=-\infty}^{+\infty} h(k)h(e) \mathbb{E}[(x_{n-k}-m_x)(x_{n+p-e}-m_x)]
$$

利用**输入协方差函数 $r_x(\cdot)$** 来表达，定义输入信号的协方差函数：
$$
r_x(\tau) = \mathbb{E}[(x_{n}-m_x)(x_{n+\tau}-m_x)]
$$

根据这一定义：

$$
\mathbb{E}[(x_{n-k}-m_x)(x_{n+p-e}-m_x)] = r_x(p+k-e)
$$

将此结果代入上式：

$$
\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)]
= \sum_{k=-\infty}^{+\infty} \sum_{e=-\infty}^{+\infty} h(k)h(e)r_x(p+k-e)
$$

我们定义一个**中间函数 $\tilde{r}_x(p+k)$**
<div>
$$
\tilde{r}_x(p+k) = \sum_{e=-\infty}^{+\infty} h(e) \cdot r_x(p+k-e)
$$
</div>

这相当于将 $r_x(\cdot)$ 与 $h(\cdot)$ 进行一次卷积得到中间结果。目的是为简化表达。

于是有：

$$
r_y(p)=\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)] = \sum_{k=-\infty}^{+\infty} h(k)\tilde{r}_x(p+k)
$$

**定义 $\bar{h}(k) = h(-k)$ 并进一步化简**

通过定义 $\bar{h}(k)=h(-k)$，对求和指标进行变换，就能将表达式写成多次卷积的形式：

<div>
$$r_y(p)=\sum_{k=-\infty}^{+\infty} h(k)\tilde{r}_x(p+k)
= \sum_{k=-\infty}^{+\infty} \bar{h}(-k) \tilde{r}_x(p+k)$$
</div>


通过索引替换 $q=-k$，最终可以将其表示为：

<div>
$$r_y(p)=  \sum_{q=-\infty}^{\infty} \bar{h}(q)\tilde{r}_x(p-q)=\tilde{\tilde{r}}_x(p)$$
</div>

综上所述，我们有:

<div>
$$\tilde{\tilde{r}}_x(p) =  \sum_{q=-\infty}^{\infty} \bar{h}(q)\tilde{r}_x(p-q)$$
</div>




这再次呈现出卷积的形式。实际上，这个结果显示 $r_y(p)$ 可以用 $h(\cdot)$、$\bar{h}(\cdot)$ 和 $r_x(\cdot)$ 的多重卷积来表示：

$$
r_y(p) = \bar{h} * h * \tilde{r}_x(p)
$$

#### 频域表示

在频域表示中，卷积在时域对应频域的乘法关系。已知 $S_x(\nu)$ 是输入的功率谱密度，$H(\nu)$ 是系统频率响应，则输出功率谱密度为：

$$
S_y(\nu) = H(\nu)^* \cdot H(\nu) \cdot S_x(\nu) = |H(\nu)|^2 \cdot S_x(\nu)
$$

与时域结果 $r_y(p) = \bar{h} * h * \tilde{r}_x(p)$ 相吻合，因为卷积在时域转化为频域相应函数的乘积。

综上所述
$$
\begin{cases}
  r_y(p) = \bar{h} * h * \tilde{r}_x(p)  \\\\
  S_y(\nu) =  |H(\nu)|^2 \cdot S_x(\nu)  \\
\end{cases}
$$



这就是经过线性滤波器后的输出自相关函数以及功率谱密度与输入功率谱密度之间的关系。接下来我们要用这个线性滤波器的输出与输入统计特性的关系来推导**维纳滤波器（Filtrage de Wiener）**，用于在有噪音的环境中恢复信号。

## 维纳滤波器 (Wiener Filter) 

维纳滤波器的基本目标是在有噪声的环境中，从观测到的输出信号 $y_n$ 中尽可能恢复原始信号 $x_n$。通过构建一个滤波器 $g_n$ 对输出进行处理，希望得到的估计 $\hat{x}_n$ 与真实 $x_n$ 之间的均方误差 (MSE) 最小。

给定带噪模型：

$$
y_n = x_n * h_n + b_n = \sum_{k=-\infty}^{+\infty} h(k) \cdot x(n-k) + b_n
$$

这里，$h_n$ 是已知系统的脉冲响应，$b_n$ 是加性噪声。由该模型可知，当没有噪声时 ($b_n=0$)，$y_n$ 只是 $x_n$ 经过系统的线性时不变变换。

相应协方差与功率谱密度的结果为：

$$
\begin{cases}
r_y(p) = \bar{h} * h * \tilde{r}_x(p) + r_b \\\\
S_y(\nu) = |H(\nu)|^2 \cdot S_x(\nu) + S_b(\nu)
\end{cases}
$$

这里的 $r_y(p)$ 和 $S_y(\nu)$ 是输出信号 $y_n$ 的协方差函数与功率谱密度。$S_x(\nu)$ 和 $S_b(\nu)$ 分别是输入信号与噪声的功率谱密度，$H(\nu)$ 是系统的频率响应。

#### 求解维纳滤波器

定义估计误差的均方值 (MSE)：

$$
e_n = \mathbb{E}\left[ (\hat{x}_n - x_n)^2 \right]
$$

其中 $\hat{x}_n = y_n * g_n$ 表示我们在输出 $y_n$ 上再施加一个滤波器 $g_n$ 得到的估计量，$g_n$ 是我们需要求解的滤波器脉冲响应。

**关键想法**：通过调整 $g_n$（滤波器的参数），使得 $e_n$ 最小。为了求最优 $g_n$，对 $e_n$ 关于 $g_{k_0}$（$g_n$ 的第 $k_0$ 个参数）的偏导数设为零。这个过程相当于最小化 MSE 的变分条件。
$$
\min_{g_n} e_n
$$
在最优条件下，若 $g_n$ 是一组参数 $g_0, g_1, g_2, \dots$，则对每一个参数 $g_{k_0}$ 的偏导数应为零。也即是说，当 $\frac{\partial e_n}{\partial g_{k_0}} = 0$ 时，我们达到了一个极值点（最小值、最大值或鞍点）。

求导：

$$
\frac{d}{d g_{k_0}} e_n = \frac{d}{d g_{k_0}} \mathbb{E}[(\hat{x}_n - x_n)^2]
$$

<div>
$$
\frac{d e_n}{d g_{k_0}} = \frac{d}{d \hat{x}_n}\frac{d \hat{x}_n}{d g_{k_0}} \mathbb{E}[(\hat{x}_n - x_n)^2]
= E\left[ 2(\hat{x}_n - x_n) \frac{d \hat{x}_n}{d g_{k_0}} \right]
$$
</div>

我们已知:

<div>
$$
\hat{x}_n = \sum_k g_k y_{n-k}
$$
</div>



那么:

<div>
$$\frac{d \hat{x}_n}{d g_{k_0}} = y_{n-k_0}$$
</div>



通过链式法则和线性算子特性，可得：

$$
\frac{d}{d g_{k_0}} e_n = 2 \mathbb{E} \left[ y_{n-k_0}(\hat{x}_n - x_n) \right]
$$

这个公式说明了，如果想通过调节 $g _{k_0}$ 来减小误差，一定要看该系数对应的输入信号 $y _{n-k_0}$ 与当前误差 $(\hat{x}_n - x_n)$ 的期望乘积。然后根据期望乘积的正负来增加或减少 $g _{k_0}$ 以最大化的减小误差。



#### 计算期望项

1. 考虑期望项 $E[y_{n-k_0} \cdot x_n]$：

$$
E[y_{n-k_0} x_n] = E\left[\left(\sum_\tau h_\tau x_{(n-k_0)-\tau}\right) x_n\right]
$$
将求和与期望交换顺序
$$
E[y_{n-k_0} x_n] = \sum_\tau h_\tau E[x_{n-k_0-\tau} x_n]
$$
由于 $x_n$ 是 WSS（宽平稳过程），自相关只与时间差有关，因此：

$$
E[x_{n-k_0-\tau} x_n] = r_x(k_0 + \tau)
$$
将此代入原式：

$$
E[y_{n-k_0} x_n] = \sum_\tau h_\tau r_x(k_0 + \tau)
$$
经过变量代换，$\bar{h}=h_{-\tau}$ ，那么可以写出 $\bar{h}$ 与 $r_x(k_0)$ 的一个卷积形式：
$$
\mathbb{E} \left[ y_{n-k_0} \cdot x_n \right] = \bar{h} * r_x(k_0)
$$

通过这个卷积形式 $\bar{h} * r_x(k_0)$ ，可以清楚看到输出信号 $y_n$ 与输入信号 $x_n$ 之间的统计相关性关系，当没有噪声时，$y_n$ 与 $x_n$ 的关联完全由 $h_n$ 和 $r_x$ 决定



2. 考虑期望项 $\mathbb{E}[y_{n-k_0} \cdot \hat{x}_n]$：

<div>
$$
\hat{x}_n = \sum_k g_k y_{n-k}
$$
</div>

带入到期望项中:

<div>
$$
E[y_{n-k_0} \cdot \hat{x}_n] = E\left[y_{n-k_0} \left(\sum_k g_k y_{n-k}\right)\right]
$$
</div>

将求和符号提到期望外面:
<div>
$$
E[y_{n-k_0} \cdot \hat{x}_n] = \sum_k g_k E[y_{n-k_0} y_{n-k}]
$$
</div>

用 $y_n$ 的自相关函数（二阶平稳）表示期望
$$
E[y_{n-k_0}y_{n-k}] = r_y((n-k) - (n-k_0)) = r_y(k_0 - k)
$$
代回原式:

<div>
$$
E[y_{n-k_0} \cdot \hat{x}_n] = \sum_k g_k r_y(k_0 - k)
$$
</div>

即:
$$
\mathbb{E}[y_{n-k_0} \cdot \hat{x}_n] = g * r_y(k_0)
$$

#### 最优滤波器条件方程

因此把上面的到的  $E[y_{n-k_0} \cdot x_n]$ 和  $\mathbb{E}[y _{n-k_0} \cdot \hat{x} _n]$ 带入到 $\frac{d}{d g _{k_0}} e _n$ 原公式中:

$$
\frac{d}{d g_{k_0}} e_n = 2 \left( g * r_y(k_0) - \bar{h} * r_x(k_0) \right)
$$

令偏导数为零，得到最优滤波器公式：

$$
g * r_y(k_0) = \bar{h} * r_x(k_0)
$$

这是一个关键方程，它表明在时域下，维纳滤波器 $g_n$ 的作用是将输出协方差 $r_y$ 与输入信号特性通过 $\bar{h}$ 和 $r_x$ 联系起来。要实现最优估计，$g_n$ 必须满足这个卷积方程。

#### 转换到频域求解

在频域中，卷积变为简单的乘法。对上式取傅里叶变换：

$$
G(\nu) S_y(\nu) = H^*(\nu) S_x(\nu)
$$

因此得到维纳滤波器的频率响应（频域传递函数）：
<div>
$$
G(\nu) = \frac{H^*(\nu) S_x(\nu)}{S_y(\nu)}
$$
</div>

由 $S_y(\nu) = |H(\nu)|^2 S_x(\nu) + S_b(\nu)$，可将 $S_y(\nu)$ 替换进去：
$$
G(\nu) = \frac{H^*(\nu) S_x(\nu)}{|H(\nu)|^2 S_x(\nu) + S_b(\nu)}
$$

#### 特殊情况分析

1. **无噪音（当 $\gamma_B = 0$，$S_B = 0$）**

$$
G(\nu) = \frac{H^*(\nu) S_x(\nu)}{|H(\nu)|^2 S_x(\nu)} = \frac{1}{H(\nu)}
$$

即维纳滤波器退化为系统传递函数的逆滤波器，以完全恢复输入信号 $x_n$。

2. **无滤波器（仅直通）且有噪声 ($H(\nu)=1$)**：

$$
G(\nu) = \frac{S_x(\nu)}{S_x(\nu) + S_b(\nu)} = \frac{1}{1 + \frac{S_b(\nu)}{S_x(\nu)}}
$$

此时，滤波器在各频率处根据信噪比 (SNR = $S_x(\nu)/S_b(\nu)$) 来决定增益大小：  

- 当 $S_x(\nu)$ 远大于 $S_b(\nu)$，即信号显著强于噪声，$G(\nu)$ 接近 1；  
- 当 $S_x(\nu)$ 接近或小于 $S_b(\nu)$，增益会小于 1，从而衰减该频段成分，减少噪声影响。

这反映了维纳滤波器的平衡策略：在高信噪比频段尽量还原信号，在低信噪比频段减少增益以抑制噪声。

关于 Wiener 滤波器的应用部分请看 [维纳滤波器进行反卷积](https://zehua.eu/zh/posts/signal_cn/随机信号tp3/)

## 经验估计器

#### 偏差与方差分解

假设 $\hat{\theta}$ 为估计值，评判标准为最小均方误差（MSE）：

$$
\varepsilon = \mathbb{E}[(\theta - \hat{\theta})^2]
$$

展开：

$$
\varepsilon = \mathbb{E}[(\theta - \mathbb{E}(\hat{\theta}) + \mathbb{E}(\hat{\theta}) - \hat{\theta})^2] 
$$

- 系统性偏差：$\theta - \mathbb{E}[\hat{\theta}]$ 

  这是估计值的期望与真实参数 $\theta$ 的差异，即估计量相对于真实值的平均偏移量，不随随机性的不同实现而变化（它是确定性的，不随样本的不同取值变化）。

- 随机波动项：$\mathbb{E}[\hat{\theta}] - \hat{\theta}$  

  这是估计量本身围绕其期望值的波动，体现了估计量的方差性质。



假设偏差 $B = \theta - E[\hat{\theta}]$，即真实值减去估计的期望值。

因此，有：

$$
\varepsilon = \mathbb{E}[(B + (\mathbb{E}[\hat{\theta}] - \hat{\theta}))^2]
$$

展开:
$$
\varepsilon = \mathbb{E}[B^2 + 2B(\mathbb{E}[\hat{\theta}] - \hat{\theta}) + (\mathbb{E}[\hat{\theta}] - \hat{\theta})^2]
$$

由于 $B$ 是一个常数（不随随机性变化），而 $\mathbb{E}[\hat{\theta}] - \hat{\theta}$ 是随机变量且均值为零，因此:

$$
\varepsilon = B^2 + \mathbb{E}[(\mathbb{E}[\hat{\theta}] - \hat{\theta})^2]
$$

注意到 $\mathbb{E}[\hat{\theta}] - \hat{\theta}$ 是 $\hat{\theta}$ 相对于其期望的偏差，定义为估计量的方差：

$$
\text{Var}(\hat{\theta}) = \mathbb{E}[(\hat{\theta} - \mathbb{E}[\hat{\theta}])^2]
$$

最终得到著名的偏差-方差分解公式：

$$
\varepsilon = B^2 + \text{Var}(\hat{\theta})
$$

#### 偏差-方差权衡意义

- 若估计量是无偏的，即 $B=0$，则有 $\varepsilon = \text{Var}(\hat{\theta})$。此时均方误差等同于方差，减小方差便能直接降低均方误差。
- 若估计量有偏差，则 $\varepsilon$ 包含了一个不可忽略的常量项 $B^2$。即使我们减小估计量的方差，也无法使均方误差低于 $B^2$
- 这体现了一个偏差-方差权衡：有时允许一点偏差可以大幅降低方差，从而整体减少MSE；如果偏偏要无偏估计，很可能使方差增大，从而造成MSE反而更大。









