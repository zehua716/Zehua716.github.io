---
title: "随机信号与噪音（理论部分）"
# author: "Zehua"
date: "2023-12-20T16:25:17+01:00"
lastmod: "2024-11-13T17:12:35+08:00"
lang: "zh"
draft: false
summary: "主要介绍随机信号及其统计特性，包括协方差函数与功率谱密度，最后简单介绍维纳滤波器在信号处理中的应用"
description: ""
tags: ["信号处理", "随机过程", "统计分析", "滤波器设计"]
# categories: "posts"
#cover:
    #image: "img/signal.png"
# comments: true
# hideMeta: false
searchHidden: true
# ShowBreadCrumbs: true
# ShowReadingTime: false

---

##  一维随机变量

#### 概率密度函数的性质 

对随机变量  $X$ 来说，其概率密度函数  $f_x(x)$ 满足：
$$
\int_{-\infty}^{\infty} f_x(x)\,dx = 1, \quad f_x(x) \geq 0 \,\, \forall x \in \mathbb{R}
$$

即  $f_x(x)$ 是非负函数，其积分总和为 1。

#### 概率的计算

若需计算事件  $\{X \in [m,M]\}$ 的概率，有：

<div>$$P\left\{ x \in [m, M] \right\} = \int_{m}^{M} f_x(x) \, dx$$</div>

#### 数学期望 

对随机变量  $X$ ，其期望为：
$$
E(X) = \int_{-\infty}^{\infty} x f_x(x) \, dx
$$

对任意函数  $\varphi(X)$ 的期望：
$$
E(\varphi(X)) = \int_{-\infty}^{\infty} \varphi(x) f_x(x) \, dx
$$
期望是加权平均值（加权由概率密度给出）

#### 方差与标准差

方差定义为：
$$
\sigma_x^2 = \mathrm{Var}[X] = E[(X - E[X])^2]
$$
标准差为方差的平方根：
$$
\sigma_x = \sqrt{\mathrm{Var}[X]}
$$
方差和标准差度量随机变量取值围绕其期望的离散程度。分布越分散，方差和标准差越大。

#### 均方根误差 (RMSE)  

在数据拟合、预测或信号处理领域，用均方根误差来衡量预测值  $\hat{y}_i$ 与真实值  $y_i$ 之间的偏差：
<div>
$$\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$$
</div>
RMSE 体现了预测误差的平均幅度，值越小说明预测越接近真实值。在信号与控制领域，RMSE 常用于评价模型的估计精度或滤波效果。

#### 代码示例

```matlab
% 生成一维高斯随机变量
N = 10^6; % 样本数
mu = 2;   % 均值
sigma = 3;% 标准差
X = mu + sigma*randn(N,1);

% 验证期望与方差
est_mu = mean(X);
est_var = var(X);

fprintf('理论均值 = %.2f, 实际估计均值 = %.2f\n', mu, est_mu);
fprintf('理论方差 = %.2f, 实际估计方差 = %.2f\n', sigma^2, est_var);

% 验证概率计算：P(X in [m,M])
m = 0; M = 5;
p_est = mean(X>=m & X<=M);
fprintf('P(X in [%.1f, %.1f])的模拟值为: %.4f\n', m, M, p_est);
```

```matlab
RMSE = sqrt(mean((y - hat_y).^2)); % 假设有预测值hat_y与真实值y
fprintf('RMSE = %.4f\n', RMSE);
```



## 两维随机变量

#### 联合概率密度函数

对两个随机变量   $X, Y$   而言，其联合概率密度函数   $f_{X,Y}(x,y)$   满足：
$$
\iint_{\mathbb{R} \times \mathbb{R}} f_{X,Y}(x,y)\,dx\,dy = 1,\quad f_{X,Y}(x,y) \geq 0
$$

这里   $f_{X,Y}(x,y)$   对所有   $x, y \in \mathbb{R}$   非负，并通过对整个二维平面的积分为 1 来保证这是一个有效的概率密度函数。

- 在一维情况下，概率密度函数  $f_X(x)$  表示  $X$  在点  $x$  的密度。
- 在二维情况下，联合概率密度函数  $f_{X,Y}(x,y)$  则表示  $X,Y$  同时在点  $(x,y)$  附近出现的“概率密度”。由于是密度值，对它进行二维积分才能得到相应的概率。

```matlab
clear; clc; close all;

%% 定义符号变量与参数
syms x y real

%----------------------------
% 一维高斯参数
mu_x = 0;    % E[X]
sigma_x = 1; % Var(X)=sigma_x^2

% 二维高斯分布参数
mu_y = 2;          % E[Y]
sigma_y = 1.5;     % Var(Y)=sigma_y^2
rho_xy = 0.3;      % 相关系数rho_{xy}, 范围(-1,1)
%----------------------------
```

#### 一维高斯分布

对于一维正态（高斯）分布  $X \sim \mathcal{N}(\mu, \sigma^2)$  ，其概率密度函数为：
$$
f_X(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$

```matlab
%% 一维高斯分布pdf定义
fX = (1/(sqrt(2*pi)*sigma_x))*exp(-((x - mu_x)^2)/(2*sigma_x^2));

% 验证归一化: ∫ fX(x) dx = 1
int_fX = int(fX, x, -inf, inf); 
disp(['一维高斯分布积分验证（应为1）：', char(vpa(simplify(int_fX),10))]);
```

#### 二维高斯分布

若  $X,Y$  联合呈正态分布  $\mathcal{N}(\mu_x, \mu_y, \sigma_x^2, \sigma_y^2, \rho_{xy}) $，其联合概率密度函数为：
$$
f_{X,Y}(x,y) = \frac{1}{2\pi \sigma_x \sigma_y \sqrt{1-\rho_{xy}^2}} \exp\left(-\frac{1}{2(1-\rho_{xy}^2)}\left[\left(\frac{x-\mu_x}{\sigma_x}\right)^2 + \left(\frac{y-\mu_y}{\sigma_y}\right)^2 - 2\rho_{xy}\left(\frac{x-\mu_x}{\sigma_x}\right)\left(\frac{y-\mu_y}{\sigma_y}\right)\right]\right)
$$

-  $\rho_{xy}$  为  $X,Y$  的相关系数（取值范围在  $-1$ 至 $1$ 之间）。当  $\rho_{xy}=0$  时，两变量在统计意义上不相关。

```matlab
%% 二维高斯分布pdf定义
fXY = (1/(2*pi*sigma_x*sigma_y*sqrt(1-rho_xy^2))) * ...
      exp(-1/(2*(1-rho_xy^2)) * ( ((x - mu_x)/sigma_x)^2 + ((y - mu_y)/sigma_y)^2 ...
      - 2*rho_xy*((x - mu_x)/sigma_x)*((y - mu_y)/sigma_y) ) );

% 验证二维高斯分布归一化: ∫∫ f_{X,Y}(x,y) dx dy = 1
int_fXY = int(int(fXY, x, -inf, inf), y, -inf, inf);
disp(['二维高斯分布积分验证（应为1）：', char(vpa(simplify(int_fXY),10))]);
```



#### 边缘概率密度函数

给定联合概率密度函数  $f_{X,Y}(x,y)$ ，对于  $X$  的边缘分布由联合分布对  $y$  积分得到：
$$
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dy
$$

同理，对  $x$  积分可得  $f_Y(y)$ :
$$
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y)\,dx.
$$
边缘分布描述单个变量的分布情况，是由联合分布“合并”掉另一维度获得的。

```matlab
%% 边缘分布计算
fX_from_joint = int(fXY, y, -inf, inf);  % 对y积分得到fX
fY_from_joint = int(fXY, x, -inf, inf);  % 对x积分得到fY

% 验证fX_from_joint归一化
disp(['X的边缘分布归一化验证（应为1）：', char(vpa(simplify(int(fX_from_joint, x, -inf, inf)),10))]);

% 验证fY_from_joint归一化
disp(['Y的边缘分布归一化验证（应为1）：', char(vpa(simplify(int(fY_from_joint, y, -inf, inf)),10))]);
```



#### 条件概率密度函数

在给定  $Y=y$  条件下， $X$  的条件概率密度函数定义为：
$$
f_{X|Y}(x|y) = \frac{f_{X,Y}(x, y)}{f_Y(y)}
$$

- 前提是  $f_Y(y)>0$ 

条件分布则描述在知道一个变量取值的前提下，另一个变量的分布特性，从而反映随机变量之间的条件依赖关系。  

**重要性质:** 对于给定条件 $Y=y_0$ 的条件概率密度函数 $f_{X|Y}(x|y_0)$，在 $x$ 上的积分必为 1

{{< alert class="warning" >}}
**证明:**  

将该条件密度对 $x$ 从 $-\infty$ 到 $\infty$ 积分时，有：
$$
\int_{-\infty}^{\infty} f_{X|Y}(x|y_0) dx = \frac{\int_{-\infty}^{\infty} f_{X,Y}(x,y_0) dx}{f_Y(y_0)} = \frac{f_Y(y_0)}{f_Y(y_0)} = 1
$$
这和条件概率密度函数的基本性质一致：条件概率密度作为一个 PDF，对所条件的自变量进行积分必为1。

{{< /alert >}}



```matlab
%% 条件概率分布验证
% f_{X|Y}(x|y) = f_{X,Y}(x,y)/f_Y(y)
y0 = 2; 
fX_given_Y = simplify(fXY / subs(fY_from_joint, y, y0)); 
int_fX_given_Y = int(subs(fX_given_Y, y, y0), x, -inf, inf);
disp(['条件分布 在x上的积分（应为1）：', char(vpa(simplify(int_fX_given_Y),10))]);
```



#### 协方差 

对于随机变量  $X,Y$ ，协方差定义为：
$$
\text{Cov}(X, Y) = E\left[(X - E[X])(Y - E[Y])\right]
$$



#### 相关系数 

相关系数是协方差的归一化版本，其定义为：
$$
\rho_{X,Y} = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X)} \cdot \sqrt{\text{Var}(Y)}}
$$

-  $\rho_{X,Y}$  在  $-1$ 和 $1$  之间。  
-  $\rho_{X,Y}=1$  表示完美正线性相关， $\rho_{X,Y}=-1$  表示完美负线性相关， $\rho_{X,Y}=0$  表示无线性相关性。  

```matlab
%% 协方差与相关系数计算验证
% E[X]=mu_x, E[Y]=mu_y, Cov(X,Y)=rho_xy*sigma_x*sigma_y
% E[XY] = E[X]E[Y] + Cov(X,Y)
E_X = mu_x;
E_Y = mu_y;
Cov_XY = rho_xy*sigma_x*sigma_y;
E_XY = E_X*E_Y + Cov_XY;

calc_rho = Cov_XY/(sigma_x*sigma_y);

disp(['理论计算的协方差Cov(X,Y)=', num2str(Cov_XY)]);
disp(['由协方差计算得到的rho_{X,Y}=', num2str(calc_rho), '，与设定的rho_xy = ', num2str(rho_xy), ' 对比']);
```



#### 随机变量对的特性

- 线性特性

  对任意实常数  $\alpha, \beta$  与随机变量函数  $\varphi(x)$  和  $\psi(x)$  有：

$$
\quad E \left[ \alpha \varphi(x) + \beta \psi(x) \right] = \alpha E[\varphi(x)] + \beta E[\psi(x)]
$$

- 常数特性

$$
\quad E[\alpha] = \alpha
$$

- 期望与方差

  若  $Y = aX + b$  ，其中  $a,b$  为常数，则有：
  $$
  \quad E[Y] = E[ax + b] = aE[x] + b
  $$
  方差对加法不敏感（仅对乘法敏感），有：

$$
\text{Var}[Y] = E[(Y - E[Y])^2] = E[a^2(X - E[X])^2] = a^2 \text{Var}[X]
$$

#### 二维概率的计算

对于二维随机变量  $X,Y$  ，任意矩形区域  $[x_m,x_M]\times[y_m,y_M]$  上的概率为：

$$
P[x_m \leq X \leq x_M, \; y_m \leq Y \leq y_M] = \int_{x_m}^{x_M}\int_{y_m}^{y_M} f_{X,Y}(x, y)\,dy\,dx
$$

```matlab
%% 二维概率区域积分
% P[x_m<=X<=x_M, y_m<=Y<=y_M] = ∫_{x_m}^{x_M}∫_{y_m}^{y_M} fXY dx dy
x_m = -1; x_M = 1;
y_m = 1;  y_M = 3;
region_prob = vpa(int(int(fXY, y, y_m, y_M), x, x_m, x_M),10);
disp(['给定区域下的概率：', char(vpa(region_prob, 10))]);
```



#### 独立性条件

若  $X,Y$  独立，则：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$
由此可推得：


$$
\begin{cases}
f_{y|x}(y|x) = f_y(y) \\\\
f_{x|y}(x|y) = f_x(x)\\
\end{cases}
$$

条件概率等于单独发生的概率，即在独立条件下，另一随机变量的已知并不改变某一随机变量的分布特征。

```matlab
%% 独立性验证
% 当rho_xy=0时，fXY应能分解为fX*fY
if abs(rho_xy) < 1e-12
    fXY_factorized = simplify(fX_from_joint * fY_from_joint);
    diff_expr = simplify(fXY - fXY_factorized);
    disp('rho_xy=0时，fXY与fX*fY的差值应为0：');
    disp(diff_expr);
else
    disp('rho_xy不为0，故X与Y不独立，此时fXY不等于fX*fY。');
end
```

#### 协方差：  

$$
\text{Cov}[X,Y] = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]
$$
其中:

- $\text{Cov}[X,X] = \text{Var}[X]$，$\text{Cov}[Y,Y] = \text{Var}[Y]$  

- 对常数因子有线性性：  
  $$
  \text{Cov}[\alpha X, Y] = \alpha \text{Cov}[X,Y], \quad \text{Cov}[\alpha X, \beta Y] = \alpha \beta \text{Cov}[X,Y]
  $$

**在独立条件下**，有  $E[XY] = E[X]E[Y]$  ，故  $\text{Cov}[X,Y]=0$ 。但  $\text{Cov}[X,Y]=0$  不一定代表独立，只能代表不线性相关（零相关）。独立是更强的条件。**但是特殊情况下**：若  $X,Y$  联合服从二元高斯分布，则不相关 ( $\rho_{X,Y}=0$ ) 即可以推出独立。这是高斯分布下的特殊性质。当  $\rho_{X,Y}=0$  时，二元高斯分布的联合密度函数因子化为单独的  $X$  与  $Y$  密度函数之积，即：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$
因此，对于高斯分布：
$$
\rho_{X,Y}=0 \iff \text{Cov}[X,Y]=0 \implies X,Y \text{ 独立。}
$$

对于非高斯分布，不相关不保证独立，但独立却一定能保证不相关，因为独立必然导致  $E[XY] = E[X]E[Y]$ 。



{{< alert class="warning" >}}
**证明:**  不相关不一定意味着独立

**证明思路**：通过给出一个反例，展示存在不相关但不独立的随机变量。

设随机变量  $X$  满足：  
$$
P(X=1)=\tfrac{1}{2}, \quad P(X=-1)=\tfrac{1}{2}.
$$
则  $E[X]=0$  且  $X$  对称分布。定义随机变量  $Y=X^2$  ，则无论  $X=1$  还是  $X=-1$ ，有  $Y=1$ 。因此  $Y$  是一个退化随机变量，恒为1。

计算协方差：  
$$
E[XY] = E[X \cdot X^2] = E[X^3] = E[X] = 0,
$$
且  
$$
E[X]=0, \quad E[Y]=E[X^2]=1.
$$

所以：  
$$
\text{Cov}(X,Y) = E[XY] - E[X]E[Y] = 0 - 0\cdot1 = 0.
$$

此时  $X,Y$  不相关。但  $Y=X^2$  表明  $Y$  完全由  $X$  决定，二者并非独立。如果  $X,Y$  独立，那么  $Y$  的取值不应随  $X$  的变化而定。然而这里  $Y$  始终是  $X$  的函数， $Y=1$  对  $X$  的取值有完全的依赖性。

由此举例可见，不相关并不蕴含独立。

{{< /alert >}}



```matlab
%% 不相关但不独立的反例
% X: P(X=1)=0.5, P(X=-1)=0.5 => E[X]=0
% Y=X^2 => Y=1总是恒定 => E[Y]=1
% E[XY]=E[X]=0, Cov(X,Y)=0, 但Y由X决定，不独立
E_X_example = 0;
E_Y_example = 1;
E_XY_example = E_X_example; 
Cov_XY_example = E_XY_example - E_X_example*E_Y_example;
disp(['反例中Cov(X,Y)=', num2str(Cov_XY_example), ' -> Cov=0但X,Y不独立。']);
```



{{< alert class="warning" >}}
**证明：** 高斯分布的联合概率密度情况下，可以由不相关 $\to$ 独立

若 $\text{Cov}(x, y) = 0 \implies \rho_{xy} = 0$

$$
f_{xy}(x, y) = \dfrac{1}{2\pi \sigma_x \sigma_y \sqrt{1 - \rho_{xy}^2}} 
e^{-\dfrac{1}{2(1 - \rho_{xy}^2)} \left[ \left( \dfrac{x - \mu_x}{\sigma_x} \right)^2 + \left( \dfrac{y - \mu_y}{\sigma_y} \right)^2 - 2\rho_{xy} \left( \dfrac{x - \mu_x}{\sigma_x} \right) \left( \dfrac{y - \mu_y}{\sigma_y} \right) \right]}
$$

当  $\rho_{xy}=0$  时，上式中  $-2\rho_{xy}(\cdots)$  项消失，化简为：

$$
f_{X,Y}(x,y) = \frac{1}{2\pi \sigma_x \sigma_y}\exp\left(-\frac{1}{2}\left(\frac{x-\mu_x}{\sigma_x}\right)^2\right)\exp\left(-\frac{1}{2}\left(\frac{y-\mu_y}{\sigma_y}\right)^2\right)
$$

注意该表达式可分解为：
<div>
$$f_{X,Y}(x,y) = \underbrace{\frac{1}{\sqrt{2\pi}\sigma_x}e^{-\frac{(x-\mu_x)^2}{2\sigma_x^2}}}_{f_X(x)} \cdot \underbrace{\frac{1}{\sqrt{2\pi}\sigma_y}e^{-\frac{(y-\mu_y)^2}{2\sigma_y^2}}}_{f_Y(y)}$$
</div>

因此：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y)
$$

这表明  $X,Y$  是独立的。

{{< /alert >}}





{{< alert class="warning" >}}
**证明:**  若  $X,Y$  独立，则  $\text{Cov}(X,Y)=0$  （不相关）

若  $X,Y$  独立，则其联合概率密度函数满足：
$$
f_{X,Y}(x,y) = f_X(x)f_Y(y).
$$

计算  $E[XY]$ ：
$$
E[XY] = \iint xy f_{X,Y}(x,y)\,dx\,dy = \iint xy f_X(x)f_Y(y)\,dx\,dy
$$

由于可分离积分：
$$
E[XY] = \left(\int x f_X(x)\,dx\right)\left(\int y f_Y(y)\,dy\right) = E[X]E[Y]
$$

协方差定义为：
$$
\text{Cov}(X,Y) = E[XY] - E[X]E[Y]
$$

代入  $E[XY]=E[X]E[Y]$  得：
$$
\text{Cov}(X,Y) = E[X]E[Y] - E[X]E[Y] = 0
$$

由此可见，独立必然导致不相关。

{{< /alert >}}







## 随机向量

给定一个 $n$ 维随机向量 $\mathbf{x} = [x_1, x_2, \dots, x_n]^T$，其联合概率密度函数为 $f_x(x_1, x_2, \dots, x_n)$。该函数满足：

$$
f_x(x_1, x_2, \dots, x_n) \geq 0, \quad \forall x_1, x_2, \dots, x_n \in \mathbb{R}
$$

$$
\int_{-\infty}^{\infty} \dots \int_{-\infty}^{\infty} f_x(x_1, \dots, x_n) \, dx_1 \dots dx_n = 1
$$

对于任意超矩形区域 $[m_1,M_1]\times[m_2,M_2]\times\dots\times[m_n,M_n]$ 上的概率为：

$$
P\{x_1 \in [m_1,M_1], x_2 \in [m_2,M_2], \dots, x_n \in [m_n,M_n]\} 
= \int_{m_1}^{M_1} \int_{m_2}^{M_2} \dots \int_{m_n}^{M_n} f_x(x_1,\dots,x_n) \, dx_1 \dots dx_n
$$



#### 一阶矩与二阶矩

**一阶矩（期望向量）**
$$
m_x = E[\mathbf{x}] = 
\begin{bmatrix}
E[x_1] \\\\
E[x_2] \\\\
\vdots \\\\
E[x_n]
\end{bmatrix} \quad
$$

其中：

$$
E[x_n] =  \int_{-\infty}^{\infty} x_n \cdot f_{x_n}(x_n) \, dx_n
$$

这里 $f_{x_n}(x_n)$ 是 $x_n$ 的边缘分布。



**二阶矩（协方差矩阵）**

定义随机向量 $\mathbf{x}$ 的协方差矩阵 $C_x$ 为：
$$
C_x = E[(\mathbf{x} - m_x)(\mathbf{x} - m_x)^T]
$$

将 $\mathbf{x}-m_x$ 展开：

$$
\mathbf{x}-m_x = 
\begin{bmatrix}
x_1 - E[x_1] \\\\
x_2 - E[x_2] \\\\
\vdots \\\\
x_n - E[x_n]\\
\end{bmatrix}
$$

因此：

$$
C_x = E \left[
\begin{bmatrix}
x_1 - E[x_1] \\\\
x_2 - E[x_2]  \\\\
\vdots  \\\\
x_n - E[x_n] \\\\ 
\end{bmatrix} \quad
\begin{bmatrix}
x_1 - E[x_1] & x_2 - E[x_2] & \dots & x_n - E[x_n] \quad
\end{bmatrix} 
\right]
$$

所以：

$$
C_x =
\begin{bmatrix}
\text{Var}(x_1) & \text{Cov}(x_1, x_2) & \dots & \text{Cov}(x_1, x_n) \\\\
\text{Cov}(x_2, x_1) & \text{Var}(x_2) & \dots & \text{Cov}(x_2, x_n) \\\\
\vdots & \vdots & \ddots & \vdots \\\\
\text{Cov}(x_n, x_1) & \text{Cov}(x_n, x_2) & \dots & \text{Var}(x_n)
\end{bmatrix}\quad
$$

若 $\mathbf{x}$ 的分量相互独立，则对任意 $i \neq j$，$\text{Cov}(x_i, x_j) = 0$，协方差矩阵为对角阵：

$$
C_x =
\begin{bmatrix}
\text{Var}(x_1) & 0 & \dots & 0 \\\\
0 & \text{Var}(x_2) & \dots & 0 \\\\
\vdots & \vdots & \ddots & \vdots \\\\
0 & 0 & \dots & \text{Var}(x_n)
\end{bmatrix}
$$

```matlab
clear; clc; close all;

%% 定义符号变量与参数
syms x1 x2 real

%----------------------------
% 定义2维高斯分布参数
% 均值向量 m_x = [mu_x1; mu_x2]
mu_x1 = 0;  
mu_x2 = 2;
m_x = [mu_x1; mu_x2];

% 协方差矩阵 C_x
sigma_x1 = 1;
sigma_x2 = 1.5;
rho_x1x2 = 0.3; % 相关系数
C_x = [sigma_x1^2, rho_x1x2*sigma_x1*sigma_x2;
       rho_x1x2*sigma_x1*sigma_x2, sigma_x2^2];
```

**协方差矩阵 $C_x$ 的性质**

- **对称性**：$C_x = C_x^T$

{{< alert class="warning" >}}

**证明**：
$$
C_x^T = \left( E[(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T] \right)^T 
= E[((\mathbf{x}-m_x)(\mathbf{x}-m_x)^T)^T] 
= E[(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T] = C_x
$$

{{< /alert >}}




```matlab
% 验证C_x为对称
eigVals = eig(C_x);

% 定义用于显示的字符串
stateStr = {'不对称','对称'};

% 使用issymmetric判断并通过索引选择相应的字符串
disp(['协方差矩阵C_x=', mat2str(C_x), ' -> C_x=', stateStr{issymmetric(C_x)+1}]);
```



- **正定性**：$C_x$ 是一个半正定矩阵

{{< alert class="warning" >}}

**证明**：
对任意向量 $u$：
$$
u^T C_x u = u^T E[(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T] u 
= E[u^T(\mathbf{x}-m_x)(\mathbf{x}-m_x)^T u] 
= E[(u^T(\mathbf{x}-m_x))^2] \geq 0
$$

若无退化（方差均大于0），则 $C_x$ 正定。

{{< /alert >}}



```matlab
% 验证C_x 半正定
disp(['C_x的特征值(应非负)=', mat2str(eigVals,4)]);
```



- 所有特征值非负，迹为方差和，必然 $\text{Tr}(C_x) \geq 0$。



**线性变换下的协方差**

若 $Y = A x + B$，则：

$$
C_y = E[(Y - E[Y])(Y - E[Y])^T]
= A E[(X - E[X])(X - E[X])^T] A^T
= A C_x A^T
$$

```matlab
%% 线性变换下的协方差
% 若Y = A X + B，则 C_y = A C_x A^T
A = [2 1; -1 3];
B = [1;0];
C_y = A*C_x*A';
disp('线性变换后Y的协方差矩阵:');
disp(C_y);
disp('C_y的特征值(应>=0)：');
disp(eig(C_y));
```



#### 不相关与独立

- **不相关 (Uncorrelated)**：若 $\text{Cov}(x_i, x_j)=0$ 对所有 $i\neq j$ 成立，则称 $x_i$ 与 $x_j$ 不相关。但不相关不保证独立。

- **独立 (Independent)**：若满足
  $$
  f_{x_1,\dots,x_n}(x_1,\dots,x_n) = \prod_{i=1}^n f_{x_i}(x_i),
  $$
  则称 $x_1,\dots,x_n$ 独立。

**重要结论**：一般情况下，不相关 $\not\to$ 独立。但对于高斯（正态）分布，在不相关条件下可以推出独立。



{{< alert class="warning" >}}

**证明**：

对于多维高斯随机向量 $\mathbf{x}$，其概率密度函数为：

$$
f_x(\mathbf{x}) = (2\pi)^{-N/2} [\det(C_x)]^{-1/2} \exp\left(-\frac{1}{2}(\mathbf{x}-m_x)^T C_x^{-1} (\mathbf{x}-m_x)\right)
$$

```matlab
% 定义二维高斯联合pdf f_{X}(x1,x2)
x = [x1; x2];
C_x_inv = inv(C_x);
det_Cx = det(C_x);
fX = (1/(2*pi*sqrt(det_Cx))) * ...
     exp(-1/2 * (x - m_x).' * C_x_inv * (x - m_x));
```

当各分量不相关时，$C_x$ 为对角矩阵：

$$
C_x =
\begin{bmatrix}
\text{Var}(x_1) & 0 & \dots & 0 \\\\\\
0 & \text{Var}(x_2) & \dots & 0 \\\\
\vdots & \vdots & \ddots & \vdots \\\\
0 & 0 & \dots & \text{Var}(x_n)
\end{bmatrix}
$$

于是：

$$
C_x^{-1} = \text{diag}\left(\frac{1}{\gamma_1}, \frac{1}{\gamma_2}, \dots, \frac{1}{\gamma_n}\right)
$$

带入指数项中：

$$
\exp\left(-\frac{1}{2}(\mathbf{x}-m_x)^T C_x^{-1} (\mathbf{x}-m_x)\right)
= \exp\left(-\frac{1}{2}\sum_{i=1}^n \frac{(x_i - m_{x_i})^2}{\gamma_i}\right)
$$

密度函数分解为各分量的高斯密度乘积：

$$
f_x(\mathbf{x}) = \prod_{i=1}^n \left( (2\pi)^{-1/2} \gamma_i^{-1/2} \exp\left(-\frac{(x_i - m_{x_i})^2}{2\gamma_i}\right) \right)
= \prod_{i=1}^n f_{x_i}(x_i)
$$

举例：


$$
假设
\begin{cases}
  f_{x_1}(x_1) = (2\pi)^{-\frac{1}{2}} \gamma_1^{-\frac{1}{2}} \cdot \exp\left( -\frac{1}{2} \cdot \frac{(x_1 - m_{x_1})^2}{\gamma_1} \right)   \\\\
  f_{x_2}(x_2) = (2\pi)^{-\frac{1}{2}} \gamma_2^{-\frac{1}{2}} \cdot\exp\left( -\frac{1}{2} \cdot \frac{(x_2 - m_{x_2})^2}{\gamma_2} \right) &
\end{cases}
$$

$$
f_{x_1, x_2}(x_1, x_2) = f_{x_1}(x_1) \cdot f_{x_2}(x_2)
$$

结论：高斯向量在不相关条件下的联合分布可分解为独立分布的乘积，即此时 $x_i$ 相互独立。

{{< /alert >}}

## 随机信号

设有离散时间随机过程(信号) $\{X_n\}$。从统计特性角度，若满足以下条件则称其为平稳（stationary）：

一阶稳态：均值不随时间变化

$$
m_x(n) = \mathbb{E}[X_n] = m_x
$$

二阶稳态：协方差 $ r_x(n, p)$ 仅与时间差有关，不随绝对时间点  $n$ 变化 
$$
r_x(n, p) = \text{Cov}(X_n, X_{n+p}) = \mathbb{E} \left[ \left( X_n - \mathbb{E}(X_n) \right) \left( X_{n+p} - \mathbb{E}(X_{n+p}) \right) \right]
$$

若该函数仅依赖于时间差 $p$，即对所有 $n$：
$$
r_x(n, p) = r_x(p)
$$

#### 实例分析

给定一个随机信号：
$$
x_n = \alpha \cdot e^{j\left(2\pi v n + \phi\right)}
$$
其中 $\phi$ 在区间 $[-\pi, \pi]$ 上均匀分布且独立于 $n$

```matlab
clear; close all; clc;

%% 部分1：验证 x_n = alpha * exp(j(2*pi*nu0*n + phi)) 的特性

% 参数设置
N = 100000;          % 信号长度
alpha = 1;           % 幅值
nu0 = 0.1;           % 信号频率(归一化频率)
% 产生 phi 均匀分布于[-pi, pi]
phi = (rand(1)*2*pi - pi); 

% 产生信号 x_n
n = (0:N-1);

NumTrials = 1000;  % 多次重复试验以计算期望
X_all = zeros(NumTrials, N);

for trial = 1:NumTrials
    phi_rand = (rand(1)*2*pi - pi);
    X_all(trial,:) = alpha * exp(1j*(2*pi*nu0*n + phi_rand));
end
```



1. 计算均值：

$$
m_x(n) = \mathbb{E}[x_n] = \mathbb{E} \left[ \alpha \cdot e^{j \left( 2\pi v \cdot n + \phi \right)} \right] = \alpha \cdot e^{j 2\pi v n} \cdot \mathbb{E} \left[ e^{j \phi} \right]
$$

由于 $\phi$ 在 $[-\pi, \pi]$ 上均匀分布，且 $\mathbb{E} \left[ e^{j \phi} \right] = 0$，计算期望：

$$
\mathbb{E}[e^{j\phi}] = \frac{1}{2\pi}\int_{-\pi}^{\pi} e^{j\phi} d\phi = 0,
$$

因此：
$$
m_x(n) = 0
$$
因此与 $n$ 无关，满足一阶稳态。

```matlab
% 计算均值 (对试验数和时间长度求平均)
m_x_est = mean(mean(X_all,2));  
disp(['估计的均值 m_x = ', num2str(m_x_est)]);
```



2. 计算协方差函数：

$$
r_x(n, p) = \mathbb{E}[x_n x_{n+p}^*] 
$$

将定义代入：
$$
x_n x_{n+p}^* = \alpha e^{j(2\pi v n + \phi)} \cdot \alpha e^{-j(2\pi v (n+p) + \phi)}
$$
化简：
$$
x_n x_{n+p}^* = \alpha^2 e^{j2\pi v n + j\phi}e^{-j2\pi v n - j2\pi v p - j\phi} = \alpha^2 e^{-j2\pi v p}
$$
注意这里因为 $x_{n+p}$ 与 $x_n$ 中的 $\phi$ 相同，对 $\phi$ 的期望不会产生消去效应（实际上 $\phi$ 出现在 $x_n$ 和 $x_{n+p}$ 中会相互抵消），故求期望时：
$$
r_x(n,p) = \mathbb{E}[x_n x_{n+p}^*] = \alpha^2 e^{-j2\pi v p}
$$
该函数不依赖于 $n$，只依赖于 $p$，满足二阶稳态。



#### 协方差函数的特性（在一二阶稳态的情况下）

1. **对称性**： 
   $$
   r_x(-p) = r_x(p)
   $$
   {{< alert class="warning" >}}

   **证明**：
   $$
   r_x(-p) = \mathbb{E}[(X_n - m_x)(X_{n-p} - m_x)]
   $$

   {{< /alert >}}

   更换索引 $n \to n-p$，不影响统计特性：
   $$
   r_x(-p) = \mathbb{E}[(X_{n-p} - m_x)(X_n - m_x)] = r_x(p)
   $$

2. **移位不变性**： 
   $$
   \text{Cov}[X_n, X_m] = \gamma(n-m) = \gamma(m-n)
   $$
   因为二阶稳态要求协方差仅依赖于时间差 $(m-n)$。

3. **方差和协方差的关系**： 
   $$
   r_x(0) = \mathbb{E}[(X_n - m_x)^2] = \text{Var}(X_n)
   $$

4. **最大值性质**： 
   $$
   \gamma_x(p) \leq \gamma_x(0)
   $$
   即在 $p=0$ 处取得最大值。这直观上表明，一个信号与其自身的重合（无延迟）协方差最大。



#### 功率谱密度 (PSD)

功率谱密度 $S_x(\nu)$ 是协方差函数 $r_x(p)$ 的离散时间傅里叶变换（DTFT）：

$$
S_x(\nu) = \text{TF}[r_x(p)] = \sum_{k=-\infty}^{\infty} r_x(k) e^{-j2\pi \nu k}, \quad v \in \mathbb{R}
$$

反变换：

$$
r_x(p) = \int_{-\frac{1}{2}}^{\frac{1}{2}} S_x(\nu) e^{j 2 \pi \nu p} d\nu = \text{TFI} \left[ S_x(\nu) \right]
$$

**性质**：

- $S_x(\nu)$ 是 $1$ 周期的周期函数： 

  因为:
  $$
  e^{-j2\pi(\nu+1)k} = e^{-j2\pi\nu k} \cdot e^{-j2\pi k} = e^{-j2\pi\nu k} \cdot 1
  $$
  对任意整数 $k$ 都成立，所以 $S_x(\nu+1)=S_x(\nu)$。

  

- $S_x(\nu)$ 是实且非负的： 

$$
S_x(\nu) \geq 0
$$

- 频域积分等于时域协方差在零点的值，即方差：  
  $$
  r_x(0) = \text{Var}(X_n) = \int_{-1/2}^{1/2} S_x(\nu) d\nu.
  $$

  

  这表明在频域对功率谱密度积分，得到时域零延迟协方差（方差）。



#### 例子继续说明

对于之前定义的 $x_n = \alpha e^{j(2\pi \nu_0 n + \phi)}$，我们已知：

- $$
  m_x=0
  $$

  

- $$
  \gamma_x(p)=\alpha^2 e^{j2\pi\nu_0 p}
  $$

将其作傅里叶变换可以得到功率谱密度 $S_x(\nu)$。对一个纯正弦信号加上相位的情形，这类似一个单频分量，因此 $S_x(\nu)$ 将在 $\nu=\nu_0$ 处表现为一个冲激函数 $\delta(\nu-\nu_0)$：
$$
S_x(\nu)=\alpha^2 \delta(\nu-\nu_0)
$$
这意味着该随机信号在频域上集中于一个频率点 $\nu_0$，所有功率都在此单一频点上。



#### 白噪声示例

对白噪声信号 $\{B_n\}$ 而言：

- $E[B_n]=0$
- 在两个不同时间点不相关，即 $\text{Cov}(B_n,B_m)=0$ 当 $n \neq m$
- 对于 $n=m$ 时，$\text{Var}(B_n)=\gamma_0$（某个常量）

故协方差函数（自相关函数）：
$$
r_{B}(p) = \gamma_0 \cdot  \delta_p
$$
对功率谱密度进行反变换：
$$
r_B(p) = \int_{-1/2}^{1/2} S_B(\nu) e^{j2\pi\nu p} d\nu
$$

若 $S_B(\nu)$ 是常量（即白噪声频谱平坦）：
$$
S_B(\nu)=\gamma_0
$$
则：
$$
r_B(p)=\gamma_0 \int_{-1/2}^{1/2} e^{j2\pi\nu p} d\nu
$$

当 $p=0$：
$$
r_B(0)=\gamma_0 \int_{-1/2}^{1/2} d\nu = \gamma_0
$$

当 $p \neq 0$ 时，该积分为一个复指数函数在对称区间上的积分，其结果为零。这恰好与 $\delta_p$ 的定义一致（只有在 $p=0$ 时非零）。

## 随机信号滤波

考虑一个输入为随机信号 $x_n$，输出为 $y_n$ 的线性时不变(LTI)系统。该系统可以用卷积描述：

$$
y_n = x_n * h_n = \sum_{k=-\infty}^{+\infty} h(k) \cdot x(n-k)
$$

- 其中 $h_n$ 为系统脉冲响应。

#### 输出协方差的推导

**去均值的输出过程表示**

给定输出信号：

$$
y_n = \sum_{k=-\infty}^{+\infty} h(k) \cdot x(n-k),
$$

输出去掉均值 $m_y$ 后为：

$$
(y_n - m_y) = \sum_{k=-\infty}^{+\infty} h(k) \cdot [x(n-k) - m_x].
$$

同理，对于延迟 $p$ 个点的输出：

$$
(y_{n+p} - m_y) = \sum_{e=-\infty}^{+\infty} h(e) \cdot [x(n+p-e) - m_x].
$$

这两式说明输出减去均值后的值仍是由输入减去其均值的值通过相同的脉冲响应 $h(\cdot)$ 线性叠加得到的。

**协方差定义与代入**

输出的协方差定义为：

$$
r_y(p) = \mathbb{E}[(y_n - m_y)(y_{n+p}-m_y)]
$$

代入前面去均值的表达式：

$$
\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)]
= \mathbb{E}\left[\left(\sum_{k} h(k)[x(n-k)-m_x]\right)\left(\sum_{e} h(e)[x(n+p-e)-m_x]\right)\right]
$$

由于期望是线性算子，可以先将 $h(k)$ 和 $h(e)$ 提出来，再对 $x(\cdot)-m_x$ 的乘积项求期望：

$$
= \sum_{k=-\infty}^{+\infty} \sum_{e=-\infty}^{+\infty} h(k)h(e) \mathbb{E}[(x_{n-k}-m_x)(x_{n+p-e}-m_x)]
$$

**利用输入协方差函数 $r_x(\cdot)$**

定义输入信号的协方差函数：

$$
r_x(\tau) = \mathbb{E}[(x_{n}-m_x)(x_{n+\tau}-m_x)]
$$

根据这一定义：

$$
\mathbb{E}[(x_{n-k}-m_x)(x_{n+p-e}-m_x)] = r_x(p+k-e)
$$

将此结果代入上式：

$$
\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)]
= \sum_{k=-\infty}^{+\infty} \sum_{e=-\infty}^{+\infty} h(k)h(e)r_x(p+k-e)
$$

**定义中间函数 $\tilde{r}_x(p+k)$**

给出了一个中间定义：

$$
\tilde{r}_x(p+k) = \sum_{e=-\infty}^{+\infty} h(e) \cdot r_x(p+k-e)
$$

这相当于将 $r_x(\cdot)$ 与 $h(\cdot)$ 进行一次卷积得到的中间结果。这一步是为了简化表达。

于是有：

$$
\mathbb{E}[(y_n - m_y)(y_{n+p} - m_y)] = \sum_{k=-\infty}^{+\infty} h(k)\tilde{r}_x(p+k)
$$

**定义 $\bar{h}(k) = h(-k)$ 并进一步化简**

通过定义 $\bar{h}(k)=h(-k)$，对求和指标进行变换，就能将表达式写成多次卷积的形式：

<div>
$$\sum_{k=-\infty}^{+\infty} h(k)\tilde{r}_x(p+k)
= \sum_{k=-\infty}^{+\infty} \bar{h}(-k) \tilde{r}_x(p+k)$$
</div>

通过索引替换 $q=-k$（或其他方式），最终可以将其表示为：

<div>
$$\tilde{\tilde{r}}_x(p) = \sum_{q=-\infty}^{\infty} \bar{h}(q)\tilde{r}_x(p-q)$$
</div>

这再次呈现出卷积的形式。实际上，这个结果显示 $r_y(p)$ 可以用 $h(\cdot)$、$\bar{h}(\cdot)$ 和 $r_x(\cdot)$ 的多重卷积来表示：

$$
r_y(p) = \bar{h} * h * \tilde{r}_x(p)
$$

#### 频域表示

在频域表示中，卷积在时域对应频域的乘法关系。已知 $S_x(\nu)$ 是输入的功率谱密度，$H(\nu)$ 是系统频率响应，则输出功率谱密度为：

$$
S_y(\nu) = |H(\nu)|^2 S_x(\nu).
$$

这里的等式：

$$
S_y(\nu) = H(\nu)^* \cdot H(\nu) \cdot S_x(\nu) = |H(\nu)|^2 \cdot S_x(\nu)
$$

与时域结果 $r_y(p) = \bar{h} * h * \tilde{r}_x(p)$ 相吻合，因为卷积在时域转化为频域相应函数的乘积。

综上所述
$$
\begin{cases}
  r_y(p) = \bar{h} * h * \tilde{r}_x(p)  \\\\
  S_y(\nu) =  |H(\nu)|^2 \cdot S_x(\nu)  \\
\end{cases}
$$



这就是**维纳滤波器（Filtrage de Wiener）**，用于在有噪音的环境中恢复信号。

## 维纳滤波器 (Wiener Filter) 

维纳滤波器的基本目标是在有噪声的环境中，从观测到的输出信号 $y_n$ 中尽可能恢复原始信号 $x_n$。通过构建一个滤波器 $g_n$ 对输出进行处理，希望得到的估计 $\hat{x}_n$ 与真实 $x_n$ 之间的均方误差 (MSE) 最小。

给定带噪模型：

$$
y_n = x_n * h_n + b_n = \sum_{k=-\infty}^{+\infty} h(k) \cdot x(n-k) + b_n
$$

这里，$h_n$ 是已知系统的脉冲响应，$b_n$ 是加性噪声。由该模型可知，当没有噪声时 ($b_n=0$)，$y_n$ 只是 $x_n$ 经过系统的线性时不变变换。

相应协方差与功率谱密度的结果为：

$$
\begin{cases}
r_y(p) = \bar{h} * h * \tilde{r}_x(p) + r_b \\\\
S_y(\nu) = |H(\nu)|^2 \cdot S_x(\nu) + S_b(\nu)
\end{cases}
$$

这里的 $r_y(p)$ 和 $S_y(\nu)$ 是输出信号 $y_n$ 的协方差函数与功率谱密度。$S_x(\nu)$ 和 $S_b(\nu)$ 分别是输入信号与噪声的功率谱密度，$H(\nu)$ 是系统的频率响应。

#### 求解维纳滤波器

定义估计误差的均方值 (MSE)：

$$
e_n = \mathbb{E}\left[ (\hat{x}_n - x_n)^2 \right]
$$

其中 $\hat{x}_n = y_n * g_n$ 表示我们在输出 $y_n$ 上再施加一个滤波器 $g_n$ 得到的估计量；$g_n$ 是我们需要求解的滤波器脉冲响应。

**关键想法**：通过调整 $g_n$，使得 $e_n$ 最小。为了求最优 $g_n$，对 $e_n$ 关于 $g_{k_0}$（$g_n$ 的第 $k_0$ 个参数）的偏导数设为零。这个过程相当于最小化 MSE 的变分条件。

求导步骤是：

$$
\frac{d}{d g_{k_0}} e_n = \frac{d}{d g_{k_0}} \mathbb{E}[(\hat{x}_n - x_n)^2].
$$

通过链式法则和线性算子特性，可得：

$$
\frac{d}{d g_{k_0}} e_n = 2 \mathbb{E} \left[ y_{n-k_0}(\hat{x}_n - x_n) \right].
$$

其中使用了中间结果：

<div>
$$\frac{d \hat{x}_n}{d g_{k_0}} = y_{n-k_0}$$
</div>



这意味着当改变滤波器 $g_{k_0}$ 的某个系数时，对估计误差的影响与输出信号的取值 $y_{n-k_0}$ 成正比。

#### 计算期望项与条件方程

计算：

$$
\mathbb{E} \left[ y_{n-k_0} \cdot x_n \right] = \bar{h} * r_x(k_0)
$$

这一步体现了输出信号与输入信号之间的相关性。当没有噪声时，$y_n$ 与 $x_n$ 的关联由 $h_n$ 和 $r_x$ 决定。

 这里的卷积形式 $\bar{h} * r_x(k_0)$ 说明：为了得到输出与输入的二阶统计量关系，需要将输入的协方差函数 $r_x(\cdot)$ 经过包含 $h(\cdot)$ 的变换（以及 $\bar{h}(k)=h(-k)$ 的定义）来获得。
$$
\mathbb{E}[y_{n-k_0} \cdot \hat{x}_n] = g * r_y(k_0)
$$

当考虑估计量 $\hat{x}_n$ 时，我们有 $\hat{x}_n = y_n * g_n$，因此该期望中同时出现 $y_n$ 和 $\hat{x}_n$，最终呈现为 $g$ 与 $r_y$ 的卷积。

这表达了估计滤波器 $g_n$ 对输出统计特性的作用：$g_n$ 与 $r_y$ 相卷积来描述对输出自身统计属性的修正。

因此：

$$
\frac{d}{d g_{k_0}} e_n = 2 \left( g * r_y(k_0) - \bar{h} * r_x(k_0) \right)
$$

令偏导数为零，得到最优滤波器公式：

$$
g * r_y(k_0) = \bar{h} * r_x(k_0)
$$

这是一个关键方程，它表明在时域下，维纳滤波器 $g_n$ 的作用是将输出协方差 $r_y$ 与输入信号特性通过 $\bar{h}$ 和 $r_x$ 联系起来。要实现最优估计，$g_n$ 必须满足这个卷积方程。

#### 转换到频域求解

在频域中，卷积变为简单的乘法。对上式取傅里叶变换：

$$
G(\nu) S_y(\nu) = H(\nu)^* S_x(\nu)
$$

因此得到维纳滤波器的频率响应：
$$
G(\nu) = \frac{H(\nu)^* S_x(\nu)}{S_y(\nu)}
$$
由 $S_y(\nu) = |H(\nu)|^2 S_x(\nu) + S_b(\nu)$，可将 $S_y(\nu)$ 替换进去：
$$
G(\nu) = \frac{H(\nu)^* S_x(\nu)}{|H(\nu)|^2 S_x(\nu) + S_b(\nu)}
$$

#### 特殊情况分析

1. **无噪音（当 $\gamma_B = 0$，$S_B = 0$）**

$$
G(\nu) = \frac{H(\nu)^* S_x(\nu)}{|H(\nu)|^2 S_x(\nu)} = \frac{1}{H(\nu)},
$$

即维纳滤波器退化为系统传递函数的逆滤波器，以完全恢复输入信号 $x_n$。

2. **无滤波器（仅直通）且有噪声 ($H(\nu)=1$)**：

$$
G(\nu) = \frac{S_x(\nu)}{S_x(\nu) + S_b(\nu)} = \frac{1}{1 + \frac{S_b(\nu)}{S_x(\nu)}}
$$

此时，滤波器在各频率处根据信噪比 (SNR = $S_x(\nu)/S_b(\nu)$) 来决定增益大小：  

- 当 $S_x(\nu)$ 远大于 $S_b(\nu)$，即信号显著强于噪声，$G(\nu)$ 接近 1；  
- 当 $S_x(\nu)$ 接近或小于 $S_b(\nu)$，增益会小于 1，从而衰减该频段成分，减少噪声影响。

这反映了维纳滤波器的平衡策略：在高信噪比频段尽量还原信号，在低信噪比频段减少增益以抑制噪声。

关于 Wiener 滤波器的应用部分请看 [维纳滤波器进行反卷积](https://zehua.eu/zh/posts/signal_cn/随机信号tp3/)

## 经验估计器

#### 偏差与方差分解

假设 $\hat{\theta}$ 为估计值，评判标准为最小均方误差（MSE）：

$$
\varepsilon = \mathbb{E}[(\theta - \hat{\theta})^2]
$$

展开：

$$
\varepsilon = \mathbb{E}[(\theta - \mathbb{E}(\hat{\theta}) + \mathbb{E}(\hat{\theta}) - \hat{\theta})^2] = \mathbb{E}[(\theta - \mathbb{E}(\hat{\theta}))^2] + \mathbb{E}[(\mathbb{E}(\hat{\theta}) - \hat{\theta})^2]
$$

- 系统性偏差：$\theta - \mathbb{E}[\hat{\theta}]$ 

  这是估计值的期望与真实参数 $\theta$ 的差异，即估计量相对于真实值的平均偏移量，不随随机性的不同实现而变化（它是确定性的，不随样本的不同取值变化）。

- 随机波动项：$\mathbb{E}[\hat{\theta}] - \hat{\theta}$  

  这是估计量本身围绕其期望值的波动，体现了估计量的方差性质。



假设偏差 $B = \theta - E[\hat{\theta}]$，即真实值减去估计的期望值。

因此，有：

$$
\varepsilon = \mathbb{E}[(B + (\mathbb{E}[\hat{\theta}] - \hat{\theta}))^2]
$$

由于 $B$ 是一个常数（不随随机性变化），而 $(\mathbb{E}[\hat{\theta}] - \hat{\theta})$ 是随机变量且均值为零，我们可将二次期望展开为：

$$
\varepsilon = \mathbb{E}[B^2 + 2B(\mathbb{E}[\hat{\theta}] - \hat{\theta}) + (\mathbb{E}[\hat{\theta}] - \hat{\theta})^2]
$$

因为 $B$ 为常量，且 $\mathbb{E}[\hat{\theta}] - \hat{\theta}$ 的期望为0（其期望值即 $\mathbb{E}[(\mathbb{E}[\hat{\theta}] - \hat{\theta})] = \mathbb{E}[\hat{\theta}] - \mathbb{E}[\hat{\theta}] = 0$），中间项的期望 $\mathbb{E}[2B(\mathbb{E}[\hat{\theta}] - \hat{\theta})] = 2B \mathbb{E}[\mathbb{E}[\hat{\theta}] - \hat{\theta}] = 0$。

于是剩下：

$$
\varepsilon = B^2 + \mathbb{E}[(\mathbb{E}[\hat{\theta}] - \hat{\theta})^2]
$$

注意到 $(\mathbb{E}[\hat{\theta}] - \hat{\theta})$ 是 $\hat{\theta}$ 相对于其期望的偏差，定义为估计量的方差：

$$
\text{Var}(\hat{\theta}) = \mathbb{E}[(\hat{\theta} - \mathbb{E}[\hat{\theta}])^2]
$$

由于 $(\mathbb{E}[\hat{\theta}] - \hat{\theta})^2 = (\hat{\theta}-\mathbb{E}[\hat{\theta}])^2$，故可直接写为方差。

最终得到著名的偏差-方差分解公式：

$$
\varepsilon = B^2 + \text{Var}(\hat{\theta})
$$

#### 偏差-方差权衡意义

- 若估计量是无偏的，即 $B=0$，则有 $\varepsilon = \text{Var}(\hat{\theta})$。此时均方误差等同于方差，减小方差便能直接降低均方误差。	

- 若估计量有偏差，则 $\varepsilon$ 包含了一个不可忽略的常量项 $B^2$。即使我们减小估计量的方差，也无法使均方误差低于 $B^2$。这体现了一个偏差-方差权衡：有时允许一点偏差可以大幅降低方差，从而整体减少MSE；有时严格坚持无偏性会导致较大的方差，使MSE变大。









